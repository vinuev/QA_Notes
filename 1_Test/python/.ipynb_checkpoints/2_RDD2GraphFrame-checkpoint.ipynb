{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content\n",
    "    0. File Path\n",
    "    1. Load Vertices\n",
    "    2. Load Edges\n",
    "    3. Create Graph & Test\n",
    "    4. GST Requirements\n",
    "    5. GST Steps\n",
    "    6. BT-QA main_GST Steps ( Plan )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GST Requirements\n",
    "### Function: \n",
    "    call_main_GST\n",
    "    (QKG_file, cornerstone_file, qtype, answer_list_file, no_GST, gdict, verbose, gt,config,con)\n",
    "    \n",
    "### Corresponding Parameter\n",
    "    f1, f2, f4, f5, no_GST, gdict, verbose, gt1, config, context_file\n",
    "        \n",
    "    0. QKG_file            f1=argv[1] #input QKG\n",
    "    1. cornerstone_file    f2=argv[2] #input Cornerstones \n",
    "    2. qtype               f4=argv[3] #answer match / qtype\n",
    "    3. answer_list_file    f5=argv[4] #answer type /answer_list_file \n",
    "    4. no_GST              no_GST=int(argv[5]) #number of GSTs\n",
    "    5. gdict               gdict\n",
    "    6. verbose             verbose=int(argv[6])\n",
    "    7. gt\n",
    "    8. config\n",
    "    9. con                 context file\n",
    "    \n",
    "### Corresponding Value\n",
    "    0. f1 = \"./files/QKG_ques-q1\"  \n",
    "        *** What: KG \n",
    "        *** From: Generated by Data2Graph\n",
    "        *** How to use it in GST:\n",
    "        \n",
    "    1. f2 = \"./files/QKG_cornerstones_ques-q1\" \n",
    "        *** What: KG Gpickle \n",
    "        *** From: Generated by Data2Graph, cornerstones?? and them selected by ????\n",
    "        *** How to use it in GST:\n",
    "        \n",
    "    2. f4 = \"question_type.txt\" \n",
    "        *** What: question type\n",
    "        *** From: get_answer_types_from_questions.py\n",
    "        *** How to use it in GST:used to check the answer type and select related answer\n",
    "        \n",
    "    3. f5 = \"./files/Answer_list_ques-q1\" \n",
    "        \n",
    "        *** What: answer_list_file='./files/Answer_list_'+str(qid) only represent an address\n",
    "        *** From: path parameter\n",
    "        *** How to use it in GST: used to named answer-related address\n",
    "    \n",
    "    4. no_GST = 50 #Number of GSTs to be considered\n",
    "        *** What: \n",
    "        *** From: config\n",
    "        *** How to use it in GST:set the limited node number  \n",
    "        \n",
    "    5. gdict = \n",
    "            # gdict={}\n",
    "            # model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)  \n",
    "            # word_vectors = model.wv\n",
    "            # gdict=word_vectors\n",
    "            \n",
    "        *** What: word2vector\n",
    "        *** From: gensim.models.KeyedVectors\n",
    "        *** How to use it in GST: for calculate the Predicate weight(no need to used in BT-QA)\n",
    "\n",
    "    6. verbose=int(argv[6])      \n",
    "        *** What: To print intermediate statements in verbose manner make it 1, other wise 0 \n",
    "        *** From: Config\n",
    "        *** How to use it in GST:\n",
    "    \n",
    "    7. gt = set(['unknown'])\n",
    "        *** What: a set of answer, the initial is 'unknown'\n",
    "        *** From: \n",
    "        original from reformat_dataset_single.py\n",
    "        in get_formatted_docs function,  \n",
    "        fp.write('Answer\\t' + 'Unknown\\n')\n",
    "        *** How to use it in GST:\n",
    "        \n",
    "    8. config stream = open(\"config.yml\", 'r')\n",
    "        for line in stream:\n",
    "        if not line.startswith('#') and len(line)>1:\n",
    "            line=line.split(':')\n",
    "            config[line[0]]=line[1].strip()\n",
    "       \n",
    "    9. con = \"./files/context_ques-q1\"  \n",
    "        *** What: context_file, not be used in GST, should be deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. GST Steps\n",
    "    - 0. load graph & corner\n",
    "    - 1. initialize_queue \n",
    "        (combine the 'corner' with graph and get edges' cost between 'corner node' and 'question node' in graph. see the result T & Q)\n",
    "    - 2. get GST set\n",
    "    - 3. get answer type \n",
    "    - 4. trees with potential answers by filtering answer type from GST set\n",
    "    - 5. answering merge (need to be changed because mention node provide more convience)\n",
    "    - 6. find unique sets of answers and get result list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. BT-QA main_GST Steps ( Plan )\n",
    "### preprepare (libraries part)\n",
    "- 0. For graph part: \n",
    "    - add node property (only for 'entity' & 'mention' nodes): weight & matched \n",
    "         - reference: \"def add_node_weights\" in \"generate_graphs_from_triples.py\"\n",
    "        \n",
    "    - add edges property wight & wlist \n",
    "         - reference: \"def distribute_node_weights\" in \"generate_graphs_from_triples.py\"\n",
    "        \n",
    "    - add type node of all 'mention' node\n",
    "         - reference: \"def add_type_edges\" in \"generate_graphs_from_triples.py\"\n",
    "        \n",
    "    - change the id from 'number' to 'vocabulary: Node Type(doc/sent/clause/entity/mention/type)'\n",
    "        \n",
    "    - Structure:\n",
    "   \n",
    "            *Nodes:\n",
    "            - ID:'vocabulary: Node Type(doc/sent/clause/entity/mention/type)'\n",
    "            - Attribute:\n",
    "                (u“id”, {\n",
    "                ‘type’:“”\n",
    "                ‘attr1’:“”\n",
    "                ‘attr2’:“”\n",
    "                ‘attr3’:“”\n",
    "                ‘matched’:“” ##for matched questions' entities\n",
    "                ‘weight’:0.0 ##for matched weight between node and questions' entities\n",
    "                })\n",
    "            - the weight are calculted by ‘Jaccard Coefficient’\n",
    "\n",
    "            *Edges:\n",
    "            - Node1, Node2\n",
    "            - Attribute:\n",
    "            (u'node1’,\n",
    "             u'node2',\n",
    "             {'weight': 0.0,\n",
    "              'wlist': [0.0，0.0]})\n",
    "\n",
    "    - generate corner and save it into pickle \n",
    "        reference: \"generate_graphs_from triples in generate graph from triples.py\"\n",
    "\n",
    "\n",
    "- 1. Generate answer type from question\n",
    "     - reference: get_answer_types_from_questions.py\n",
    "    \n",
    "### steps: ( 24 functions need to be modified, 14 of them contains graph )\n",
    "- 0. load graph & corner\n",
    "- 1. initialize_queue (2 def)\n",
    "    (combine the 'corner' with graph and get edges' cost between 'corner node' and 'question node' in graph. see the result T & Q)\n",
    "- 2. get GST set (6 def)\n",
    "- 3. get answer type \n",
    "- 4. trees with potential answers by filtering answer type from GST set (4 def)\n",
    "- 5. answering merge (need to be changed because Entity node provide more convience) (2 def)\n",
    "- 6. find unique sets of answers and get result list (10 def)\n",
    "    \n",
    "    future plan: \n",
    "    I'll try to extract predicate and generate predicate node from clause to see if the precision will be enhanced or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.3.5:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.addPyFile('/usr/local/Cellar/apache-spark/2.4.1/libexec/jars/graphframes-0.7.0-spark2.4-s_2.11.jar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. RDD -> DataFrame -> GraphFrame (code need to be change when add attr)\n",
    "#2. GraphX -> GraphFrame (code no need to change when add attr) encounter problem：https://github.com/graphframes/graphframes/issues/359"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Code part\n",
    "### 7.1 preprepare (libraries part)\n",
    "### 7.1.1 modify the id from \"number\" to \"nodeType:Attr1:id\" (1.edges, 2.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 get answer type from quetion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "import sys\n",
    "from graphframes import *\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "# library \n",
    "sys.path.append(\"project/library\")\n",
    "import get_answer_types_from_questions as gtQType\n",
    "import get_all_subjects_predicates_from_questions as gtQSub\n",
    "from stanfordcorenlp import StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP(r'/Users/jeanxu/PycharmProjects/QUEST_TerminalTest/Code/stanford-corenlp-full-2018-10-05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prune the predicate terms from the query if the query has more than 'prune' number of terms\n",
    "prune=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'when is national day of England '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting potential answer type from question\n",
    "f1='question_type.txt'\n",
    "gtQType.get_answer_type_main(question,f1,nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting query terms from question.\n",
    "s1='question_subject_predicate.txt'\n",
    "gtQSub.get_sub_pred_ques_main(question,s1,nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_list=set()\n",
    "for l in open('auxiliary_verb_list.txt'):\n",
    "    l=l.strip()\n",
    "    aux_list.add(l.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'am',\n",
       " 'are',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'can',\n",
       " 'could',\n",
       " 'dare',\n",
       " 'did',\n",
       " 'do',\n",
       " 'done',\n",
       " 'had',\n",
       " 'has',\n",
       " 'have',\n",
       " 'is',\n",
       " 'may',\n",
       " 'might',\n",
       " 'must',\n",
       " 'need',\n",
       " 'ought',\n",
       " 'shall',\n",
       " 'should',\n",
       " 'was',\n",
       " 'were',\n",
       " 'will',\n",
       " 'would'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read entities of question\n",
    "s11=open(s1, 'r')\n",
    "q_ent = set()\n",
    "type_qent = {}\n",
    "for line in s11:\n",
    "    line = line.strip()\n",
    "    line = line.split()\n",
    "    s = line[0]\n",
    "    for i in range(1, len(line) - 1):\n",
    "        s += ' ' + line[i]\n",
    "    q_ent.add(s.lower())\n",
    "    type_qent[s.lower()] = line[len(line) - 1]\n",
    "if verbose:\n",
    "    print \"Query terms ->\", len(q_ent), q_ent\n",
    "if len(q_ent) > prune:\n",
    "    if verbose:\n",
    "        print \"Pruning..\"\n",
    "    p = frozenset(q_ent)\n",
    "    for s in p:\n",
    "        if type_qent[s] == 'P':\n",
    "            q_ent.remove(s)\n",
    "\n",
    "if verbose:\n",
    "    print \"Without Predicate Query terms ->\", len(q_ent), q_ent\n",
    "\n",
    "p = frozenset(q_ent)\n",
    "for s in p:\n",
    "    if s in aux_list and type_qent[s] == 'P':\n",
    "        q_ent.remove(s)\n",
    "\n",
    "if verbose:\n",
    "    print \"Without Auxiliary Query terms ->\", len(q_ent), q_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'england national day': 'NE', 'is': 'P'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_qent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'england national day'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_ent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. File Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "File_verticesTextRDD = \"/Users/jeanxu/Documents/UniLU/0_MasterThesis/4_Spark/ReferenceFromPaul/Graph-Small/Vertices/part-*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "File_edgesTextRDD = \"/Users/jeanxu/Documents/UniLU/0_MasterThesis/4_Spark/ReferenceFromPaul/Graph-Small/Edges/part-*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "verticesText0 = spark.read.csv(File_verticesTextRDD, header='false', inferSchema='false', sep='\\t')\n",
    "#rdd=sc.textFile(File_verticesTextRDD).map(lambda line : line.split('\\t')).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+---+--------------------+-------------------+------+\n",
      "|     _c0|_c1|_c2|                 _c3|                _c4|   _c5|\n",
      "+--------+---+---+--------------------+-------------------+------+\n",
      "|Sentence|  0|  1|Politics of Burun...|Politics of Burundi| $END$|\n",
      "|Sentence|  1|  2|Executive power i...|Politics of Burundi| $END$|\n",
      "|Sentence|  2|  3|Legislative power...|Politics of Burundi| $END$|\n",
      "|Sentence|  3|  4|The political lan...|Politics of Burundi| $END$|\n",
      "|Sentence|  4|  5|The current Presi...|Politics of Burundi| $END$|\n",
      "|Sentence|  5|  6|Nkurunziza was th...|Politics of Burundi| $END$|\n",
      "|Sentence|  6|  7|In November 1995,...|Politics of Burundi| $END$|\n",
      "|Sentence|  7|  8|In July 1996, for...|Politics of Burundi| $END$|\n",
      "|Sentence|  8|  9|He declared himse...|Politics of Burundi| $END$|\n",
      "|Sentence|  9| 10|Widespread condem...|Politics of Burundi| $END$|\n",
      "+--------+---+---+--------------------+-------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "verticesText0.show(10)\n",
    "# Document：(id, DocumentProperty(title, url, domain, tweets))\n",
    "# Sentence：(id, SentenceProperty(sentenceNumber, sentenceContent, root, links.toList(lenth!=0)))\n",
    "# Clause：  (id, ClauseProperty(clause,clauseType,subject,relation,argument,root,additional.toList))\n",
    "# Mention： (id, MentionProperty(mention, NERtype, entity))\n",
    "# Entity：  (id, EntityProperty(entity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##exmaple:\n",
    "# Document\t5691614\tOffice of the United Nations High Commissioner for Human Rights\t\t\tList() $END$\n",
    "# Document\t5691615\tGecko\t\t\tList() $END$\n",
    "# Document\t5691616\tMaeshowe\t\t\tList() $END$\n",
    "# Document\t5691617\tKiwi\t\t\tList() $END$\n",
    "# Document\t5691618\tIblis\t\t\tList() $END$\n",
    "# Document\t5691619\tNumber\t\t\tList() $END$\n",
    "\n",
    "# Sentence\t0\t1\tPolitics of Burundi takes place in a framework of a transitional presidential representative democratic republic, whereby the President of Burundi is both head of state and head of government, and of a multi-party system.\tPolitics of Burundi\t $END$\n",
    "# Sentence\t1\t2\tExecutive power is exercised by the government.\tPolitics of Burundi\t $END$\n",
    "\n",
    "# Clause\t24971\t(\"This method\", \"was used\", \"by an estimated 38 million couples worldwide\", \"in 1991\")\tSVA\tThis method\twas used\tby an estimated 38 million couples worldwide\tCoitus interruptus-3\tin 1991\t\t $END$\n",
    "# Clause\t24972\t(\"what\", \"was transpiring\", \"quickly\", \"spread and everybody\")\tUNKNOWN\twhat\twas transpiring\tquickly\tFirst Council of Constantinople-36\tspread and everybody\t\t $END$\n",
    "# Clause\t24973\t(\"The news of what was transpiring quickly spread and everybody\", \"rushed\", \"to the church\")\tSVA\tThe news of what was transpiring quickly spread and everybody\trushed\tto the church\tFirst Council of Constantinople-36\t\t $END$\n",
    "\n",
    "# Mention\t24975\tFreedom House\tMISC\tFreedom_House $END$\n",
    "# Mention\t24976\tNGO\tORGANIZATION\tNon-governmental_organization $END$\n",
    "# Mention\t24977\tObiang\tPERSON\tTeodoro_Obiang_Nguema_Mbasogo $END$\n",
    "\n",
    "# Entity\t8593089\tJosephine_of_Leuchtenberg $END$\n",
    "# Entity\t8593090\tPublic_Auditorium $END$\n",
    "# Entity\t8593091\tWest_Plains,_Missouri $END$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./GraphExample.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "verticesText1 = verticesText0.select(\"_c1\",\"_c0\",\"_c2\",\"_c3\",\"_c4\")\\\n",
    ".withColumnRenamed(\"_c0\", \"nodeType\").withColumnRenamed(\"_c1\", \"id\")\\\n",
    ".withColumnRenamed(\"_c2\", \"attr1\").withColumnRenamed(\"_c3\", \"attr2\")\\\n",
    ".withColumnRenamed(\"_c4\", \"attr3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+-------------------+\n",
      "| id|nodeType|attr1|               attr2|              attr3|\n",
      "+---+--------+-----+--------------------+-------------------+\n",
      "|  0|Sentence|    1|Politics of Burun...|Politics of Burundi|\n",
      "|  1|Sentence|    2|Executive power i...|Politics of Burundi|\n",
      "|  2|Sentence|    3|Legislative power...|Politics of Burundi|\n",
      "|  3|Sentence|    4|The political lan...|Politics of Burundi|\n",
      "|  4|Sentence|    5|The current Presi...|Politics of Burundi|\n",
      "|  5|Sentence|    6|Nkurunziza was th...|Politics of Burundi|\n",
      "|  6|Sentence|    7|In November 1995,...|Politics of Burundi|\n",
      "|  7|Sentence|    8|In July 1996, for...|Politics of Burundi|\n",
      "|  8|Sentence|    9|He declared himse...|Politics of Burundi|\n",
      "|  9|Sentence|   10|Widespread condem...|Politics of Burundi|\n",
      "+---+--------+-----+--------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "verticesText1.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 add node attributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd=sc.textFile(File_verticesTextRDD).map(lambda line : line.split('\\t')).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.createOrReplaceTempView(\"vertices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+---+--------------------+-------------------+------+\n",
      "|      _1| _2| _3|                  _4|                 _5|    _6|\n",
      "+--------+---+---+--------------------+-------------------+------+\n",
      "|Sentence|  0|  1|Politics of Burun...|Politics of Burundi| $END$|\n",
      "|Sentence|  1|  2|Executive power i...|Politics of Burundi| $END$|\n",
      "|Sentence|  2|  3|Legislative power...|Politics of Burundi| $END$|\n",
      "|Sentence|  3|  4|The political lan...|Politics of Burundi| $END$|\n",
      "|Sentence|  4|  5|The current Presi...|Politics of Burundi| $END$|\n",
      "|Sentence|  5|  6|Nkurunziza was th...|Politics of Burundi| $END$|\n",
      "|Sentence|  6|  7|In November 1995,...|Politics of Burundi| $END$|\n",
      "|Sentence|  7|  8|In July 1996, for...|Politics of Burundi| $END$|\n",
      "|Sentence|  8|  9|He declared himse...|Politics of Burundi| $END$|\n",
      "|Sentence|  9| 10|Widespread condem...|Politics of Burundi| $END$|\n",
      "|Sentence| 10| 11|Buyoya agreed in ...|Politics of Burundi| $END$|\n",
      "|Sentence| 11| 12|Nonetheless, figh...|Politics of Burundi| $END$|\n",
      "|Sentence| 12| 13|In June 1998, Buy...|Politics of Burundi| $END$|\n",
      "|Sentence| 13| 14|After facilitator...|Politics of Burundi| $END$|\n",
      "|Sentence| 14| 15|Under Mandela the...|Politics of Burundi| $END$|\n",
      "|Sentence| 15| 16|In April 2015 the...|Politics of Burundi| $END$|\n",
      "|Sentence| 16| 17|Protests in the c...|Politics of Burundi| $END$|\n",
      "|Sentence| 17| 18|The president is ...|Politics of Burundi| $END$|\n",
      "|Sentence| 18| 19|He nominates two ...|Politics of Burundi| $END$|\n",
      "|Sentence| 19| 20|The National Asse...|Politics of Burundi| $END$|\n",
      "+--------+---+---+--------------------+-------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+\n",
      "| _1| _2| _3| _4| _5| _6|\n",
      "+---+---+---+---+---+---+\n",
      "+---+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd.filter(\"1 = 'Clause'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesText0 = spark.read.csv(File_edgesTextRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+--------------------+\n",
      "|         _c0|    _c1|                 _c2|\n",
      "+------------+-------+--------------------+\n",
      "|Edge(5691617|7284099|contains the sent...|\n",
      "|Edge(5691617|7284100|contains the sent...|\n",
      "|Edge(5691617|7284101|contains the sent...|\n",
      "|Edge(5691617|7284102|contains the sent...|\n",
      "|Edge(5691617|7284103|contains the sent...|\n",
      "|Edge(5691617|7284104|contains the sent...|\n",
      "|Edge(5691617|7284105|contains the sent...|\n",
      "|Edge(5691617|7284106|contains the sent...|\n",
      "|Edge(5691617|7284107|contains the sent...|\n",
      "|Edge(5691617|7284108|contains the sent...|\n",
      "+------------+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edgesText0.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesText0=edgesText0.select(f.translate(f.col(\"_c0\"), \"Edge(\", \"\").alias(\"src\"), \"_c1\", f.translate(f.col(\"_c2\"), \")\", \"\").alias(\"label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+\n",
      "|    src|    _c1|               label|\n",
      "+-------+-------+--------------------+\n",
      "|5691617|7284099|contains the sent...|\n",
      "|5691617|7284100|contains the sent...|\n",
      "|5691617|7284101|contains the sent...|\n",
      "|5691617|7284102|contains the sent...|\n",
      "|5691617|7284103|contains the sent...|\n",
      "|5691617|7284104|contains the sent...|\n",
      "|5691617|7284105|contains the sent...|\n",
      "|5691617|7284106|contains the sent...|\n",
      "|5691617|7284107|contains the sent...|\n",
      "|5691617|7284108|contains the sent...|\n",
      "|5691617|7284109|contains the sent...|\n",
      "|5691617|7284110|contains the sent...|\n",
      "|5691617|7284111|contains the sent...|\n",
      "|5691617|7284112|contains the sent...|\n",
      "|5691617|7284113|contains the sent...|\n",
      "|5691617|7284114|contains the sent...|\n",
      "|5691617|7284115|contains the sent...|\n",
      "|5691617|7284116|contains the sent...|\n",
      "|5691617|7284117|contains the sent...|\n",
      "|5691617|7284118|contains the sent...|\n",
      "+-------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edgesText0.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesText1 = edgesText0.select(\"*\").withColumnRenamed(\"_c1\", \"dst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+\n",
      "|    src|    dst|               label|\n",
      "+-------+-------+--------------------+\n",
      "|5691617|7284099|contains the sent...|\n",
      "|5691617|7284100|contains the sent...|\n",
      "|5691617|7284101|contains the sent...|\n",
      "|5691617|7284102|contains the sent...|\n",
      "|5691617|7284103|contains the sent...|\n",
      "|5691617|7284104|contains the sent...|\n",
      "|5691617|7284105|contains the sent...|\n",
      "|5691617|7284106|contains the sent...|\n",
      "|5691617|7284107|contains the sent...|\n",
      "|5691617|7284108|contains the sent...|\n",
      "|5691617|7284109|contains the sent...|\n",
      "|5691617|7284110|contains the sent...|\n",
      "|5691617|7284111|contains the sent...|\n",
      "|5691617|7284112|contains the sent...|\n",
      "|5691617|7284113|contains the sent...|\n",
      "|5691617|7284114|contains the sent...|\n",
      "|5691617|7284115|contains the sent...|\n",
      "|5691617|7284116|contains the sent...|\n",
      "|5691617|7284117|contains the sent...|\n",
      "|5691617|7284118|contains the sent...|\n",
      "+-------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edgesText1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edgesText1.join(verticesText1.set_index('id'), on='src')\n",
    "# edgesText1.join(verticesText1, [\"src\"], \"outer\")\n",
    "edgesText2 = edgesText1.join(verticesText1, edgesText1.src == verticesText1.id, \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------------------+---+--------+-----+--------------------+--------------------+\n",
      "|src|    dst|              label| id|nodeType|attr1|               attr2|               attr3|\n",
      "+---+-------+-------------------+---+--------+-----+--------------------+--------------------+\n",
      "|148|1439369|contains the clause|148|Sentence|    5|Athlon comes from...|              Athlon|\n",
      "|148|1439370|contains the clause|148|Sentence|    5|Athlon comes from...|              Athlon|\n",
      "|463|2220614|contains the clause|463|Sentence|   46|By rearrangement ...|Fundamental theor...|\n",
      "|463|2220615|contains the clause|463|Sentence|   46|By rearrangement ...|Fundamental theor...|\n",
      "|463|2220616|contains the clause|463|Sentence|   46|By rearrangement ...|Fundamental theor...|\n",
      "|463|2220617|contains the clause|463|Sentence|   46|By rearrangement ...|Fundamental theor...|\n",
      "|463|2220618|contains the clause|463|Sentence|   46|By rearrangement ...|Fundamental theor...|\n",
      "|463|2220619|contains the clause|463|Sentence|   46|By rearrangement ...|Fundamental theor...|\n",
      "|471|3682886|contains the clause|471|Sentence|   54|This contradictio...|Fundamental theor...|\n",
      "|471|3682887|contains the clause|471|Sentence|   54|This contradictio...|Fundamental theor...|\n",
      "+---+-------+-------------------+---+--------+-----+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edgesText2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------------------+-----+--------------------+\n",
      "|  id|nodeType|               attr1|attr2|               attr3|\n",
      "+----+--------+--------------------+-----+--------------------+\n",
      "|4559|  Clause|(\"A significant c...|  SVA|A significant con...|\n",
      "|4560|  Clause|(\"by the French r...|  SVO|by the French res...|\n",
      "|4561|  Clause|(\"quinine and str...|  SVC|quinine and stryc...|\n",
      "|4562|  Clause|(\"strychnine\", \"i...|  SVC|          strychnine|\n",
      "|4563|  Clause|(\"Some writers\", ...|  SVO|        Some writers|\n",
      "|4564|  Clause|(\"those\", \"would ...|  SVO|               those|\n",
      "|4565|  Clause|(\"The English Cha...|  SVC|The English Chann...|\n",
      "|4566|  Clause|(\"Johnston\", \"res...|  SVO|            Johnston|\n",
      "|4567|  Clause|(\"Tupper\", \"becam...|  SVO|              Tupper|\n",
      "|4568|  Clause|(\"His father\", \"m...|  SVA|          His father|\n",
      "|4569|  Clause|(\"Many physicists...|  SVA|     Many physicists|\n",
      "|4570|  Clause|(\"of quantum mech...|  SVC|of quantum mechanics|\n",
      "|4571|  Clause|(\"The King\", \"app...|  SVO|            The King|\n",
      "|4572|  Clause|(\"the band\", \"spl...|  SVA|            the band|\n",
      "|4573|  Clause|(\"they\", \"had bui...|  SVO|                they|\n",
      "|4574|  Clause|(\"Channel 4\", \"ha...|  SVO|           Channel 4|\n",
      "|4575|  Clause|(\"the same logo\",...|  SVO|       the same logo|\n",
      "|4576|  Clause|(\"Others\", \"agree...| SVOC|              Others|\n",
      "|4577|  Clause|(\"some portion of...|  SVC|some portion of t...|\n",
      "|4578|  Clause|(\"the Kingdom of ...|  SVA|the Kingdom of Judah|\n",
      "+----+--------+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "verticesText1.filter(\"nodeType = 'Clause'\").show()##remember here the  attr3 is not complete, however, this data will not be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Graph & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph = GraphFrame(verticesText1, edgesText1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+\n",
      "|    src|    dst|               label|\n",
      "+-------+-------+--------------------+\n",
      "|5691617|7284099|contains the sent...|\n",
      "|5691617|7284100|contains the sent...|\n",
      "|5691617|7284101|contains the sent...|\n",
      "|5691617|7284102|contains the sent...|\n",
      "|5691617|7284103|contains the sent...|\n",
      "|5691617|7284104|contains the sent...|\n",
      "|5691617|7284105|contains the sent...|\n",
      "|5691617|7284106|contains the sent...|\n",
      "|5691617|7284107|contains the sent...|\n",
      "|5691617|7284108|contains the sent...|\n",
      "+-------+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Graph.edges.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+-------------------+\n",
      "| id|nodeType|attr1|               attr2|              attr3|\n",
      "+---+--------+-----+--------------------+-------------------+\n",
      "|  0|Sentence|    1|Politics of Burun...|Politics of Burundi|\n",
      "|  1|Sentence|    2|Executive power i...|Politics of Burundi|\n",
      "|  2|Sentence|    3|Legislative power...|Politics of Burundi|\n",
      "|  3|Sentence|    4|The political lan...|Politics of Burundi|\n",
      "|  4|Sentence|    5|The current Presi...|Politics of Burundi|\n",
      "|  5|Sentence|    6|Nkurunziza was th...|Politics of Burundi|\n",
      "|  6|Sentence|    7|In November 1995,...|Politics of Burundi|\n",
      "|  7|Sentence|    8|In July 1996, for...|Politics of Burundi|\n",
      "|  8|Sentence|    9|He declared himse...|Politics of Burundi|\n",
      "|  9|Sentence|   10|Widespread condem...|Politics of Burundi|\n",
      "+---+--------+-----+--------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Graph.vertices.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8593092"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graph.vertices.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11607488"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graph.edges.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: bfs Algorithm\n",
    "filteredPaths = Graph.bfs(\n",
    "  fromExpr = \"id = '5691617'\",\n",
    "  toExpr = \"id = '7284108'\",\n",
    "  maxPathLength = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                from|                  e0|                  to|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|[5691617, Documen...|[5691617, 7284108...|[7284108, Sentenc...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display(filteredPaths)\n",
    "filteredPaths.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.13 64-bit ('QUEST': conda)",
   "language": "python",
   "name": "python271364bitquestconda39a3e5c16cfd48579e21bcb7b60777eb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
