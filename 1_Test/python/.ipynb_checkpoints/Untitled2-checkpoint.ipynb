{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Graph\n",
    "# graphframe\n",
    "sc.addPyFile('/usr/local/Cellar/apache-spark/2.4.1/libexec/jars/graphframes-0.7.0-spark2.4-s_2.11.jar')\n",
    "\n",
    "# modules\n",
    "import sys\n",
    "from graphframes import *\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# library \n",
    "sys.path.append(\"/Users/jeanxu/Documents/UniLU/0_MasterThesis/5_Notes/QA_Notes/1_Test/python/project/library\")\n",
    "import get_answer_types_from_questions as gtQType\n",
    "import get_all_subjects_predicates_from_questions as gtQSub\n",
    "from stanfordcorenlp import StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "verbose = 0\n",
    "nlp = StanfordCoreNLP(r'/Users/jeanxu/PycharmProjects/QUEST_TerminalTest/Code/stanford-corenlp-full-2018-10-05')\n",
    "prune = 5\n",
    "question = 'when is national day of England'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting potential answer type from question\n",
    "f1 = 'question_type.txt'\n",
    "gtQType.get_answer_type_main(question,f1,nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting query terms from question.\n",
    "s1 = 'question_subject_predicate.txt'\n",
    "gtQSub.get_sub_pred_ques_main(question,s1,nlp)\n",
    "aux_list = set()\n",
    "for l in open('auxiliary_verb_list.txt'):\n",
    "    l = l.strip()\n",
    "    aux_list.add(l.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read entities of question\n",
    "s11 = open(s1, 'r')\n",
    "q_ent = set()\n",
    "type_qent = {}\n",
    "for line in s11:\n",
    "    line = line.strip()\n",
    "    line = line.split()\n",
    "    s = line[0]\n",
    "    for i in range(1, len(line) - 1):\n",
    "        s += ' ' + line[i]\n",
    "    q_ent.add(s.lower())\n",
    "    type_qent[s.lower()] = line[len(line) - 1]\n",
    "if verbose:\n",
    "    print \"Query terms ->\", len(q_ent), q_ent\n",
    "if len(q_ent) > prune:\n",
    "    if verbose:\n",
    "        print \"Pruning..\"\n",
    "    p = frozenset(q_ent)\n",
    "    for s in p:\n",
    "        if type_qent[s] == 'P':\n",
    "            q_ent.remove(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'england', 'is', 'national day'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'england': 'NE', 'is': 'P', 'national day': 'NE'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_qent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = frozenset(q_ent)\n",
    "for s in p:\n",
    "    if s in aux_list and type_qent[s] == 'P':\n",
    "        q_ent.remove(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'england', 'is', 'national day'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path\n",
    "File_verticesTextRDD = \"/Users/jeanxu/Documents/UniLU/0_MasterThesis/4_Spark/ReferenceFromPaul/Graph-Small/Vertices/part-*\"\n",
    "File_edgesTextRDD = \"/Users/jeanxu/Documents/UniLU/0_MasterThesis/4_Spark/ReferenceFromPaul/Graph-Small/Edges/part-*\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### load vertices\n",
    "verticesText0 = spark.read.csv(File_verticesTextRDD, header='false', inferSchema='false', sep='\\t')\n",
    "\n",
    "verticesText1 = verticesText0.select(\"_c1\",\"_c0\",\"_c2\",\"_c3\",\"_c4\")\\\n",
    ".withColumnRenamed(\"_c0\", \"nodeType\").withColumnRenamed(\"_c1\", \"id\")\\\n",
    ".withColumnRenamed(\"_c2\", \"attr1\").withColumnRenamed(\"_c3\", \"attr2\")\\\n",
    ".withColumnRenamed(\"_c4\", \"attr3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Sample test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction = 0.1\n",
    "# data_sample = data_from_file_conv.sample(False, fraction, 666)\n",
    "smaple_test = verticesText1.sample(False, fraction, 666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "858943"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaple_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8593092"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verticesText1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+-------------------+\n",
      "| id|nodeType|attr1|               attr2|              attr3|\n",
      "+---+--------+-----+--------------------+-------------------+\n",
      "|  0|Sentence|    1|Politics of Burun...|Politics of Burundi|\n",
      "|  8|Sentence|    9|He declared himse...|Politics of Burundi|\n",
      "| 20|Sentence|   21|The Senate (\"SÃ©na...|Politics of Burundi|\n",
      "| 37|Sentence|   12|Explicitly, \"beha...| Abstract data type|\n",
      "| 40|Sentence|   15|An \"interface\" ty...| Abstract data type|\n",
      "| 42|Sentence|   17|An abstract queue...| Abstract data type|\n",
      "| 43|Sentence|   18|There would be no...| Abstract data type|\n",
      "| 54|Sentence|   29|In the philosophy...| Abstract data type|\n",
      "| 55|Sentence|   30|Some operations m...| Abstract data type|\n",
      "| 61|Sentence|   36|In this definitio...| Abstract data type|\n",
      "| 66|Sentence|   41|Note that this de...| Abstract data type|\n",
      "|102|Sentence|   77|In this way, the ...| Abstract data type|\n",
      "|106|Sentence|   81|This gives a grea...| Abstract data type|\n",
      "|139|Sentence|  114|Functional-style ...| Abstract data type|\n",
      "|146|Sentence|    3|It made its debut...|             Athlon|\n",
      "|152|Sentence|    9|The K7 design tea...|             Athlon|\n",
      "|156|Sentence|   13|In August 1999, A...|             Athlon|\n",
      "|168|Sentence|   25|This means that a...|             Athlon|\n",
      "|172|Sentence|   29|Deeper pipelining...|             Athlon|\n",
      "|178|Sentence|   35|While the K6 FPU ...|             Athlon|\n",
      "+---+--------+-----+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smaple_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+-------------------+\n",
      "| id|nodeType|attr1|               attr2|              attr3|\n",
      "+---+--------+-----+--------------------+-------------------+\n",
      "|  0|Sentence|    1|Politics of Burun...|Politics of Burundi|\n",
      "|  1|Sentence|    2|Executive power i...|Politics of Burundi|\n",
      "|  2|Sentence|    3|Legislative power...|Politics of Burundi|\n",
      "|  3|Sentence|    4|The political lan...|Politics of Burundi|\n",
      "|  4|Sentence|    5|The current Presi...|Politics of Burundi|\n",
      "|  5|Sentence|    6|Nkurunziza was th...|Politics of Burundi|\n",
      "|  6|Sentence|    7|In November 1995,...|Politics of Burundi|\n",
      "|  7|Sentence|    8|In July 1996, for...|Politics of Burundi|\n",
      "|  8|Sentence|    9|He declared himse...|Politics of Burundi|\n",
      "|  9|Sentence|   10|Widespread condem...|Politics of Burundi|\n",
      "| 10|Sentence|   11|Buyoya agreed in ...|Politics of Burundi|\n",
      "| 11|Sentence|   12|Nonetheless, figh...|Politics of Burundi|\n",
      "| 12|Sentence|   13|In June 1998, Buy...|Politics of Burundi|\n",
      "| 13|Sentence|   14|After facilitator...|Politics of Burundi|\n",
      "| 14|Sentence|   15|Under Mandela the...|Politics of Burundi|\n",
      "| 15|Sentence|   16|In April 2015 the...|Politics of Burundi|\n",
      "| 16|Sentence|   17|Protests in the c...|Politics of Burundi|\n",
      "| 17|Sentence|   18|The president is ...|Politics of Burundi|\n",
      "| 18|Sentence|   19|He nominates two ...|Politics of Burundi|\n",
      "| 19|Sentence|   20|The National Asse...|Politics of Burundi|\n",
      "+---+--------+-----+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "verticesText1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### load edges\n",
    "edgesText0 = spark.read.csv(File_edgesTextRDD)\n",
    "edgesText0 = edgesText0.select(f.translate(f.col(\"_c0\"), \"Edge(\", \"\").alias(\"src\"), \"_c1\", f.translate(f.col(\"_c2\"), \")\", \"\").alias(\"label\"))\n",
    "edgesText1 = edgesText0.select(\"*\").withColumnRenamed(\"_c1\", \"dst\")\n",
    "verticesText1J = verticesText1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+-------------------+\n",
      "| id|nodeType|attr1|               attr2|              attr3|\n",
      "+---+--------+-----+--------------------+-------------------+\n",
      "|  0|Sentence|    1|Politics of Burun...|Politics of Burundi|\n",
      "|  1|Sentence|    2|Executive power i...|Politics of Burundi|\n",
      "|  2|Sentence|    3|Legislative power...|Politics of Burundi|\n",
      "|  3|Sentence|    4|The political lan...|Politics of Burundi|\n",
      "|  4|Sentence|    5|The current Presi...|Politics of Burundi|\n",
      "|  5|Sentence|    6|Nkurunziza was th...|Politics of Burundi|\n",
      "|  6|Sentence|    7|In November 1995,...|Politics of Burundi|\n",
      "|  7|Sentence|    8|In July 1996, for...|Politics of Burundi|\n",
      "|  8|Sentence|    9|He declared himse...|Politics of Burundi|\n",
      "|  9|Sentence|   10|Widespread condem...|Politics of Burundi|\n",
      "| 10|Sentence|   11|Buyoya agreed in ...|Politics of Burundi|\n",
      "| 11|Sentence|   12|Nonetheless, figh...|Politics of Burundi|\n",
      "| 12|Sentence|   13|In June 1998, Buy...|Politics of Burundi|\n",
      "| 13|Sentence|   14|After facilitator...|Politics of Burundi|\n",
      "| 14|Sentence|   15|Under Mandela the...|Politics of Burundi|\n",
      "| 15|Sentence|   16|In April 2015 the...|Politics of Burundi|\n",
      "| 16|Sentence|   17|Protests in the c...|Politics of Burundi|\n",
      "| 17|Sentence|   18|The president is ...|Politics of Burundi|\n",
      "| 18|Sentence|   19|He nominates two ...|Politics of Burundi|\n",
      "| 19|Sentence|   20|The National Asse...|Politics of Burundi|\n",
      "+---+--------+-----+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "verticesText1J.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesText2 = edgesText1.join(verticesText1.select(\"id\",\"nodeType\"), edgesText1.src == verticesText1.select(\"id\",\"nodeType\").id, \"inner\")\n",
    "edgesText2 = edgesText2.withColumnRenamed(\"id\", \"src_id\").withColumnRenamed(\"nodeType\", \"src_nodeType\")\n",
    "edgesText3 = edgesText2.join(verticesText1.select(\"id\",\"nodeType\"), edgesText2.dst == verticesText1.select(\"id\",\"nodeType\").id, \"inner\")\n",
    "edgesText3 = edgesText3.withColumnRenamed(\"id\", \"dst_id\").withColumnRenamed(\"nodeType\", \"dst_nodeType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------------------+-------+------------+-------+------------+\n",
      "|    src|    dst|              label| src_id|src_nodeType| dst_id|dst_nodeType|\n",
      "+-------+-------+-------------------+-------+------------+-------+------------+\n",
      "|1234113| 100010|contains the clause|1234113|    Sentence| 100010|      Clause|\n",
      "|3875588|1000240|contains the clause|3875588|    Sentence|1000240|      Clause|\n",
      "|3650624|1000280|contains the clause|3650624|    Sentence|1000280|      Clause|\n",
      "|2068926|1000665|contains the clause|2068926|    Sentence|1000665|      Clause|\n",
      "| 467648|1000795|contains the clause| 467648|    Sentence|1000795|      Clause|\n",
      "| 233944|1000839|contains the clause| 233944|    Sentence|1000839|      Clause|\n",
      "|4022932|1000888|contains the clause|4022932|    Sentence|1000888|      Clause|\n",
      "|1212133| 100140|contains the clause|1212133|    Sentence| 100140|      Clause|\n",
      "| 452611|1001866|contains the clause| 452611|    Sentence|1001866|      Clause|\n",
      "|1487892|1002011|contains the clause|1487892|    Sentence|1002011|      Clause|\n",
      "|1525764|1002185|contains the clause|1525764|    Sentence|1002185|      Clause|\n",
      "|1455756| 100227|contains the clause|1455756|    Sentence| 100227|      Clause|\n",
      "|2791683|1002442|contains the clause|2791683|    Sentence|1002442|      Clause|\n",
      "|2753656| 100263|contains the clause|2753656|    Sentence| 100263|      Clause|\n",
      "|3182725|1002783|contains the clause|3182725|    Sentence|1002783|      Clause|\n",
      "|1212312|1002883|contains the clause|1212312|    Sentence|1002883|      Clause|\n",
      "|1212752|1002887|contains the clause|1212752|    Sentence|1002887|      Clause|\n",
      "|3082848| 100320|contains the clause|3082848|    Sentence| 100320|      Clause|\n",
      "|3036946|1003202|contains the clause|3036946|    Sentence|1003202|      Clause|\n",
      "|3486666|1003366|contains the clause|3486666|    Sentence|1003366|      Clause|\n",
      "+-------+-------+-------------------+-------+------------+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edgesText3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### documnet vertice & edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### documnets---attributes\n",
    "doc_verticesText = verticesText1.filter(\"nodeType = 'Document'\")\n",
    "doc_verticesText = doc_verticesText.withColumn(\"did\", doc_verticesText.id).withColumn(\"dtitle\", doc_verticesText.attr1).drop(\"attr1\").drop(\"attr2\").drop(\"attr3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----+--------------------+\n",
      "|  id|nodeType| did|              dtitle|\n",
      "+----+--------+----+--------------------+\n",
      "|4526|Document|4526|     Africa Alphabet|\n",
      "|4527|Document|4527|               Brain|\n",
      "|4528|Document|4528|     Andreas Aagesen|\n",
      "|4529|Document|4529|Australian Broadc...|\n",
      "|4530|Document|4530|The Elephant 6 Re...|\n",
      "|4531|Document|4531|Albert of Branden...|\n",
      "|4532|Document|4532|Telecommunication...|\n",
      "|4533|Document|4533|                 DMA|\n",
      "|4534|Document|4534|         Alford plea|\n",
      "|4535|Document|4535|        Claude Piron|\n",
      "|4536|Document|4536|Full disclosure (...|\n",
      "|4537|Document|4537|    Anthem of Europe|\n",
      "|4538|Document|4538|             Cytosol|\n",
      "|4539|Document|4539|            Barbagia|\n",
      "|4540|Document|4540|             Calcium|\n",
      "|4541|Document|4541|   Chomsky hierarchy|\n",
      "|4542|Document|4542| Critical philosophy|\n",
      "|4543|Document|4543|   Cultural movement|\n",
      "|4544|Document|4544|          Braveheart|\n",
      "|4545|Document|4545|                Bill|\n",
      "+----+--------+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_verticesText.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sentence---attributes\n",
    "# sen_verticesText = verticesText1.filter(\"nodeType = 'Sentence'\")\n",
    "sen_edges = edgesText3.filter(\"label = 'contains the sentence'\")\n",
    "sen_verticesTextJ_test = verticesText1.filter(\"nodeType = 'Sentence'\")\n",
    "sen_edgesJ = sen_edges.select(\"src_id\",\"src_nodeType\",\"dst_id\",\"dst_nodeType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+-------+------------+\n",
      "|src_id|src_nodeType| dst_id|dst_nodeType|\n",
      "+------+------------+-------+------------+\n",
      "|626404|    Document|1014942|    Sentence|\n",
      "|626407|    Document|1015263|    Sentence|\n",
      "|626411|    Document|1015551|    Sentence|\n",
      "|626411|    Document|1015552|    Sentence|\n",
      "|626411|    Document|1015610|    Sentence|\n",
      "|626413|    Document|1015827|    Sentence|\n",
      "|626414|    Document|1015968|    Sentence|\n",
      "|626417|    Document|1016299|    Sentence|\n",
      "|626417|    Document|1016518|    Sentence|\n",
      "|626417|    Document|1016816|    Sentence|\n",
      "|626418|    Document|1017045|    Sentence|\n",
      "|626418|    Document|1017074|    Sentence|\n",
      "|626419|    Document|1017462|    Sentence|\n",
      "|626421|    Document|1017551|    Sentence|\n",
      "|626422|    Document|1017716|    Sentence|\n",
      "|626422|    Document|1017805|    Sentence|\n",
      "|626422|    Document|1017849|    Sentence|\n",
      "|626422|    Document|1018090|    Sentence|\n",
      "|626422|    Document|1018100|    Sentence|\n",
      "|626392|    Document|1018247|    Sentence|\n",
      "+------+------------+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sen_edgesJ.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conbine src_id\n",
    "sen_edgesJ_test1 = sen_edgesJ.join(doc_verticesText, sen_edgesJ.src_id==doc_verticesText.id,\"inner\")\n",
    "sen_edgesJ_test1 = sen_edgesJ_test1.drop(\"id\").drop(\"nodeType\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-------+------------+-------+--------------+\n",
      "| src_id|src_nodeType| dst_id|dst_nodeType|    did|        dtitle|\n",
      "+-------+------------+-------+------------+-------+--------------+\n",
      "|1019881|    Document|3245237|    Sentence|1019881|Emperor Ninken|\n",
      "|1019881|    Document|3245224|    Sentence|1019881|Emperor Ninken|\n",
      "|1019881|    Document|3245236|    Sentence|1019881|Emperor Ninken|\n",
      "|1019881|    Document|3245232|    Sentence|1019881|Emperor Ninken|\n",
      "|1019881|    Document|3245222|    Sentence|1019881|Emperor Ninken|\n",
      "|1019881|    Document|3245228|    Sentence|1019881|Emperor Ninken|\n",
      "|1019881|    Document|3245238|    Sentence|1019881|Emperor Ninken|\n",
      "|1019881|    Document|3245239|    Sentence|1019881|Emperor Ninken|\n",
      "|1019881|    Document|3245223|    Sentence|1019881|Emperor Ninken|\n",
      "|1019881|    Document|3245229|    Sentence|1019881|Emperor Ninken|\n",
      "|1019881|    Document|3245231|    Sentence|1019881|Emperor Ninken|\n",
      "|1019881|    Document|3245225|    Sentence|1019881|Emperor Ninken|\n",
      "|1019881|    Document|3245235|    Sentence|1019881|Emperor Ninken|\n",
      "|1019881|    Document|3245230|    Sentence|1019881|Emperor Ninken|\n",
      "|1019881|    Document|3245227|    Sentence|1019881|Emperor Ninken|\n",
      "|1019881|    Document|3245234|    Sentence|1019881|Emperor Ninken|\n",
      "|1019881|    Document|3245221|    Sentence|1019881|Emperor Ninken|\n",
      "|1019881|    Document|3245233|    Sentence|1019881|Emperor Ninken|\n",
      "|1019881|    Document|3245226|    Sentence|1019881|Emperor Ninken|\n",
      "|1019881|    Document|3245220|    Sentence|1019881|Emperor Ninken|\n",
      "+-------+------------+-------+------------+-------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sen_edgesJ_test1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conbine dst_id\n",
    "sen_verticesTextJ_test1 = sen_edgesJ_test1.join(sen_verticesTextJ_test,sen_edgesJ_test1.dst_id==sen_verticesTextJ_test.id,\"inner\")\n",
    "sen_verticesTextJ_test2 = sen_verticesTextJ_test1.drop(\"attr2\").drop(\"attr3\")\n",
    "sen_verticesText = sen_verticesTextJ_test2.drop(\"src_id\").drop(\"src_nodeType\").drop(\"dst_id\").drop(\"dst_nodeType\")\n",
    "sen_verticesText = sen_verticesText.withColumnRenamed(\"attr1\",\"sid\")\n",
    "sen_verticesText = sen_verticesText.select(\"id\",\"nodeType\",\"did\",\"dtitle\",\"sid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+--------------------+---+\n",
      "|     id|nodeType|   did|              dtitle|sid|\n",
      "+-------+--------+------+--------------------+---+\n",
      "|1014942|Sentence|626404|              Genome|102|\n",
      "|1015263|Sentence|626407|             Alcohol| 99|\n",
      "|1015551|Sentence|626411|             Cartoon|  5|\n",
      "|1015552|Sentence|626411|             Cartoon|  6|\n",
      "|1015610|Sentence|626411|             Cartoon| 64|\n",
      "|1015827|Sentence|626413|Charlton Athletic...|190|\n",
      "|1015968|Sentence|626414|          Battleship|135|\n",
      "|1016299|Sentence|626417|          Bangladesh| 93|\n",
      "|1016518|Sentence|626417|          Bangladesh|312|\n",
      "|1016816|Sentence|626417|          Bangladesh|610|\n",
      "|1017045|Sentence|626418|               Ghost| 40|\n",
      "|1017074|Sentence|626418|               Ghost| 69|\n",
      "|1017462|Sentence|626419|United States For...|133|\n",
      "|1017551|Sentence|626421|         Amoxicillin| 38|\n",
      "|1017716|Sentence|626422|         El Salvador|112|\n",
      "|1017805|Sentence|626422|         El Salvador|201|\n",
      "|1017849|Sentence|626422|         El Salvador|245|\n",
      "|1018090|Sentence|626422|         El Salvador|486|\n",
      "|1018100|Sentence|626422|         El Salvador|496|\n",
      "|1018247|Sentence|626392|Brouwer fixed-poi...| 16|\n",
      "+-------+--------+------+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sen_verticesText.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### clause---attributes\n",
    "clause_verticesText_test = verticesText1.filter(\"nodeType = 'Clause'\")\n",
    "clause_edges = edgesText3.filter(\"label = 'contains the clause'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dst_id\n",
    "clause_verticesTextJ_test = clause_verticesText_test.join(clause_edges.select(\"src_id\",\"src_nodeType\",\"dst_id\",\"dst_nodeType\"), clause_verticesText_test.id==clause_edges.dst_id, \"inner\")\n",
    "clause_verticesTextJ_test = clause_verticesTextJ_test.drop(\"src_nodeType\").drop(\"dst_id\").drop(\"dst_nodeType\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------------+-----+--------------------+-------+\n",
      "|     id|nodeType|               attr1|attr2|               attr3| src_id|\n",
      "+-------+--------+--------------------+-----+--------------------+-------+\n",
      "| 100010|  Clause|(\"Kerensky\", \"ord...|  SVO|            Kerensky|1234113|\n",
      "|1000240|  Clause|(\"to the paternal...|  SVC|to the paternal h...|3875588|\n",
      "|1000280|  Clause|(\"roughly speakin...|  SVO|roughly speaking ...|3650624|\n",
      "|1000665|  Clause|(\"sympatric speci...|  SVC|sympatric speciation|2068926|\n",
      "|1000795|  Clause|(\"The growth of t...|  SVO|The growth of the...| 467648|\n",
      "|1000839|  Clause|(\"the priests\", \"...|  SVA|         the priests| 233944|\n",
      "|1000888|  Clause|(\"the absolute va...|  SVC|  the absolute value|4022932|\n",
      "| 100140|  Clause|(\"A memorial plaq...|  SVA|   A memorial plaque|1212133|\n",
      "|1001866|  Clause|(\"1QDan\", \"is\", \"...|  SVC|               1QDan| 452611|\n",
      "|1002011|  Clause|(\"the use of Afri...|  SVC|the use of Africa...|1487892|\n",
      "|1002185|  Clause|(\"he\", \"won\", \"th...|  SVO|                  he|1525764|\n",
      "| 100227|  Clause|(\"The following y...|  SVC|  The following year|1455756|\n",
      "|1002442|  Clause|(\"Beetles\", \"are\"...|  SVC|             Beetles|2791683|\n",
      "| 100263|  Clause|(\"it\", \"changes\",...|  SVO|                  it|2753656|\n",
      "|1002783|  Clause|(\"Disraeli\", \"hop...|  SVA|            Disraeli|3182725|\n",
      "|1002883|  Clause|(\"they\", \"reject\"...|  SVO|                they|1212312|\n",
      "|1002887|  Clause|(\"The result\", \"w...|  SVC|          The result|1212752|\n",
      "| 100320|  Clause|(\"chicks\", \"fledg...|  SVO|              chicks|3082848|\n",
      "|1003202|  Clause|(\"of stable indiv...|  SVC|of stable indivis...|3036946|\n",
      "|1003366|  Clause|(\"they\", \"emphasi...|  SVO|                they|3486666|\n",
      "+-------+--------+--------------------+-----+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clause_verticesTextJ_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_verticesTextJ=sen_verticesText.withColumnRenamed(\"id\",\"senid\")##important, need to keep different column name with others when \"JOIN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine src_id\n",
    "clause_verticesText_test1 = clause_verticesTextJ_test.join(sen_verticesTextJ.select(\"senid\",\"did\",\"dtitle\",\"sid\"), clause_verticesTextJ_test.src_id==sen_verticesTextJ.senid, \"inner\")\n",
    "clause_verticesText_test2 = clause_verticesText_test1.drop(\"attr2\").drop(\"attr3\").drop(\"src_id\").drop(\"sen_id\")\n",
    "clause_verticesText = clause_verticesText_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------------+-------+------+--------------------+---+\n",
      "|     id|nodeType|               attr1|  senid|   did|              dtitle|sid|\n",
      "+-------+--------+--------------------+-------+------+--------------------+---+\n",
      "|2911087|  Clause|(\"Both the proces...|1014942|626404|              Genome|102|\n",
      "|1732278|  Clause|(\"alcohols\", \"are...|1015263|626407|             Alcohol| 99|\n",
      "|3236586|  Clause|(\"cartoon\", \"came...|1015551|626411|             Cartoon|  5|\n",
      "|3493546|  Clause|(\"to animated fil...|1015552|626411|             Cartoon|  6|\n",
      "|3493545|  Clause|(\"it\", \"began\", \"...|1015552|626411|             Cartoon|  6|\n",
      "|3327830|  Clause|(\"Thomson\", \"capi...|1015610|626411|             Cartoon| 64|\n",
      "|1230382|  Clause|(\"The ground-shar...|1015827|626413|Charlton Athletic...|190|\n",
      "|2658479|  Clause|(\"the Austro-Hung...|1015968|626414|          Battleship|135|\n",
      "|2658478|  Clause|(\"The Adriatic\", ...|1015968|626414|          Battleship|135|\n",
      "| 276441|  Clause|(\"British rule\", ...|1016299|626417|          Bangladesh| 93|\n",
      "| 276440|  Clause|(\"Several rebelli...|1016299|626417|          Bangladesh| 93|\n",
      "| 464234|  Clause|(\"The Bangladesh ...|1016518|626417|          Bangladesh|312|\n",
      "| 427430|  Clause|(\"Ivory and brass...|1016816|626417|          Bangladesh|610|\n",
      "| 386149|  Clause| (\"the one\", \"died\")|1017045|626418|               Ghost| 40|\n",
      "| 386148|  Clause|(\"the ghost or sp...|1017045|626418|               Ghost| 40|\n",
      "| 386147|  Clause|(\"Some people\", \"...|1017045|626418|               Ghost| 40|\n",
      "|3457439|  Clause|(\"Supernatural ac...|1017074|626418|               Ghost| 69|\n",
      "|1880973|  Clause|(\"the Act\", \"woul...|1017462|626419|United States For...|133|\n",
      "|1880971|  Clause|(\"Rulings for the...|1017462|626419|United States For...|133|\n",
      "|1880972|  Clause|(\"the government\"...|1017462|626419|United States For...|133|\n",
      "+-------+--------+--------------------+-------+------+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clause_verticesText.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change clause to predicate\n",
    "clause_verticesText1 = clause_verticesText.withColumn(\"attr1\", f.split(clause_verticesText['attr1'], \",\"))\n",
    "predicate_verticesText = clause_verticesText.withColumn(\"predicate\", f.split(\"attr1\", \",\")[1])\n",
    "predicate_verticesText1 = predicate_verticesText.select(\"*\", f.translate(f.col(\"predicate\"), \"[\\\"()]\", \"\").alias(\"predicate1\"))\n",
    "predicate_verticesText2 = predicate_verticesText1.withColumn(\"nodeType1\",f.lit(\"Predicate\"))\n",
    "predicate_verticesText = predicate_verticesText2.select(\"id\",\"nodeType1\",\"did\",\"dtitle\",\"sid\",\"predicate1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_verticesText=predicate_verticesText.withColumnRenamed(\"nodeType1\",\"nodeType\").withColumnRenamed(\"predicate1\",\"predicate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+--------------------+---+-----------------+\n",
      "|     id| nodeType|   did|              dtitle|sid|        predicate|\n",
      "+-------+---------+------+--------------------+---+-----------------+\n",
      "|2911087|Predicate|626404|              Genome|102|       can result|\n",
      "|1732278|Predicate|626407|             Alcohol| 99|              are|\n",
      "|3236586|Predicate|626411|             Cartoon|  5|             came|\n",
      "|3493546|Predicate|626411|             Cartoon|  6|        resembled|\n",
      "|3493545|Predicate|626411|             Cartoon|  6|            began|\n",
      "|3327830|Predicate|626411|             Cartoon| 64|      capitalized|\n",
      "|1230382|Predicate|626413|Charlton Athletic...|190|              was|\n",
      "|2658479|Predicate|626414|          Battleship|135|         remained|\n",
      "|2658478|Predicate|626414|          Battleship|135|              was|\n",
      "| 276441|Predicate|626417|          Bangladesh| 93|        displaced|\n",
      "| 276440|Predicate|626417|          Bangladesh| 93|        broke out|\n",
      "| 464234|Predicate|626417|          Bangladesh|312|      was enacted|\n",
      "| 427430|Predicate|626417|          Bangladesh|610|        were used|\n",
      "| 386149|Predicate|626418|               Ghost| 40|             died|\n",
      "| 386148|Predicate|626418|               Ghost| 40|     never leaves|\n",
      "| 386147|Predicate|626418|               Ghost| 40|          believe|\n",
      "|3457439|Predicate|626418|               Ghost| 69|          is said|\n",
      "|1880973|Predicate|626419|United States For...|133| would be amended|\n",
      "|1880971|Predicate|626419|United States For...|133|         prompted|\n",
      "|1880972|Predicate|626419|United States For...|133|  had overreached|\n",
      "+-------+---------+------+--------------------+---+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicate_verticesText.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### mention---mention edges\n",
    "entity_edges = edgesText3.filter(\"label = 'is disambiguated as'\")\n",
    "NewMentionEdges = entity_edges.groupBy(\"dst_id\").agg(f.collect_list('src_id').alias('NewMentionEdges'))\n",
    "NewMentionEdges = NewMentionEdges.withColumnRenamed(\"NewMentionEdges\",\"Mention\")\n",
    "NewMentionEdges = NewMentionEdges.select(\"Mention\")\n",
    "NewMentionEdges = NewMentionEdges.withColumn(\"Mention1\",NewMentionEdges.Mention)\n",
    "NewMentionEdgesJ = NewMentionEdges.withColumn(\"Mention1\", f.explode(\"Mention1\"))\n",
    "\n",
    "NewMentionEdgesJ1 = NewMentionEdgesJ.withColumn(\"Mention\", f.explode(\"Mention\"))\n",
    "NewMentionEdgesJ2 = NewMentionEdgesJ1.filter(NewMentionEdgesJ1.Mention!=NewMentionEdgesJ1.Mention1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|Mention|Mention1|\n",
      "+-------+--------+\n",
      "|4417364| 4417352|\n",
      "|4417356| 4417352|\n",
      "|7915519| 4417352|\n",
      "|7171576| 4417352|\n",
      "|7171574| 4417352|\n",
      "|4417352| 4417364|\n",
      "|4417356| 4417364|\n",
      "|7915519| 4417364|\n",
      "|7171576| 4417364|\n",
      "|7171574| 4417364|\n",
      "|4417352| 4417356|\n",
      "|4417364| 4417356|\n",
      "|7915519| 4417356|\n",
      "|7171576| 4417356|\n",
      "|7171574| 4417356|\n",
      "|4417352| 7915519|\n",
      "|4417364| 7915519|\n",
      "|4417356| 7915519|\n",
      "|7171576| 7915519|\n",
      "|7171574| 7915519|\n",
      "+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NewMentionEdgesJ2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "##add type node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_verticesText_test=verticesText1.filter(\"nodeType = 'Sentence'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_Type_verticesText_test=sen_verticesText_test.select(\"attr2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               attr2|\n",
      "+--------------------+\n",
      "|Politics of Burun...|\n",
      "|Executive power i...|\n",
      "|Legislative power...|\n",
      "|The political lan...|\n",
      "|The current Presi...|\n",
      "|Nkurunziza was th...|\n",
      "|In November 1995,...|\n",
      "|In July 1996, for...|\n",
      "|He declared himse...|\n",
      "|Widespread condem...|\n",
      "|Buyoya agreed in ...|\n",
      "|Nonetheless, figh...|\n",
      "|In June 1998, Buy...|\n",
      "|After facilitator...|\n",
      "|Under Mandela the...|\n",
      "|In April 2015 the...|\n",
      "|Protests in the c...|\n",
      "|The president is ...|\n",
      "|He nominates two ...|\n",
      "|The National Asse...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sen_Type_verticesText_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_symbols(s):\n",
    "\ts=s.replace('(',' ')\n",
    "\ts=s.replace(')',' ')\n",
    "\ts=s.replace('[',' ')\n",
    "\ts=s.replace(']',' ')\n",
    "\ts=s.replace('{',' ')\n",
    "\ts=s.replace('}',' ')\n",
    "\ts=s.replace('|',' ')\n",
    "\ts=s.replace('\"',' ')\n",
    "\ts=s.strip()\n",
    "\treturn s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceS_udf=udf(replace_symbols,StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_Type_verticesText_test1 = sen_Type_verticesText_test.select(\"attr2\",replaceS_udf(sen_Type_verticesText_test[\"attr2\"]).alias(\"RS\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_Type_verticesText_test1 = sen_Type_verticesText_test.withColumn(\"RPS\",replaceS_udf(sen_Type_verticesText_test[\"attr2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sen_Type_verticesText_test1 =sen_Type_verticesText_test.select(gtQSub.replace_symbols(\"attr2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               attr2|                 RPS|\n",
      "+--------------------+--------------------+\n",
      "|Politics of Burun...|Politics of Burun...|\n",
      "|Executive power i...|Executive power i...|\n",
      "|Legislative power...|Legislative power...|\n",
      "|The political lan...|The political lan...|\n",
      "|The current Presi...|The current Presi...|\n",
      "|Nkurunziza was th...|Nkurunziza was th...|\n",
      "|In November 1995,...|In November 1995,...|\n",
      "|In July 1996, for...|In July 1996, for...|\n",
      "|He declared himse...|He declared himse...|\n",
      "|Widespread condem...|Widespread condem...|\n",
      "|Buyoya agreed in ...|Buyoya agreed in ...|\n",
      "|Nonetheless, figh...|Nonetheless, figh...|\n",
      "|In June 1998, Buy...|In June 1998, Buy...|\n",
      "|After facilitator...|After facilitator...|\n",
      "|Under Mandela the...|Under Mandela the...|\n",
      "|In April 2015 the...|In April 2015 the...|\n",
      "|Protests in the c...|Protests in the c...|\n",
      "|The president is ...|The president is ...|\n",
      "|He nominates two ...|He nominates two ...|\n",
      "|The National Asse...|The National Asse...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sen_Type_verticesText_test1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_Type_verticesText_test1=sen_Type_verticesText_test1.drop(\"attr2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.addPyFile('/Users/jeanxu/Documents/UniLU/0_MasterThesis/5_Notes/QA_Notes/1_Test/python/project/library/hearstPatterns.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hearstPatterns as hP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h = hP.HearstPatterns(extended=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test find_hyponyms\n",
    "# h.find_hyponyms(\"Forty-four percent of patients with uveitis had one or more identifiable signs or symptoms, such as red eye, ocular pain, visual acuity, or photophobia, in order of decreasing frequency.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hearstPatterns import HearstPatterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h=HearstPatterns(extended=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test find_hyponyms\n",
    "# x=h.find_hyponyms(\"Forty-four percent of patients with uveitis had one or more identifiable signs or symptoms, such as red eye, ocular pain, visual acuity, or photophobia, in order of decreasing frequency.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test use pandas\n",
    "# sen_Type_verticesText_test2[\"RPS\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sen_Type_verticesText_test2[\"RPS\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h.find_hyponyms(sen_Type_verticesText_test2[\"RPS\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost a lot of time give up\n",
    "# sen_Type_verticesText_test2=sen_Type_verticesText_test1.toPandas()\n",
    "# HP = set()\n",
    "# for i in range(sen_Type_verticesText_test2[\"RPS\"].count()):\n",
    "#     HP1 = set(h.find_hyponyms(sen_Type_verticesText_test2[\"RPS\"][i]))#\n",
    "#     HP = HP.union(HP1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "\n",
    "class HearstPatterns(object):\n",
    "\n",
    "    def __init__(self, extended = False):\n",
    "        self.__chunk_patterns = r\"\"\" #  helps us find noun phrase chunks\n",
    "                NP: {<DT|PP\\$>?<JJ>*<NN>+}\n",
    "                    {<NNP>+}\n",
    "                    {<NNS>+}\n",
    "        \"\"\"\n",
    "\n",
    "        self.__np_chunker = nltk.RegexpParser(self.__chunk_patterns) # create a chunk parser \n",
    "\n",
    "        # now define the Hearst patterns\n",
    "        # format is <hearst-pattern>, <general-term>\n",
    "        # so, what this means is that if you apply the first pattern, the firsr Noun Phrase (NP)\n",
    "        # is the general one, and the rest are specific NPs\n",
    "        self.__hearst_patterns = [\n",
    "                (\"(NP_\\w+ (, )?such as (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"(such NP_\\w+ (, )?as (NP_\\w+ ?(, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?other NP_\\w+)\", \"last\"),\n",
    "                (\"(NP_\\w+ (, )?including (NP_\\w+ ?(, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"(NP_\\w+ (, )?especially (NP_\\w+ ?(, )?(and |or )?)+)\", \"first\"),\n",
    "            ]\n",
    "\n",
    "        if extended:\n",
    "            self.__hearst_patterns.extend([\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?any other NP_\\w+)\", \"last\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?some other NP_\\w+)\", \"last\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?is a NP_\\w+)\", \"last\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?was a NP_\\w+)\", \"last\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?were a NP_\\w+)\", \"last\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?are a NP_\\w+)\", \"last\"),\n",
    "                (\"(NP_\\w+ (, )?like (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"such (NP_\\w+ (, )?as (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?like other NP_\\w+)\", \"last\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?one of the NP_\\w+)\", \"last\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?one of these NP_\\w+)\", \"last\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?one of those NP_\\w+)\", \"last\"),\n",
    "                (\"examples of (NP_\\w+ (, )?is (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"examples of (NP_\\w+ (, )?are (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?are examples of NP_\\w+)\", \"last\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?is example of NP_\\w+)\", \"last\"),\n",
    "                (\"(NP_\\w+ (, )?for example (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?wich is called NP_\\w+)\", \"last\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?which is named NP_\\w+)\", \"last\"),\n",
    "                (\"(NP_\\w+ (, )?mainly (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"(NP_\\w+ (, )?mostly (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"(NP_\\w+ (, )?notably (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"(NP_\\w+ (, )?particularly (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"(NP_\\w+ (, )?principally (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"(NP_\\w+ (, )?in particular (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"(NP_\\w+ (, )?except (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"(NP_\\w+ (, )?other than (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"(NP_\\w+ (, )?e.g. (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"(NP_\\w+ (, )?i.e. (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?a kind of NP_\\w+)\", \"last\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?kinds of NP_\\w+)\", \"last\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?form of NP_\\w+)\", \"last\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?forms of NP_\\w+)\", \"last\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?which looks like NP_\\w+)\", \"last\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?which sounds like NP_\\w+)\", \"last\"),\n",
    "                (\"(NP_\\w+ (, )?which are similar to (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"(NP_\\w+ (, )?which is similar to (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"(NP_\\w+ (, )?examples of this is (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"(NP_\\w+ (, )?examples of this are (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"(NP_\\w+ (, )?types (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )? NP_\\w+ types)\", \"last\"),\n",
    "                (\"(NP_\\w+ (, )?whether (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"(compare (NP_\\w+ ?(, )?)+(and |or )?with NP_\\w+)\", \"last\"),\n",
    "                (\"(NP_\\w+ (, )?compared to (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"(NP_\\w+ (, )?among them (NP_\\w+ ? (, )?(and |or )?)+)\", \"first\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?as NP_\\w+)\", \"last\"),\n",
    "                (\"(NP_\\w+ (, )? (NP_\\w+ ? (, )?(and |or )?)+ for instance)\", \"first\"),\n",
    "                (\"((NP_\\w+ ?(, )?)+(and |or )?sort of NP_\\w+)\", \"last\"),\n",
    "            ])\n",
    "\n",
    "        self.__pos_tagger = PerceptronTagger()\n",
    "        \n",
    "    def prepare(self, rawtext):\n",
    "        sentences = nltk.sent_tokenize(rawtext.strip()) # NLTK default sentence segmenter\n",
    "        sentences = [nltk.word_tokenize(sent) for sent in sentences] # NLTK word tokenizer\n",
    "        sentences = [self.__pos_tagger.tag(sent) for sent in sentences] # NLTK POS tagger\n",
    "\n",
    "        return sentences\n",
    "\n",
    "    def chunk(self, rawtext):\n",
    "        sentences = self.prepare(rawtext.strip())\n",
    "\n",
    "        all_chunks = []\n",
    "        for sentence in sentences:\n",
    "            chunks = self.__np_chunker.parse(sentence) # parse the example sentence\n",
    "            #for chunk in chunks:\n",
    "            #   print(str(chunk))\n",
    "            all_chunks.append(self.prepare_chunks(chunks))\n",
    "        return all_chunks\n",
    "\n",
    "    def prepare_chunks(self, chunks):\n",
    "        # basically, if the chunk is NP, keep it as a string taht starts w/ NP and replace \" \" with _\n",
    "        # otherwise, keep the word.\n",
    "        # remove punct\n",
    "        # this is all done to make it super easy to apply the Hearst patterns...\n",
    "\n",
    "        terms = []\n",
    "        for chunk in chunks:\n",
    "            label = None\n",
    "            try: # gross hack to see if the chunk is simply a word or a NP, as we want. But non-NP fail on this method call\n",
    "                label = chunk.label()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if label is None: #means one word...\n",
    "                token = chunk[0]\n",
    "                pos = chunk[1]\n",
    "                if pos in ['.', ':', '-', '_']:\n",
    "                    continue\n",
    "                terms.append(token)\n",
    "            else:\n",
    "                np = \"NP_\"+\"_\".join([a[0] for a in chunk]) #This makes it easy to apply the Hearst patterns later\n",
    "                terms.append(np)\n",
    "        return ' '.join(terms)\n",
    "\n",
    "    def replace_np_sequences(self, sentence):\n",
    "        words = \"\"\n",
    "        first_word_in_sequence = False\n",
    "        for word in nltk.word_tokenize(sentence.replace(\"NP_\", \"_\")):\n",
    "            if word[0] == \"_\":\n",
    "                if not first_word_in_sequence:\n",
    "                    word = \"NP\" + word\n",
    "                    first_word_in_sequence = True\n",
    "                    words = words + \" \" + word\n",
    "                else:\n",
    "                    words += word\n",
    "            else:\n",
    "                words = words + \" \" + word\n",
    "                first_word_in_sequence = False\n",
    "        return words.strip()\n",
    "\n",
    "    \"\"\"\n",
    "        This is the main entry point for this code.\n",
    "        It takes as input the rawtext to process and returns a list of tuples (specific-term, general-term)\n",
    "        where each tuple represents a hypernym pair.\n",
    "\n",
    "    \"\"\"\n",
    "    def find_hyponyms(self, rawtext):\n",
    "\n",
    "        hyponyms = []\n",
    "        np_tagged_sentences = self.chunk(rawtext)\n",
    "        #print \"NP tagged-->\",np_tagged_sentences\n",
    "\n",
    "        for raw_sentence in np_tagged_sentences:\n",
    "            # two or more NPs next to each other should be merged into a single NP, it's a chunk error\n",
    "\n",
    "            # find any N consecutive NP_ and merge them into one...\n",
    "            # So, something like: \"NP_foo NP_bar blah blah\" becomes \"NP_foo_bar blah blah\"\n",
    "            sentence = self.replace_np_sequences(raw_sentence)\n",
    "\n",
    "            for (hearst_pattern, parser) in self.__hearst_patterns:\n",
    "                matches = re.search(hearst_pattern, sentence)\n",
    "                if matches:\n",
    "                    match_str = matches.group(0)\n",
    "\n",
    "                    nps = [a for a in match_str.split() if a.startswith(\"NP_\")]\n",
    "\n",
    "                    if parser == \"first\":\n",
    "                        general = nps[0]\n",
    "                        specifics = nps[1:]\n",
    "                    else:\n",
    "                        general = nps[-1]\n",
    "                        specifics = nps[:-1]\n",
    "                        #print(str(general))\n",
    "                        #print(str(nps))\n",
    "\n",
    "                    for i in range(len(specifics)):\n",
    "                        #print(\"%s, %s\" % (specifics[i], general))\n",
    "                        hs = self.clean_hyponym_term(specifics[i])+\"-\"+self.clean_hyponym_term(general)\n",
    "                        hyponyms.append(hs)\n",
    "                        # hyponyms.append((self.clean_hyponym_term(general),self.clean_hyponym_term(general)))\n",
    "                        # return hyponyms\n",
    "        if hyponyms!=[]:\n",
    "            return hyponyms\n",
    "\n",
    "    # from pyspark.sql.functions import udf\n",
    "    # from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "    # find_hyponyms_udf = udf(lambda x: find_hyponyms(x), ArrayType(StringType()))\n",
    "\n",
    "    def clean_hyponym_term(self, term):\n",
    "        # good point to do the stemming or lemmatization\n",
    "        return term.replace(\"NP_\",\"\").replace(\"_\", \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "H=HearstPatterns(extended=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red eye-symptoms',\n",
       " 'ocular pain-symptoms',\n",
       " 'visual acuity-symptoms',\n",
       " 'photophobia-symptoms']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.find_hyponyms(\"Forty-four percent of patients with uveitis had one or more identifiable signs or symptoms, such as red eye, ocular pain, visual acuity, or photophobia, in order of decreasing frequency.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "H.find_hyponyms(\"apple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_hyponyms_udf = udf(H.find_hyponyms,ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_Type_verticesText_test2 = sen_Type_verticesText_test1.withColumn(\"Tp\",find_hyponyms_udf(sen_Type_verticesText_test1[\"RPS\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                 RPS|                  Tp|\n",
      "+--------------------+--------------------+\n",
      "|Politics of Burun...|                null|\n",
      "|Executive power i...|                null|\n",
      "|Legislative power...|                null|\n",
      "|The political lan...|                null|\n",
      "|The current Presi...|                null|\n",
      "|Nkurunziza was th...|                null|\n",
      "|In November 1995,...|                null|\n",
      "|In July 1996, for...|                null|\n",
      "|He declared himse...|                null|\n",
      "|Widespread condem...|                null|\n",
      "|Buyoya agreed in ...|                null|\n",
      "|Nonetheless, figh...|                null|\n",
      "|In June 1998, Buy...|                null|\n",
      "|After facilitator...|[Nelson Mandela-F...|\n",
      "|Under Mandela the...|                null|\n",
      "|In April 2015 the...|                null|\n",
      "|Protests in the c...|                null|\n",
      "|The president is ...|                null|\n",
      "|He nominates two ...|                null|\n",
      "|The National Asse...|                null|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sen_Type_verticesText_test2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "HType=sen_Type_verticesText_test2.select(\"Tp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "HType1=HType.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                  Tp|\n",
      "+--------------------+\n",
      "|[Nelson Mandela-F...|\n",
      "|[ADTs-the abstrac...|\n",
      "|   [data-data types]|\n",
      "|[relations-constr...|\n",
      "|[lattices-structu...|\n",
      "|[S-an explicit in...|\n",
      "|    [ADT-parameters]|\n",
      "|[the structure-a ...|\n",
      "|[the old state-an...|\n",
      "|[the same input s...|\n",
      "|[ADT instance use...|\n",
      "|[ADT operations-m...|\n",
      "|  [interfaces-types]|\n",
      "|[C-an imperative ...|\n",
      "|[Awk-many scripti...|\n",
      "|[Alpha engineerin...|\n",
      "|[Vinod Dham-engin...|\n",
      "|  [Athlons-a result]|\n",
      "|[core voltages-Th...|\n",
      "|[applications-an ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HType1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "HType2=HType1.withColumn(\"Tp1\", f.explode(\"Tp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                  Tp|                 Tp1|\n",
      "+--------------------+--------------------+\n",
      "|[Nelson Mandela-F...|Nelson Mandela-Fa...|\n",
      "|[ADTs-the abstrac...|ADTs-the abstraction|\n",
      "|   [data-data types]|     data-data types|\n",
      "|[relations-constr...|relations-constra...|\n",
      "|[lattices-structu...| lattices-structures|\n",
      "|[lattices-structu...|   groups-structures|\n",
      "|[S-an explicit in...|S-an explicit ins...|\n",
      "|    [ADT-parameters]|      ADT-parameters|\n",
      "|[the structure-a ...|the structure-a s...|\n",
      "|[the old state-an...|the old state-an ...|\n",
      "|[the same input s...|the same input st...|\n",
      "|[ADT instance use...|ADT instance uses...|\n",
      "|[ADT operations-m...|ADT operations-me...|\n",
      "|  [interfaces-types]|    interfaces-types|\n",
      "|[C-an imperative ...|C-an imperative l...|\n",
      "|[Awk-many scripti...|Awk-many scriptin...|\n",
      "|[Awk-many scripti...|Lua-many scriptin...|\n",
      "|[Awk-many scripti...|Perl-many scripti...|\n",
      "|[Alpha engineerin...|Alpha engineering...|\n",
      "|[Vinod Dham-engin...|Vinod Dham-engineers|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HType2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = HType2.withColumn(\"MentionName\", f.split(\"Tp1\", \"-\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "HType3 = df_temp.withColumn(\"Type\", f.split(\"Tp1\", \"-\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "HType3=HType3.drop(\"Tp\").drop(\"Tp1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|         MentionName|                Type|\n",
      "+--------------------+--------------------+\n",
      "|      Nelson Mandela|         Facilitator|\n",
      "|                ADTs|     the abstraction|\n",
      "|                data|          data types|\n",
      "|           relations|         constraints|\n",
      "|            lattices|          structures|\n",
      "|              groups|          structures|\n",
      "|                   S|an explicit insta...|\n",
      "|                 ADT|          parameters|\n",
      "|       the structure|   a separate entity|\n",
      "|       the old state|         an argument|\n",
      "|the same input st...|           arguments|\n",
      "|   ADT instance uses|          a function|\n",
      "|      ADT operations|             methods|\n",
      "|          interfaces|               types|\n",
      "|                   C|an imperative lan...|\n",
      "|                 Awk|many scripting la...|\n",
      "|                 Lua|many scripting la...|\n",
      "|                Perl|many scripting la...|\n",
      "|Alpha engineering...|              Compaq|\n",
      "|          Vinod Dham|           engineers|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HType3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HType=HType.distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "men_verticesText_1=verticesText1.filter(\"nodeType = 'Mention'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "men_verticesText_1=men_verticesText_1.drop(\"attr3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------------------+------------+\n",
      "|   id|nodeType|               attr1|       attr2|\n",
      "+-----+--------+--------------------+------------+\n",
      "|24975| Mention|       Freedom House|        MISC|\n",
      "|24976| Mention|                 NGO|ORGANIZATION|\n",
      "|24977| Mention|              Obiang|      PERSON|\n",
      "|24978| Mention|       Freedom House|        MISC|\n",
      "|24979| Mention|                  US|    LOCATION|\n",
      "|24980| Mention|       Freedom House|        MISC|\n",
      "|24981| Mention|                Root|      PERSON|\n",
      "|24982| Mention|           Queen Ask|        MISC|\n",
      "|24983| Mention|     Act of Congress|        MISC|\n",
      "|24984| Mention|          Public Law|        MISC|\n",
      "|24985| Mention|              Darwin|      PERSON|\n",
      "|24986| Mention|Evidence as to Ma...|        MISC|\n",
      "|24987| Mention|       Thomas Huxley|      PERSON|\n",
      "|24988| Mention|             Spanish|    LOCATION|\n",
      "|24989| Mention|       Mariano Rajoy|      PERSON|\n",
      "|24990| Mention|            European|    LOCATION|\n",
      "|24991| Mention|        Dragon 32/64|        MISC|\n",
      "|24992| Mention|       Dragon's Claw|        MISC|\n",
      "|24993| Mention|       Dragon's Claw|        MISC|\n",
      "|24994| Mention|                  UK|    LOCATION|\n",
      "+-----+--------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "men_verticesText_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_edges_1=edgesText3.filter(\"label = 'contains the mention'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_edges_1=mention_edges_1.drop(\"src\").drop(\"dst\").drop(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-------+------------+\n",
      "| src_id|src_nodeType| dst_id|dst_nodeType|\n",
      "+-------+------------+-------+------------+\n",
      "|2073024|      Clause|1007462|     Mention|\n",
      "|2849688|      Clause|1007636|     Mention|\n",
      "|2568628|      Clause|1007678|     Mention|\n",
      "| 117777|      Clause|1008797|     Mention|\n",
      "|1759866|      Clause|1009080|     Mention|\n",
      "|2846388|      Clause|1009129|     Mention|\n",
      "| 564274|      Clause|1009177|     Mention|\n",
      "| 935474|      Clause|1009407|     Mention|\n",
      "|1878077|      Clause|1009511|     Mention|\n",
      "|3643422|      Clause|1009562|     Mention|\n",
      "|1860471|      Clause|1010103|     Mention|\n",
      "|1860472|      Clause|1010108|     Mention|\n",
      "|2076128|      Clause|1010262|     Mention|\n",
      "| 588258|      Clause|1010351|     Mention|\n",
      "|2658225|      Clause|1010503|     Mention|\n",
      "| 321989|      Clause|1010766|     Mention|\n",
      "| 713827|      Clause|1010896|     Mention|\n",
      "|3699391|      Clause|1011171|     Mention|\n",
      "|3699391|      Clause|1011172|     Mention|\n",
      "|1240648|      Clause|1011187|     Mention|\n",
      "+-------+------------+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mention_edges_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dst_id\n",
    "mention_verticesText2 = mention_edges_1.join(men_verticesText_1, mention_edges_1.dst_id==men_verticesText_1.id, \"inner\")\n",
    "# clause_verticesTextJ_test = clause_verticesTextJ_test.drop(\"src_nodeType\").drop(\"dst_id\").drop(\"dst_nodeType\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_verticesText2=mention_verticesText2.drop(\"id\").drop(\"nodeType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-------+------------+--------------------+--------+\n",
      "| src_id|src_nodeType| dst_id|dst_nodeType|               attr1|   attr2|\n",
      "+-------+------------+-------+------------+--------------------+--------+\n",
      "|2073024|      Clause|1007462|     Mention|     Newington Youth|LOCATION|\n",
      "|2849688|      Clause|1007636|     Mention|American Film Ins...|    MISC|\n",
      "|2568628|      Clause|1007678|     Mention|               Italy|LOCATION|\n",
      "| 117777|      Clause|1008797|     Mention|              Church|    MISC|\n",
      "|1759866|      Clause|1009080|     Mention|             Laurier|  PERSON|\n",
      "|2846388|      Clause|1009129|     Mention|Anders Behring Br...|  PERSON|\n",
      "| 564274|      Clause|1009177|     Mention|     White Stockings|    MISC|\n",
      "| 935474|      Clause|1009407|     Mention|             Eleanor|  PERSON|\n",
      "|1878077|      Clause|1009511|     Mention|  Bristol University|LOCATION|\n",
      "|3643422|      Clause|1009562|     Mention|               Earth|LOCATION|\n",
      "|1860471|      Clause|1010103|     Mention|                Bell|  PERSON|\n",
      "|1860472|      Clause|1010108|     Mention|                Bell|  PERSON|\n",
      "|2076128|      Clause|1010262|     Mention|             Western|LOCATION|\n",
      "| 588258|      Clause|1010351|     Mention|AFC Croydon Athletic|    MISC|\n",
      "|2658225|      Clause|1010503|     Mention|             Islands|LOCATION|\n",
      "| 321989|      Clause|1010766|     Mention|                 BVC|    MISC|\n",
      "| 713827|      Clause|1010896|     Mention|             Bermuda|LOCATION|\n",
      "|3699391|      Clause|1011171|     Mention|              Indian|LOCATION|\n",
      "|3699391|      Clause|1011172|     Mention|               India|LOCATION|\n",
      "|1240648|      Clause|1011187|     Mention|               Jabal|    MISC|\n",
      "+-------+------------+-------+------------+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mention_verticesText2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine src_id\n",
    "mention_verticesText3 = mention_verticesText2.join(predicate_verticesText, mention_verticesText2.src_id==predicate_verticesText.id, \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_verticesText3=mention_verticesText3.drop(\"src_id\").drop(\"src_nodeType\").drop(\"id\").drop(\"nodeType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_verticesText3=mention_verticesText3.drop(\"predicate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_verticesText3=mention_verticesText3.withColumnRenamed(\"dst_id\",\"id\").withColumnRenamed(\"dst_nodeType\",\"nodeType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------------+--------+-------+-------------------+---+\n",
      "|     id|nodeType|               attr1|   attr2|    did|             dtitle|sid|\n",
      "+-------+--------+--------------------+--------+-------+-------------------+---+\n",
      "|2216143| Mention|            Kerensky|  PERSON| 606008| Alexander Kerensky| 34|\n",
      "|2216144| Mention| February Revolution|    MISC| 606008| Alexander Kerensky| 34|\n",
      "|3579976| Mention|           Cathedral|    MISC| 561719|  Claude Auchinleck|101|\n",
      "|3579975| Mention|             St Paul|LOCATION| 561719|  Claude Auchinleck|101|\n",
      "|2086736| Mention|             African|LOCATION|2444643|       Black people|183|\n",
      "|2086735| Mention|                  US|LOCATION|2444643|       Black people|183|\n",
      "|3571984| Mention|Nordic Chess Cham...|    MISC|2420916|   Aron Nimzowitsch| 13|\n",
      "|3571985| Mention|          Copenhagen|LOCATION|2420916|   Aron Nimzowitsch| 13|\n",
      "|1679175| Mention|      Ottoman Sultan|  PERSON| 851331|Christopher BÃ¡thory| 27|\n",
      "|1679176| Mention|        Transylvania|LOCATION| 851331|Christopher BÃ¡thory| 27|\n",
      "|1997886| Mention|             Beetles|  PERSON| 269398|             Beetle|307|\n",
      "|4039815| Mention|            Disraeli|  PERSON|2756547|  Benjamin Disraeli|159|\n",
      "|  77509| Mention|                John|  PERSON|3107509|        Christology| 63|\n",
      "|  77511| Mention|              Christ|  PERSON|3107509|        Christology| 63|\n",
      "|  77510| Mention|                John|  PERSON|3107509|        Christology| 63|\n",
      "|3958645| Mention|          Strasbourg|LOCATION|3323686|   Council of Trent| 58|\n",
      "|3958647| Mention|         WÃ¼rttemberg|  PERSON|3323686|   Council of Trent| 58|\n",
      "|3958646| Mention|         Protestants|    MISC|3323686|   Council of Trent| 58|\n",
      "|3958650| Mention|    Charles de Guise|  PERSON|3323686|   Council of Trent| 58|\n",
      "|3958649| Mention|          The French|LOCATION|3323686|   Council of Trent| 58|\n",
      "+-------+--------+--------------------+--------+-------+-------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mention_verticesText3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "HType4=HType3.distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "##join type by heart\n",
    "mention_verticesText4=mention_verticesText3.join(HType3, mention_verticesText3.attr1==HType3.MentionName,\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_verticesText5=mention_verticesText3.join(HType4, mention_verticesText3.attr1==HType4.MentionName,\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------------+--------+-------+-----------------+---+-----------+-------------------+\n",
      "|     id|nodeType|               attr1|   attr2|    did|           dtitle|sid|MentionName|               Type|\n",
      "+-------+--------+--------------------+--------+-------+-----------------+---+-----------+-------------------+\n",
      "|3559179| Mention|            Artesian|LOCATION|1439190|     Ellis Island| 39|       null|               null|\n",
      "|2021479| Mention|              Baloch|  PERSON|1511954|      Afghanistan|388|       null|               null|\n",
      "|1884303| Mention|      Blackford Hill|  PERSON|2081882|        Edinburgh| 98|       null|               null|\n",
      "|2242617| Mention|      Caesar Cardini|  PERSON|1235788|     Caesar salad| 16|       null|               null|\n",
      "|2809399| Mention|Combatant Status ...|    MISC|3625401|     Abu Zubaydah|176|       null|               null|\n",
      "|4039815| Mention|            Disraeli|  PERSON|2756547|Benjamin Disraeli|159|   Disraeli|           Disraeli|\n",
      "|4039815| Mention|            Disraeli|  PERSON|2756547|Benjamin Disraeli|159|   Disraeli|Conservative leader|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|            seasons|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|          festivals|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|       celebrations|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|        festivities|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter| Christian holidays|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|             feasts|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|           holidays|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|          festivals|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter| Christian holidays|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|          festivals|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|         Holy Week |\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter| Christian holidays|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|               days|\n",
      "+-------+--------+--------------------+--------+-------+-----------------+---+-----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mention_verticesText4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------------+--------+-------+-----------------+---+-----------+--------------------+\n",
      "|     id|nodeType|               attr1|   attr2|    did|           dtitle|sid|MentionName|                Type|\n",
      "+-------+--------+--------------------+--------+-------+-----------------+---+-----------+--------------------+\n",
      "|3559179| Mention|            Artesian|LOCATION|1439190|     Ellis Island| 39|       null|                null|\n",
      "|2021479| Mention|              Baloch|  PERSON|1511954|      Afghanistan|388|       null|                null|\n",
      "|1884303| Mention|      Blackford Hill|  PERSON|2081882|        Edinburgh| 98|       null|                null|\n",
      "|2242617| Mention|      Caesar Cardini|  PERSON|1235788|     Caesar salad| 16|       null|                null|\n",
      "|2809399| Mention|Combatant Status ...|    MISC|3625401|     Abu Zubaydah|176|       null|                null|\n",
      "|4039815| Mention|            Disraeli|  PERSON|2756547|Benjamin Disraeli|159|   Disraeli| Conservative leader|\n",
      "|4039815| Mention|            Disraeli|  PERSON|2756547|Benjamin Disraeli|159|   Disraeli|            Disraeli|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|           festivals|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|         festivities|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|          Holy Week |\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|        celebrations|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|       Easter Monday|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|  Christian holidays|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|              feasts|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|             seasons|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|            holidays|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|        Christianity|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|any religious sig...|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|            the year|\n",
      "|2916387| Mention|              Easter|    MISC|3038896|           Easter|138|     Easter|                days|\n",
      "+-------+--------+--------------------+--------+-------+-----------------+---+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mention_verticesText5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###alignment 'Predicate' / 'Type' / 'mention' alignment edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicate alignment\n",
    "#predicate=auxlite(is, was...) & predicate !=auxlist\n",
    "\n",
    "#1-get all predicat with id in column\n",
    "#2-delete all auxlist(was, is, are)\n",
    "#3-find same predicate in column (with different id)\n",
    "#4-get predicate glove\n",
    "#5-get weight and generate edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_alignment1=predicate_verticesText.select(\"id\",\"predicate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|     id|        predicate|\n",
      "+-------+-----------------+\n",
      "|2911087|       can result|\n",
      "|1732278|              are|\n",
      "|3236586|             came|\n",
      "|3493546|        resembled|\n",
      "|3493545|            began|\n",
      "|3327830|      capitalized|\n",
      "|1230382|              was|\n",
      "|2658479|         remained|\n",
      "|2658478|              was|\n",
      "| 276441|        displaced|\n",
      "| 276440|        broke out|\n",
      "| 464234|      was enacted|\n",
      "| 427430|        were used|\n",
      "| 386149|             died|\n",
      "| 386148|     never leaves|\n",
      "| 386147|          believe|\n",
      "|3457439|          is said|\n",
      "|1880973| would be amended|\n",
      "|1880971|         prompted|\n",
      "|1880972|  had overreached|\n",
      "+-------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicate_alignment1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-delete all auxlist(was, is, are)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover,RegexTokenizer, Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_alignment1_regexTokenizer = RegexTokenizer(inputCol='predicate', outputCol='predicate1', pattern='\\\\W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_stop_list = ['be', 'am', 'being', 'been', 'is', 'are', 'was', 'were', 'has', 'have', 'had', 'having', 'do', 'does', 'did',\n",
    "     'done', 'will', 'would', 'shall', 'should', 'can', 'could', 'dare', 'may', 'might', 'must', 'need', 'ought', \n",
    "     'a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', 'aren\\'t', 'as', 'at',\n",
    "     'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can\\'t', 'cannot', 'could',\n",
    "     'couldn\\'t', 'did', 'didn\\'t', 'do', 'does', 'doesn\\'t', 'doing', 'don\\'t', 'down', 'during', 'each', 'few', 'for',\n",
    "     'from', 'further', 'hadn\\'t', 'hasn\\'t', 'haven\\'t', 'he', 'he\\'d', 'he\\'ll',\n",
    "     'he\\'s', 'her', 'here', 'here\\'s', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'how\\'s', 'i', 'i\\'d',\n",
    "     'i\\'ll', 'i\\'m', 'i\\'ve', 'if', 'in', 'into', 'is', 'isn\\'t', 'it', 'it\\'s', 'its', 'itself', 'let\\'s',\n",
    "     'more', 'most', 'mustn\\'t','myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other',\n",
    "     'ought', 'ours','ourselves', 'out', 'over', 'own', 'same', 'shan\\'t', 'she\\'d', 'she\\'ll', 'she\\'s',\n",
    "     'should', 'shouldn\\'t', 'so', 'some', 'such', 'than', 'that', 'that\\'s', 'the', 'theirs',\n",
    "     'themselves', 'then', 'there\\'s', 'they\\'d', 'they\\'ll', 'they\\'re', 'they\\'ve', 'this',\n",
    "     'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'wasn\\'t', 'we\\'d', 'we\\'ll',\n",
    "     'we\\'re', 'we\\'ve', 'were', 'weren\\'t', 'what', 'what\\'s', 'when', 'when\\'s', 'where', 'where\\'s', 'which',\n",
    "     'while', 'who', 'who\\'s', 'whom', 'why', 'why\\'s', 'with', 'won\\'t', 'wouldn\\'t', 'you\\'d',\n",
    "     'you\\'ll', 'you\\'re', 'you\\'ve', 'your', 'yours', 'yourself', 'yourselves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_stopw = []\n",
    "for l in open('auxiliary_stopw.txt'):\n",
    "    l = l.strip()\n",
    "    aux_stopw.append(l.lower())\n",
    "aux_stopw=np.unique(aux_stopw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_alignment1_remove = StopWordsRemover(inputCol='predicate1', outputCol='predicate2').setStopWords(aux_stopw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[predicate_alignment1_regexTokenizer,predicate_alignment1_remove])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_fit = pipeline.fit(predicate_alignment1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_alignment2 = pipeline_fit.transform(predicate_alignment1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+--------------------+-------------+\n",
      "|     id|        predicate|          predicate1|   predicate2|\n",
      "+-------+-----------------+--------------------+-------------+\n",
      "|2911087|       can result|       [can, result]|     [result]|\n",
      "|1732278|              are|               [are]|           []|\n",
      "|3236586|             came|              [came]|           []|\n",
      "|3493546|        resembled|         [resembled]|  [resembled]|\n",
      "|3493545|            began|             [began]|      [began]|\n",
      "|3327830|      capitalized|       [capitalized]|[capitalized]|\n",
      "|1230382|              was|               [was]|           []|\n",
      "|2658479|         remained|          [remained]|   [remained]|\n",
      "|2658478|              was|               [was]|           []|\n",
      "| 276441|        displaced|         [displaced]|  [displaced]|\n",
      "| 276440|        broke out|        [broke, out]|      [broke]|\n",
      "| 464234|      was enacted|      [was, enacted]|    [enacted]|\n",
      "| 427430|        were used|        [were, used]|           []|\n",
      "| 386149|             died|              [died]|       [died]|\n",
      "| 386148|     never leaves|     [never, leaves]|     [leaves]|\n",
      "| 386147|          believe|           [believe]|           []|\n",
      "|3457439|          is said|          [is, said]|           []|\n",
      "|1880973| would be amended|[would, be, amended]|    [amended]|\n",
      "|1880971|         prompted|          [prompted]|   [prompted]|\n",
      "|1880972|  had overreached|  [had, overreached]|[overreached]|\n",
      "+-------+-----------------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicate_alignment2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_alignment3 = predicate_alignment2.select(\"id\",\"predicate2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|     id|   predicate2|\n",
      "+-------+-------------+\n",
      "|2911087|     [result]|\n",
      "|1732278|           []|\n",
      "|3236586|           []|\n",
      "|3493546|  [resembled]|\n",
      "|3493545|      [began]|\n",
      "|3327830|[capitalized]|\n",
      "|1230382|           []|\n",
      "|2658479|   [remained]|\n",
      "|2658478|           []|\n",
      "| 276441|  [displaced]|\n",
      "| 276440|      [broke]|\n",
      "| 464234|    [enacted]|\n",
      "| 427430|           []|\n",
      "| 386149|       [died]|\n",
      "| 386148|     [leaves]|\n",
      "| 386147|           []|\n",
      "|3457439|           []|\n",
      "|1880973|    [amended]|\n",
      "|1880971|   [prompted]|\n",
      "|1880972|[overreached]|\n",
      "+-------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicate_alignment3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_alignment3 = predicate_alignment3.withColumn(\"size\", f.size(f.col(\"predicate2\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+----+\n",
      "|     id|   predicate2|size|\n",
      "+-------+-------------+----+\n",
      "|2911087|     [result]|   1|\n",
      "|1732278|           []|   0|\n",
      "|3236586|           []|   0|\n",
      "|3493546|  [resembled]|   1|\n",
      "|3493545|      [began]|   1|\n",
      "|3327830|[capitalized]|   1|\n",
      "|1230382|           []|   0|\n",
      "|2658479|   [remained]|   1|\n",
      "|2658478|           []|   0|\n",
      "| 276441|  [displaced]|   1|\n",
      "| 276440|      [broke]|   1|\n",
      "| 464234|    [enacted]|   1|\n",
      "| 427430|           []|   0|\n",
      "| 386149|       [died]|   1|\n",
      "| 386148|     [leaves]|   1|\n",
      "| 386147|           []|   0|\n",
      "|3457439|           []|   0|\n",
      "|1880973|    [amended]|   1|\n",
      "|1880971|   [prompted]|   1|\n",
      "|1880972|[overreached]|   1|\n",
      "+-------+-------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicate_alignment3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_alignment3 = predicate_alignment3.filter(f.col(\"size\") != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+----+\n",
      "|     id|   predicate2|size|\n",
      "+-------+-------------+----+\n",
      "|2911087|     [result]|   1|\n",
      "|3493546|  [resembled]|   1|\n",
      "|3493545|      [began]|   1|\n",
      "|3327830|[capitalized]|   1|\n",
      "|2658479|   [remained]|   1|\n",
      "| 276441|  [displaced]|   1|\n",
      "| 276440|      [broke]|   1|\n",
      "| 464234|    [enacted]|   1|\n",
      "| 386149|       [died]|   1|\n",
      "| 386148|     [leaves]|   1|\n",
      "|1880973|    [amended]|   1|\n",
      "|1880971|   [prompted]|   1|\n",
      "|1880972|[overreached]|   1|\n",
      "|1443408|   [combined]|   1|\n",
      "|1747188|    [started]|   1|\n",
      "|3380427|      [drain]|   1|\n",
      "|3889909|       [made]|   1|\n",
      "|3889908|    [include]|   1|\n",
      "| 175503|      [holds]|   1|\n",
      "| 175500|[generalized]|   1|\n",
      "+-------+-------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicate_alignment3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|                id|              size|\n",
      "+-------+------------------+------------------+\n",
      "|  count|           1797303|           1797303|\n",
      "|   mean|4132753.0580180413|1.0479034419905826|\n",
      "| stddev| 2389320.165493053|0.4197790980265908|\n",
      "|    min|           1000001|                 1|\n",
      "|    max|            999999|                60|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "predicate_alignment3.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2128482"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "predicate_alignment3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2070642"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "predicate_alignment3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicate_alignment3=predicate_alignment3.drop(\"size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-find same predicate in column (with different id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_alignment4=predicate_alignment3.withColumnRenamed(\"id\",\"id2\").withColumnRenamed(\"predicate2\",\"predicate3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_alignment4=predicate_alignment4.join(predicate_alignment3,predicate_alignment3.predicate2==predicate_alignment4.predicate3,\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----+-------+--------------------+----+\n",
      "|    id2|          predicate3|size|     id|          predicate2|size|\n",
      "+-------+--------------------+----+-------+--------------------+----+\n",
      "|2571288|            [0, 258]|   2|2571288|            [0, 258]|   2|\n",
      "|1971975|         [0, 4, mag]|   3|1971975|         [0, 4, mag]|   3|\n",
      "|1724515|[000, fine, years...|   4|1724515|[000, fine, years...|   4|\n",
      "|5609685|       [000, greeks]|   2|5609685|       [000, greeks]|   2|\n",
      "|5609685|       [000, greeks]|   2|2691949|       [000, greeks]|   2|\n",
      "|5609685|       [000, greeks]|   2|1645067|       [000, greeks]|   2|\n",
      "|2691949|       [000, greeks]|   2|5609685|       [000, greeks]|   2|\n",
      "|2691949|       [000, greeks]|   2|2691949|       [000, greeks]|   2|\n",
      "|2691949|       [000, greeks]|   2|1645067|       [000, greeks]|   2|\n",
      "|1645067|       [000, greeks]|   2|5609685|       [000, greeks]|   2|\n",
      "|1645067|       [000, greeks]|   2|2691949|       [000, greeks]|   2|\n",
      "|1645067|       [000, greeks]|   2|1645067|       [000, greeks]|   2|\n",
      "|2571009|[000, inhabitants...|   4|2571009|[000, inhabitants...|   4|\n",
      "|2571009|[000, inhabitants...|   4|2571011|[000, inhabitants...|   4|\n",
      "|2571011|[000, inhabitants...|   4|2571009|[000, inhabitants...|   4|\n",
      "|2571011|[000, inhabitants...|   4|2571011|[000, inhabitants...|   4|\n",
      "|1139356|[000, light, year...|   5|1139356|[000, light, year...|   5|\n",
      "|3942774|[000, manufacturi...|   5|3942774|[000, manufacturi...|   5|\n",
      "|5096949|[000, members, ea...|   4|5096949|[000, members, ea...|   4|\n",
      "|5096949|[000, members, ea...|   4|5096948|[000, members, ea...|   4|\n",
      "+-------+--------------------+----+-------+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicate_alignment4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_alignment4=predicate_alignment4.filter(predicate_alignment4.id2!=predicate_alignment4.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------+--------------------+\n",
      "|    id2|          predicate3|     id|          predicate2|\n",
      "+-------+--------------------+-------+--------------------+\n",
      "|5609685|       [000, greeks]|2691949|       [000, greeks]|\n",
      "|5609685|       [000, greeks]|1645067|       [000, greeks]|\n",
      "|2691949|       [000, greeks]|5609685|       [000, greeks]|\n",
      "|2691949|       [000, greeks]|1645067|       [000, greeks]|\n",
      "|1645067|       [000, greeks]|5609685|       [000, greeks]|\n",
      "|1645067|       [000, greeks]|2691949|       [000, greeks]|\n",
      "|2571009|[000, inhabitants...|2571011|[000, inhabitants...|\n",
      "|2571011|[000, inhabitants...|2571009|[000, inhabitants...|\n",
      "|5096949|[000, members, ea...|5096948|[000, members, ea...|\n",
      "|5096948|[000, members, ea...|5096949|[000, members, ea...|\n",
      "|3564033|               [467]|3564032|               [467]|\n",
      "|3564033|               [467]|6857259|               [467]|\n",
      "|3564033|               [467]|6421152|               [467]|\n",
      "|3564033|               [467]|5334293|               [467]|\n",
      "|3564032|               [467]|3564033|               [467]|\n",
      "|3564032|               [467]|6857259|               [467]|\n",
      "|3564032|               [467]|6421152|               [467]|\n",
      "|3564032|               [467]|5334293|               [467]|\n",
      "|6857259|               [467]|3564033|               [467]|\n",
      "|6857259|               [467]|3564032|               [467]|\n",
      "+-------+--------------------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicate_alignment4.show()#bidirection predict alignment weight=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicate_alignment2_word2Vec = Word2Vec(vectorSize=300, minCount=0, inputCol=\"predicate2\", outputCol=\"predicate3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicate_alignment2_model = predicate_alignment2_word2Vec.fit(predicate_alignment2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicate_alignment3=result = predicate_alignment2_model.transform(predicate_alignment2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicate_alignment2=predicate_alignment1.select(\"id\",f.translate(f.col(\"predicate\"), aux_list, \"\").alias(\"predicate1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding='WORD2VEC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/QUEST/lib/python2.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "if embedding == 'WORD2VEC':\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format('/Users/jeanxu/PycharmProjects/QUEST_TerminalTest/Code/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "    word_vectors = model.wv\n",
    "    gdict = word_vectors\n",
    "else:\n",
    "    glove_file = 'glove.6B/glove.6B.300d.txt'\n",
    "    fg = open(glove_file, 'r')\n",
    "    for line in fg:\n",
    "        line = (line.strip()).split()\n",
    "        vec = []\n",
    "        for i in range(1, len(line)):\n",
    "            vec.append(float(line[i]))\n",
    "        gdict[line[0]] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_alignment5=predicate_alignment3.filter(predicate_alignment3.size==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+----+\n",
      "|     id|   predicate2|size|\n",
      "+-------+-------------+----+\n",
      "|2911087|     [result]|   1|\n",
      "|3493546|  [resembled]|   1|\n",
      "|3493545|      [began]|   1|\n",
      "|3327830|[capitalized]|   1|\n",
      "|2658479|   [remained]|   1|\n",
      "| 276441|  [displaced]|   1|\n",
      "| 276440|      [broke]|   1|\n",
      "| 464234|    [enacted]|   1|\n",
      "| 386149|       [died]|   1|\n",
      "| 386148|     [leaves]|   1|\n",
      "|1880973|    [amended]|   1|\n",
      "|1880971|   [prompted]|   1|\n",
      "|1880972|[overreached]|   1|\n",
      "|1443408|   [combined]|   1|\n",
      "|1747188|    [started]|   1|\n",
      "|3380427|      [drain]|   1|\n",
      "|3889909|       [made]|   1|\n",
      "|3889908|    [include]|   1|\n",
      "| 175503|      [holds]|   1|\n",
      "| 175500|[generalized]|   1|\n",
      "+-------+-------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicate_alignment5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_alignment6=predicate_alignment5.select(\"predicate2\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[predicate2: array<string>]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicate_alignment6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_alignment6=predicate_alignment6.withColumn('arr_to_string',f.array_join(f.col('predicate2'),','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicate_alignment6=predicate_alignment6.withColumn(\"predicate2\", f.concat(predicate_alignment6['predicate2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+\n",
      "|    predicate2|arr_to_string|\n",
      "+--------------+-------------+\n",
      "|      [travel]|       travel|\n",
      "| [transmitted]|  transmitted|\n",
      "|   [connected]|    connected|\n",
      "|     [persist]|      persist|\n",
      "|  [superseded]|   superseded|\n",
      "|     [courted]|      courted|\n",
      "|   [recognize]|    recognize|\n",
      "|  [indigenous]|   indigenous|\n",
      "|      [wields]|       wields|\n",
      "|     [flashed]|      flashed|\n",
      "|      [doubts]|       doubts|\n",
      "|          [07]|           07|\n",
      "|     [degrade]|      degrade|\n",
      "|     [hitched]|      hitched|\n",
      "|     [tarnish]|      tarnish|\n",
      "|   [traveling]|    traveling|\n",
      "|        [hope]|         hope|\n",
      "|[crystallises]| crystallises|\n",
      "|      [spared]|       spared|\n",
      "| [desertified]|  desertified|\n",
      "+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicate_alignment6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(s, gdict, np):\n",
    "    if s in gdict[s]: \n",
    "        return np.array(gdict[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vector_udf = udf(lambda x: get_vector(x,gdict, np),ArrayType(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/serializers.py\", line 590, in dumps\n",
      "    return cloudpickle.dumps(obj, 2)\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/cloudpickle.py\", line 863, in dumps\n",
      "    cp.dump(obj)\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/cloudpickle.py\", line 260, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 224, in dump\n",
      "    self.save(obj)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 554, in save_tuple\n",
      "    save(element)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/cloudpickle.py\", line 400, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/cloudpickle.py\", line 549, in save_function_tuple\n",
      "    save(state)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 655, in save_dict\n",
      "    self._batch_setitems(obj.iteritems())\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 687, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 655, in save_dict\n",
      "    self._batch_setitems(obj.iteritems())\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 687, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 331, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 425, in save_reduce\n",
      "    save(state)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 655, in save_dict\n",
      "    self._batch_setitems(obj.iteritems())\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 687, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 331, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 425, in save_reduce\n",
      "    save(state)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 568, in save_tuple\n",
      "    save(element)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 492, in save_string\n",
      "    self.write(BINSTRING + pack(\"<i\", n) + obj)\n",
      "error: 'i' format requires -2147483648 <= number <= 2147483647\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Object too large to serialize: 'i' format requires -2147483648 <= number <= 2147483647",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-345-b938bc28b374>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicate_alignment7\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicate_alignment6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vec\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_vector_udf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicate_alignment6\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"arr_to_string\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgdict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/sql/udf.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massigned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0massignments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/sql/udf.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mjudf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_judf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_to_java_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/sql/udf.pyc\u001b[0m in \u001b[0;36m_judf\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;31m# and should have a minimal performance impact.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_judf_placeholder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_judf_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_judf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_judf_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/sql/udf.pyc\u001b[0m in \u001b[0;36m_create_judf\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mwrapped_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrap_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturnType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mjdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseDataType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturnType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         judf = sc._jvm.org.apache.spark.sql.execution.python.UserDefinedPythonFunction(\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/sql/udf.pyc\u001b[0m in \u001b[0;36m_wrap_function\u001b[0;34m(sc, func, returnType)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrap_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturnType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturnType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mpickled_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincludes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_for_python_RDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n\u001b[1;32m     37\u001b[0m                                   sc.pythonVer, broadcast_vars, sc._javaAccumulator)\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36m_prepare_for_python_RDD\u001b[0;34m(sc, command)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;31m# the serialized command will be compressed by broadcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCloudPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0mpickled_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickled_command\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 1M\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m         \u001b[0;31m# The broadcast will have same life cycle as created PythonRDD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/serializers.pyc\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Could not serialize object: %s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Object too large to serialize: 'i' format requires -2147483648 <= number <= 2147483647"
     ]
    }
   ],
   "source": [
    "##to do: sovle this problem\n",
    "predicate_alignment7=predicate_alignment6.withColumn(\"vec\",get_vector_udf(predicate_alignment6[\"arr_to_string\"],gdict,np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_alignment7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "global gdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_vector(s, gdict, np):\n",
    "#     veclen = 300\n",
    "#     avec = np.zeros(veclen)\n",
    "#     c=0\n",
    "#     for i in range(len(s)):\n",
    "#         if s[i] in gdict: \n",
    "#             avec = np.add(avec, np.array(gdict[s[i]]))\n",
    "#             c += 1.0\n",
    "#     if c > 0:\n",
    "#             avec = np.divide(avec, c)\n",
    "#     return avec\n",
    "# def get_vector(s, gdict, np):\n",
    "#     if s[0] in gdict: \n",
    "#         return np.array(gdict[s[0]])\n",
    "#         c += 1.0\n",
    "#     if c > 0:\n",
    "#             avec = np.divide(avec, c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.types import FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predicate_alignment6 = predicate_alignment5.withColumn(\"Vec\",get_vector_udf(predicate_alignment3[\"predicate2\"],gdict,np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_alignment6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gdict[\"broken\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.76757812e-01,   2.94189453e-02,  -1.37695312e-01,\n",
       "         -1.14746094e-02,  -1.01074219e-01,   1.24023438e-01,\n",
       "          1.43554688e-01,   3.90625000e-03,   1.52343750e-01,\n",
       "          2.91015625e-01,  -2.39257812e-01,  -1.75781250e-02,\n",
       "         -1.23535156e-01,  -5.39550781e-02,  -9.17968750e-02,\n",
       "          6.20117188e-02,   1.29882812e-01,  -9.22851562e-02,\n",
       "         -2.26562500e-01,   1.37939453e-02,   8.30078125e-02,\n",
       "          1.30859375e-01,  -6.64062500e-02,  -1.29882812e-01,\n",
       "          1.84570312e-01,  -3.02734375e-02,  -1.95312500e-01,\n",
       "          2.55859375e-01,   2.35351562e-01,  -8.98437500e-02,\n",
       "         -2.25585938e-01,   5.78613281e-02,   1.12792969e-01,\n",
       "         -1.11328125e-01,  -3.29589844e-02,  -3.73535156e-02,\n",
       "          1.43554688e-01,  -1.37695312e-01,  -1.98242188e-01,\n",
       "          2.03125000e-01,  -7.42187500e-02,   5.32226562e-02,\n",
       "          6.78710938e-02,  -2.17285156e-02,   2.47070312e-01,\n",
       "          1.81640625e-01,  -1.21582031e-01,   3.24707031e-02,\n",
       "          1.39648438e-01,  -8.10546875e-02,  -2.94921875e-01,\n",
       "          2.67578125e-01,  -3.04687500e-01,  -2.51953125e-01,\n",
       "          7.47070312e-02,   9.66796875e-02,  -2.15820312e-01,\n",
       "         -3.45703125e-01,  -5.90820312e-02,  -4.63867188e-02,\n",
       "         -2.18505859e-02,   1.56250000e-01,   2.65625000e-01,\n",
       "         -1.13281250e-01,  -1.42578125e-01,  -2.16796875e-01,\n",
       "         -3.54003906e-02,   9.96093750e-02,  -2.02148438e-01,\n",
       "         -2.10937500e-01,  -3.39355469e-02,   1.88476562e-01,\n",
       "         -5.24902344e-03,  -1.77734375e-01,  -2.59765625e-01,\n",
       "         -6.93359375e-02,   2.08007812e-01,   7.27539062e-02,\n",
       "         -1.28906250e-01,  -2.57812500e-01,   1.50390625e-01,\n",
       "         -1.65039062e-01,   1.19140625e-01,  -2.65625000e-01,\n",
       "         -1.25976562e-01,  -1.88446045e-03,  -1.18164062e-01,\n",
       "          1.94335938e-01,  -7.32421875e-02,   1.84570312e-01,\n",
       "          1.62109375e-01,   1.79687500e-01,   3.69140625e-01,\n",
       "          5.37109375e-02,  -8.15429688e-02,  -2.09960938e-01,\n",
       "          1.18652344e-01,  -1.69921875e-01,  -2.24609375e-01,\n",
       "          7.66601562e-02,   2.94189453e-02,   1.17675781e-01,\n",
       "          2.28515625e-01,  -1.72851562e-01,   5.51757812e-02,\n",
       "         -6.73828125e-02,   6.07910156e-02,   2.10937500e-01,\n",
       "         -1.32812500e-01,  -2.77343750e-01,  -2.27355957e-03,\n",
       "         -8.39843750e-02,  -1.71661377e-03,  -9.71679688e-02,\n",
       "          1.15722656e-01,  -9.71679688e-02,  -6.25610352e-03,\n",
       "         -1.11816406e-01,  -3.58886719e-02,   6.93359375e-02,\n",
       "         -2.85156250e-01,  -1.67968750e-01,   4.10156250e-01,\n",
       "         -1.25000000e-01,  -1.44531250e-01,  -1.56250000e-01,\n",
       "          5.34667969e-02,  -2.67578125e-01,  -4.71191406e-02,\n",
       "         -6.05468750e-02,  -7.03125000e-02,  -1.15722656e-01,\n",
       "         -9.37500000e-02,  -1.63574219e-02,  -2.49023438e-01,\n",
       "          1.62353516e-02,  -2.61718750e-01,   1.74560547e-02,\n",
       "         -2.41210938e-01,  -6.44531250e-02,  -1.91406250e-01,\n",
       "          2.47070312e-01,   1.62109375e-01,   2.26562500e-01,\n",
       "         -1.19140625e-01,   1.22070312e-01,  -1.67968750e-01,\n",
       "         -3.78906250e-01,   1.87500000e-01,  -1.66992188e-01,\n",
       "          3.41796875e-01,  -1.56250000e-01,   2.36511230e-03,\n",
       "          2.27539062e-01,   1.13281250e-01,   1.22070312e-01,\n",
       "         -1.41601562e-01,  -2.51953125e-01,   3.36914062e-02,\n",
       "         -1.69921875e-01,  -6.78710938e-02,   2.05078125e-01,\n",
       "         -1.50390625e-01,  -5.27343750e-02,  -2.33398438e-01,\n",
       "         -1.41601562e-01,   8.83789062e-02,  -2.63671875e-01,\n",
       "         -6.00585938e-02,  -5.66406250e-02,  -1.72851562e-01,\n",
       "         -1.08886719e-01,  -3.06640625e-01,  -5.41992188e-02,\n",
       "          3.65234375e-01,  -9.13085938e-02,   1.32446289e-02,\n",
       "         -2.97851562e-02,  -1.11328125e-01,   1.85546875e-01,\n",
       "         -1.32812500e-01,   3.06396484e-02,   1.02050781e-01,\n",
       "          2.27050781e-02,   7.08007812e-02,   1.27929688e-01,\n",
       "          1.11694336e-02,   2.33398438e-01,  -6.73828125e-02,\n",
       "          2.21679688e-01,  -1.29882812e-01,  -1.06445312e-01,\n",
       "          1.20117188e-01,   1.97265625e-01,   1.18164062e-01,\n",
       "          4.68750000e-01,  -9.08203125e-02,  -8.34960938e-02,\n",
       "          2.21679688e-01,  -7.08007812e-03,  -1.47460938e-01,\n",
       "          9.27734375e-02,  -2.13623047e-02,  -6.59179688e-02,\n",
       "         -2.94189453e-02,  -2.53906250e-01,  -1.84326172e-02,\n",
       "         -9.08203125e-02,   1.78710938e-01,  -1.08886719e-01,\n",
       "          6.44531250e-02,   4.73632812e-02,  -6.34765625e-02,\n",
       "          5.00488281e-02,  -1.54418945e-02,   1.24023438e-01,\n",
       "          2.89062500e-01,   4.85839844e-02,  -3.20312500e-01,\n",
       "         -5.02929688e-02,  -6.07910156e-02,  -1.74804688e-01,\n",
       "         -1.80664062e-01,  -1.15234375e-01,   2.73437500e-01,\n",
       "         -3.10546875e-01,   1.34765625e-01,   5.51757812e-02,\n",
       "          5.03540039e-03,  -5.32226562e-02,  -1.70898438e-01,\n",
       "          1.16699219e-01,  -2.23632812e-01,   1.66015625e-01,\n",
       "         -1.40625000e-01,  -8.30078125e-02,  -1.92382812e-01,\n",
       "         -2.94921875e-01,  -5.64575195e-04,   5.03906250e-01,\n",
       "          3.71093750e-01,   1.24511719e-01,  -9.71679688e-02,\n",
       "         -1.06933594e-01,   2.85156250e-01,   8.34960938e-02,\n",
       "         -4.46777344e-02,  -2.92968750e-02,   6.59179688e-02,\n",
       "         -1.12304688e-01,   1.79443359e-02,  -1.31835938e-01,\n",
       "          7.27539062e-02,   1.63574219e-02,   2.28515625e-01,\n",
       "         -2.83203125e-02,   2.81250000e-01,  -1.37939453e-02,\n",
       "          8.98437500e-02,  -4.24194336e-03,  -2.91748047e-02,\n",
       "          6.10351562e-02,   1.13281250e-01,   1.33789062e-01,\n",
       "          2.62451172e-02,  -2.94921875e-01,  -5.78613281e-02,\n",
       "         -3.75976562e-02,   2.57812500e-01,   1.11816406e-01,\n",
       "          4.32128906e-02,   3.11279297e-02,   4.63867188e-02,\n",
       "          1.90429688e-02,   1.56250000e-01,  -1.09863281e-01,\n",
       "         -6.19506836e-03,  -2.96630859e-02,   1.58203125e-01,\n",
       "          1.53320312e-01,  -6.44531250e-02,   4.92095947e-04,\n",
       "         -7.27539062e-02,   1.66992188e-01,   4.98046875e-02,\n",
       "         -4.88281250e-03,  -2.23632812e-01,   2.34375000e-01,\n",
       "         -2.00195312e-01,   4.54101562e-02,   6.12792969e-02,\n",
       "         -4.17480469e-02,   1.13769531e-01,  -8.83789062e-02,\n",
       "         -2.01171875e-01,   4.07714844e-02,  -1.28906250e-01,\n",
       "         -6.44531250e-02,   8.74023438e-02,  -2.20703125e-01]], dtype=float32)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdict[[\"broken\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.76757812e-01,   2.94189453e-02,  -1.37695312e-01,\n",
       "        -1.14746094e-02,  -1.01074219e-01,   1.24023438e-01,\n",
       "         1.43554688e-01,   3.90625000e-03,   1.52343750e-01,\n",
       "         2.91015625e-01,  -2.39257812e-01,  -1.75781250e-02,\n",
       "        -1.23535156e-01,  -5.39550781e-02,  -9.17968750e-02,\n",
       "         6.20117188e-02,   1.29882812e-01,  -9.22851562e-02,\n",
       "        -2.26562500e-01,   1.37939453e-02,   8.30078125e-02,\n",
       "         1.30859375e-01,  -6.64062500e-02,  -1.29882812e-01,\n",
       "         1.84570312e-01,  -3.02734375e-02,  -1.95312500e-01,\n",
       "         2.55859375e-01,   2.35351562e-01,  -8.98437500e-02,\n",
       "        -2.25585938e-01,   5.78613281e-02,   1.12792969e-01,\n",
       "        -1.11328125e-01,  -3.29589844e-02,  -3.73535156e-02,\n",
       "         1.43554688e-01,  -1.37695312e-01,  -1.98242188e-01,\n",
       "         2.03125000e-01,  -7.42187500e-02,   5.32226562e-02,\n",
       "         6.78710938e-02,  -2.17285156e-02,   2.47070312e-01,\n",
       "         1.81640625e-01,  -1.21582031e-01,   3.24707031e-02,\n",
       "         1.39648438e-01,  -8.10546875e-02,  -2.94921875e-01,\n",
       "         2.67578125e-01,  -3.04687500e-01,  -2.51953125e-01,\n",
       "         7.47070312e-02,   9.66796875e-02,  -2.15820312e-01,\n",
       "        -3.45703125e-01,  -5.90820312e-02,  -4.63867188e-02,\n",
       "        -2.18505859e-02,   1.56250000e-01,   2.65625000e-01,\n",
       "        -1.13281250e-01,  -1.42578125e-01,  -2.16796875e-01,\n",
       "        -3.54003906e-02,   9.96093750e-02,  -2.02148438e-01,\n",
       "        -2.10937500e-01,  -3.39355469e-02,   1.88476562e-01,\n",
       "        -5.24902344e-03,  -1.77734375e-01,  -2.59765625e-01,\n",
       "        -6.93359375e-02,   2.08007812e-01,   7.27539062e-02,\n",
       "        -1.28906250e-01,  -2.57812500e-01,   1.50390625e-01,\n",
       "        -1.65039062e-01,   1.19140625e-01,  -2.65625000e-01,\n",
       "        -1.25976562e-01,  -1.88446045e-03,  -1.18164062e-01,\n",
       "         1.94335938e-01,  -7.32421875e-02,   1.84570312e-01,\n",
       "         1.62109375e-01,   1.79687500e-01,   3.69140625e-01,\n",
       "         5.37109375e-02,  -8.15429688e-02,  -2.09960938e-01,\n",
       "         1.18652344e-01,  -1.69921875e-01,  -2.24609375e-01,\n",
       "         7.66601562e-02,   2.94189453e-02,   1.17675781e-01,\n",
       "         2.28515625e-01,  -1.72851562e-01,   5.51757812e-02,\n",
       "        -6.73828125e-02,   6.07910156e-02,   2.10937500e-01,\n",
       "        -1.32812500e-01,  -2.77343750e-01,  -2.27355957e-03,\n",
       "        -8.39843750e-02,  -1.71661377e-03,  -9.71679688e-02,\n",
       "         1.15722656e-01,  -9.71679688e-02,  -6.25610352e-03,\n",
       "        -1.11816406e-01,  -3.58886719e-02,   6.93359375e-02,\n",
       "        -2.85156250e-01,  -1.67968750e-01,   4.10156250e-01,\n",
       "        -1.25000000e-01,  -1.44531250e-01,  -1.56250000e-01,\n",
       "         5.34667969e-02,  -2.67578125e-01,  -4.71191406e-02,\n",
       "        -6.05468750e-02,  -7.03125000e-02,  -1.15722656e-01,\n",
       "        -9.37500000e-02,  -1.63574219e-02,  -2.49023438e-01,\n",
       "         1.62353516e-02,  -2.61718750e-01,   1.74560547e-02,\n",
       "        -2.41210938e-01,  -6.44531250e-02,  -1.91406250e-01,\n",
       "         2.47070312e-01,   1.62109375e-01,   2.26562500e-01,\n",
       "        -1.19140625e-01,   1.22070312e-01,  -1.67968750e-01,\n",
       "        -3.78906250e-01,   1.87500000e-01,  -1.66992188e-01,\n",
       "         3.41796875e-01,  -1.56250000e-01,   2.36511230e-03,\n",
       "         2.27539062e-01,   1.13281250e-01,   1.22070312e-01,\n",
       "        -1.41601562e-01,  -2.51953125e-01,   3.36914062e-02,\n",
       "        -1.69921875e-01,  -6.78710938e-02,   2.05078125e-01,\n",
       "        -1.50390625e-01,  -5.27343750e-02,  -2.33398438e-01,\n",
       "        -1.41601562e-01,   8.83789062e-02,  -2.63671875e-01,\n",
       "        -6.00585938e-02,  -5.66406250e-02,  -1.72851562e-01,\n",
       "        -1.08886719e-01,  -3.06640625e-01,  -5.41992188e-02,\n",
       "         3.65234375e-01,  -9.13085938e-02,   1.32446289e-02,\n",
       "        -2.97851562e-02,  -1.11328125e-01,   1.85546875e-01,\n",
       "        -1.32812500e-01,   3.06396484e-02,   1.02050781e-01,\n",
       "         2.27050781e-02,   7.08007812e-02,   1.27929688e-01,\n",
       "         1.11694336e-02,   2.33398438e-01,  -6.73828125e-02,\n",
       "         2.21679688e-01,  -1.29882812e-01,  -1.06445312e-01,\n",
       "         1.20117188e-01,   1.97265625e-01,   1.18164062e-01,\n",
       "         4.68750000e-01,  -9.08203125e-02,  -8.34960938e-02,\n",
       "         2.21679688e-01,  -7.08007812e-03,  -1.47460938e-01,\n",
       "         9.27734375e-02,  -2.13623047e-02,  -6.59179688e-02,\n",
       "        -2.94189453e-02,  -2.53906250e-01,  -1.84326172e-02,\n",
       "        -9.08203125e-02,   1.78710938e-01,  -1.08886719e-01,\n",
       "         6.44531250e-02,   4.73632812e-02,  -6.34765625e-02,\n",
       "         5.00488281e-02,  -1.54418945e-02,   1.24023438e-01,\n",
       "         2.89062500e-01,   4.85839844e-02,  -3.20312500e-01,\n",
       "        -5.02929688e-02,  -6.07910156e-02,  -1.74804688e-01,\n",
       "        -1.80664062e-01,  -1.15234375e-01,   2.73437500e-01,\n",
       "        -3.10546875e-01,   1.34765625e-01,   5.51757812e-02,\n",
       "         5.03540039e-03,  -5.32226562e-02,  -1.70898438e-01,\n",
       "         1.16699219e-01,  -2.23632812e-01,   1.66015625e-01,\n",
       "        -1.40625000e-01,  -8.30078125e-02,  -1.92382812e-01,\n",
       "        -2.94921875e-01,  -5.64575195e-04,   5.03906250e-01,\n",
       "         3.71093750e-01,   1.24511719e-01,  -9.71679688e-02,\n",
       "        -1.06933594e-01,   2.85156250e-01,   8.34960938e-02,\n",
       "        -4.46777344e-02,  -2.92968750e-02,   6.59179688e-02,\n",
       "        -1.12304688e-01,   1.79443359e-02,  -1.31835938e-01,\n",
       "         7.27539062e-02,   1.63574219e-02,   2.28515625e-01,\n",
       "        -2.83203125e-02,   2.81250000e-01,  -1.37939453e-02,\n",
       "         8.98437500e-02,  -4.24194336e-03,  -2.91748047e-02,\n",
       "         6.10351562e-02,   1.13281250e-01,   1.33789062e-01,\n",
       "         2.62451172e-02,  -2.94921875e-01,  -5.78613281e-02,\n",
       "        -3.75976562e-02,   2.57812500e-01,   1.11816406e-01,\n",
       "         4.32128906e-02,   3.11279297e-02,   4.63867188e-02,\n",
       "         1.90429688e-02,   1.56250000e-01,  -1.09863281e-01,\n",
       "        -6.19506836e-03,  -2.96630859e-02,   1.58203125e-01,\n",
       "         1.53320312e-01,  -6.44531250e-02,   4.92095947e-04,\n",
       "        -7.27539062e-02,   1.66992188e-01,   4.98046875e-02,\n",
       "        -4.88281250e-03,  -2.23632812e-01,   2.34375000e-01,\n",
       "        -2.00195312e-01,   4.54101562e-02,   6.12792969e-02,\n",
       "        -4.17480469e-02,   1.13769531e-01,  -8.83789062e-02,\n",
       "        -2.01171875e-01,   4.07714844e-02,  -1.28906250e-01,\n",
       "        -6.44531250e-02,   8.74023438e-02,  -2.20703125e-01], dtype=float32)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdict[\"broken\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.76757812e-01,   2.94189453e-02,  -1.37695312e-01,\n",
       "        -1.14746094e-02,  -1.01074219e-01,   1.24023438e-01,\n",
       "         1.43554688e-01,   3.90625000e-03,   1.52343750e-01,\n",
       "         2.91015625e-01,  -2.39257812e-01,  -1.75781250e-02,\n",
       "        -1.23535156e-01,  -5.39550781e-02,  -9.17968750e-02,\n",
       "         6.20117188e-02,   1.29882812e-01,  -9.22851562e-02,\n",
       "        -2.26562500e-01,   1.37939453e-02,   8.30078125e-02,\n",
       "         1.30859375e-01,  -6.64062500e-02,  -1.29882812e-01,\n",
       "         1.84570312e-01,  -3.02734375e-02,  -1.95312500e-01,\n",
       "         2.55859375e-01,   2.35351562e-01,  -8.98437500e-02,\n",
       "        -2.25585938e-01,   5.78613281e-02,   1.12792969e-01,\n",
       "        -1.11328125e-01,  -3.29589844e-02,  -3.73535156e-02,\n",
       "         1.43554688e-01,  -1.37695312e-01,  -1.98242188e-01,\n",
       "         2.03125000e-01,  -7.42187500e-02,   5.32226562e-02,\n",
       "         6.78710938e-02,  -2.17285156e-02,   2.47070312e-01,\n",
       "         1.81640625e-01,  -1.21582031e-01,   3.24707031e-02,\n",
       "         1.39648438e-01,  -8.10546875e-02,  -2.94921875e-01,\n",
       "         2.67578125e-01,  -3.04687500e-01,  -2.51953125e-01,\n",
       "         7.47070312e-02,   9.66796875e-02,  -2.15820312e-01,\n",
       "        -3.45703125e-01,  -5.90820312e-02,  -4.63867188e-02,\n",
       "        -2.18505859e-02,   1.56250000e-01,   2.65625000e-01,\n",
       "        -1.13281250e-01,  -1.42578125e-01,  -2.16796875e-01,\n",
       "        -3.54003906e-02,   9.96093750e-02,  -2.02148438e-01,\n",
       "        -2.10937500e-01,  -3.39355469e-02,   1.88476562e-01,\n",
       "        -5.24902344e-03,  -1.77734375e-01,  -2.59765625e-01,\n",
       "        -6.93359375e-02,   2.08007812e-01,   7.27539062e-02,\n",
       "        -1.28906250e-01,  -2.57812500e-01,   1.50390625e-01,\n",
       "        -1.65039062e-01,   1.19140625e-01,  -2.65625000e-01,\n",
       "        -1.25976562e-01,  -1.88446045e-03,  -1.18164062e-01,\n",
       "         1.94335938e-01,  -7.32421875e-02,   1.84570312e-01,\n",
       "         1.62109375e-01,   1.79687500e-01,   3.69140625e-01,\n",
       "         5.37109375e-02,  -8.15429688e-02,  -2.09960938e-01,\n",
       "         1.18652344e-01,  -1.69921875e-01,  -2.24609375e-01,\n",
       "         7.66601562e-02,   2.94189453e-02,   1.17675781e-01,\n",
       "         2.28515625e-01,  -1.72851562e-01,   5.51757812e-02,\n",
       "        -6.73828125e-02,   6.07910156e-02,   2.10937500e-01,\n",
       "        -1.32812500e-01,  -2.77343750e-01,  -2.27355957e-03,\n",
       "        -8.39843750e-02,  -1.71661377e-03,  -9.71679688e-02,\n",
       "         1.15722656e-01,  -9.71679688e-02,  -6.25610352e-03,\n",
       "        -1.11816406e-01,  -3.58886719e-02,   6.93359375e-02,\n",
       "        -2.85156250e-01,  -1.67968750e-01,   4.10156250e-01,\n",
       "        -1.25000000e-01,  -1.44531250e-01,  -1.56250000e-01,\n",
       "         5.34667969e-02,  -2.67578125e-01,  -4.71191406e-02,\n",
       "        -6.05468750e-02,  -7.03125000e-02,  -1.15722656e-01,\n",
       "        -9.37500000e-02,  -1.63574219e-02,  -2.49023438e-01,\n",
       "         1.62353516e-02,  -2.61718750e-01,   1.74560547e-02,\n",
       "        -2.41210938e-01,  -6.44531250e-02,  -1.91406250e-01,\n",
       "         2.47070312e-01,   1.62109375e-01,   2.26562500e-01,\n",
       "        -1.19140625e-01,   1.22070312e-01,  -1.67968750e-01,\n",
       "        -3.78906250e-01,   1.87500000e-01,  -1.66992188e-01,\n",
       "         3.41796875e-01,  -1.56250000e-01,   2.36511230e-03,\n",
       "         2.27539062e-01,   1.13281250e-01,   1.22070312e-01,\n",
       "        -1.41601562e-01,  -2.51953125e-01,   3.36914062e-02,\n",
       "        -1.69921875e-01,  -6.78710938e-02,   2.05078125e-01,\n",
       "        -1.50390625e-01,  -5.27343750e-02,  -2.33398438e-01,\n",
       "        -1.41601562e-01,   8.83789062e-02,  -2.63671875e-01,\n",
       "        -6.00585938e-02,  -5.66406250e-02,  -1.72851562e-01,\n",
       "        -1.08886719e-01,  -3.06640625e-01,  -5.41992188e-02,\n",
       "         3.65234375e-01,  -9.13085938e-02,   1.32446289e-02,\n",
       "        -2.97851562e-02,  -1.11328125e-01,   1.85546875e-01,\n",
       "        -1.32812500e-01,   3.06396484e-02,   1.02050781e-01,\n",
       "         2.27050781e-02,   7.08007812e-02,   1.27929688e-01,\n",
       "         1.11694336e-02,   2.33398438e-01,  -6.73828125e-02,\n",
       "         2.21679688e-01,  -1.29882812e-01,  -1.06445312e-01,\n",
       "         1.20117188e-01,   1.97265625e-01,   1.18164062e-01,\n",
       "         4.68750000e-01,  -9.08203125e-02,  -8.34960938e-02,\n",
       "         2.21679688e-01,  -7.08007812e-03,  -1.47460938e-01,\n",
       "         9.27734375e-02,  -2.13623047e-02,  -6.59179688e-02,\n",
       "        -2.94189453e-02,  -2.53906250e-01,  -1.84326172e-02,\n",
       "        -9.08203125e-02,   1.78710938e-01,  -1.08886719e-01,\n",
       "         6.44531250e-02,   4.73632812e-02,  -6.34765625e-02,\n",
       "         5.00488281e-02,  -1.54418945e-02,   1.24023438e-01,\n",
       "         2.89062500e-01,   4.85839844e-02,  -3.20312500e-01,\n",
       "        -5.02929688e-02,  -6.07910156e-02,  -1.74804688e-01,\n",
       "        -1.80664062e-01,  -1.15234375e-01,   2.73437500e-01,\n",
       "        -3.10546875e-01,   1.34765625e-01,   5.51757812e-02,\n",
       "         5.03540039e-03,  -5.32226562e-02,  -1.70898438e-01,\n",
       "         1.16699219e-01,  -2.23632812e-01,   1.66015625e-01,\n",
       "        -1.40625000e-01,  -8.30078125e-02,  -1.92382812e-01,\n",
       "        -2.94921875e-01,  -5.64575195e-04,   5.03906250e-01,\n",
       "         3.71093750e-01,   1.24511719e-01,  -9.71679688e-02,\n",
       "        -1.06933594e-01,   2.85156250e-01,   8.34960938e-02,\n",
       "        -4.46777344e-02,  -2.92968750e-02,   6.59179688e-02,\n",
       "        -1.12304688e-01,   1.79443359e-02,  -1.31835938e-01,\n",
       "         7.27539062e-02,   1.63574219e-02,   2.28515625e-01,\n",
       "        -2.83203125e-02,   2.81250000e-01,  -1.37939453e-02,\n",
       "         8.98437500e-02,  -4.24194336e-03,  -2.91748047e-02,\n",
       "         6.10351562e-02,   1.13281250e-01,   1.33789062e-01,\n",
       "         2.62451172e-02,  -2.94921875e-01,  -5.78613281e-02,\n",
       "        -3.75976562e-02,   2.57812500e-01,   1.11816406e-01,\n",
       "         4.32128906e-02,   3.11279297e-02,   4.63867188e-02,\n",
       "         1.90429688e-02,   1.56250000e-01,  -1.09863281e-01,\n",
       "        -6.19506836e-03,  -2.96630859e-02,   1.58203125e-01,\n",
       "         1.53320312e-01,  -6.44531250e-02,   4.92095947e-04,\n",
       "        -7.27539062e-02,   1.66992188e-01,   4.98046875e-02,\n",
       "        -4.88281250e-03,  -2.23632812e-01,   2.34375000e-01,\n",
       "        -2.00195312e-01,   4.54101562e-02,   6.12792969e-02,\n",
       "        -4.17480469e-02,   1.13769531e-01,  -8.83789062e-02,\n",
       "        -2.01171875e-01,   4.07714844e-02,  -1.28906250e-01,\n",
       "        -6.44531250e-02,   8.74023438e-02,  -2.20703125e-01], dtype=float32)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "get_vector([\"broken\"],gdict,np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/serializers.py\", line 590, in dumps\n",
      "    return cloudpickle.dumps(obj, 2)\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/cloudpickle.py\", line 863, in dumps\n",
      "    cp.dump(obj)\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/cloudpickle.py\", line 260, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 224, in dump\n",
      "    self.save(obj)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 568, in save_tuple\n",
      "    save(element)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/cloudpickle.py\", line 406, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/cloudpickle.py\", line 549, in save_function_tuple\n",
      "    save(state)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 655, in save_dict\n",
      "    self._batch_setitems(obj.iteritems())\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 687, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 606, in save_list\n",
      "    self._batch_appends(iter(obj))\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 639, in _batch_appends\n",
      "    save(x)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/cloudpickle.py\", line 406, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/cloudpickle.py\", line 549, in save_function_tuple\n",
      "    save(state)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 655, in save_dict\n",
      "    self._batch_setitems(obj.iteritems())\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 687, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 606, in save_list\n",
      "    self._batch_appends(iter(obj))\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 639, in _batch_appends\n",
      "    save(x)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/cloudpickle.py\", line 406, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/cloudpickle.py\", line 549, in save_function_tuple\n",
      "    save(state)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 655, in save_dict\n",
      "    self._batch_setitems(obj.iteritems())\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 687, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 606, in save_list\n",
      "    self._batch_appends(iter(obj))\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 639, in _batch_appends\n",
      "    save(x)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/cloudpickle.py\", line 406, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/cloudpickle.py\", line 549, in save_function_tuple\n",
      "    save(state)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 655, in save_dict\n",
      "    self._batch_setitems(obj.iteritems())\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 687, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 606, in save_list\n",
      "    self._batch_appends(iter(obj))\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 642, in _batch_appends\n",
      "    save(tmp[0])\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/cloudpickle.py\", line 406, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/cloudpickle.py\", line 549, in save_function_tuple\n",
      "    save(state)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 655, in save_dict\n",
      "    self._batch_setitems(obj.iteritems())\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 687, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 606, in save_list\n",
      "    self._batch_appends(iter(obj))\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 642, in _batch_appends\n",
      "    save(tmp[0])\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/cloudpickle.py\", line 406, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/cloudpickle.py\", line 549, in save_function_tuple\n",
      "    save(state)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 655, in save_dict\n",
      "    self._batch_setitems(obj.iteritems())\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 687, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 606, in save_list\n",
      "    self._batch_appends(iter(obj))\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 642, in _batch_appends\n",
      "    save(tmp[0])\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 331, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 425, in save_reduce\n",
      "    save(state)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 655, in save_dict\n",
      "    self._batch_setitems(obj.iteritems())\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 687, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 331, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 425, in save_reduce\n",
      "    save(state)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 568, in save_tuple\n",
      "    save(element)\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 286, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/anaconda3/envs/QUEST/lib/python2.7/pickle.py\", line 492, in save_string\n",
      "    self.write(BINSTRING + pack(\"<i\", n) + obj)\n",
      "error: 'i' format requires -2147483648 <= number <= 2147483647\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Object too large to serialize: 'i' format requires -2147483648 <= number <= 2147483647",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-304-50cf83bf77cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicate_alignment6\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicate_alignment5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predicate2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforeach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/sql/dataframe.pyc\u001b[0m in \u001b[0;36mforeach\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforeach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforeach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mforeach\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessPartition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Force evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforeachPartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \"\"\"\n\u001b[0;32m-> 1055\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36msum\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0;36m6.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \"\"\"\n\u001b[0;32m-> 1046\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mfold\u001b[0;34m(self, zeroValue, op)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0;31m# zeroValue provided to each partition is unique from the one provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;31m# to the final reduce call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeroValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    814\u001b[0m         \"\"\"\n\u001b[1;32m    815\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36m_jrdd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2531\u001b[0m         wrapped_func = _wrap_function(self.ctx, self.func, self._prev_jrdd_deserializer,\n\u001b[0;32m-> 2532\u001b[0;31m                                       self._jrdd_deserializer, profiler)\n\u001b[0m\u001b[1;32m   2533\u001b[0m         python_rdd = self.ctx._jvm.PythonRDD(self._prev_jrdd.rdd(), wrapped_func,\n\u001b[1;32m   2534\u001b[0m                                              self.preservesPartitioning, self.is_barrier)\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36m_wrap_function\u001b[0;34m(sc, func, deserializer, serializer, profiler)\u001b[0m\n\u001b[1;32m   2432\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"serializer should not be empty\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2433\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2434\u001b[0;31m     \u001b[0mpickled_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincludes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_for_python_RDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2435\u001b[0m     return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n\u001b[1;32m   2436\u001b[0m                                   sc.pythonVer, broadcast_vars, sc._javaAccumulator)\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36m_prepare_for_python_RDD\u001b[0;34m(sc, command)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;31m# the serialized command will be compressed by broadcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCloudPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0mpickled_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickled_command\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 1M\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m         \u001b[0;31m# The broadcast will have same life cycle as created PythonRDD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/serializers.pyc\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Could not serialize object: %s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Object too large to serialize: 'i' format requires -2147483648 <= number <= 2147483647"
     ]
    }
   ],
   "source": [
    "predicate_alignment6=predicate_alignment5.select(\"predicate2\").foreach(gdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicate_alignment2 = predicate_alignment1.filter(predicate_alignment1.predicate!=aux_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.13 64-bit ('QUEST': conda)",
   "language": "python",
   "name": "python271364bitquestconda39a3e5c16cfd48579e21bcb7b60777eb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
