{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content\n",
    "    0. File Path\n",
    "    1. Load Vertices\n",
    "    2. Load Edges\n",
    "    3. Create Graph & Test\n",
    "    4. GST Requirements\n",
    "    5. GST Steps\n",
    "    6. BT-QA main_GST Steps ( Plan )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GST Requirements\n",
    "### Function: \n",
    "    call_main_GST\n",
    "    (QKG_file, cornerstone_file, qtype, answer_list_file, no_GST, gdict, verbose, gt,config,con)\n",
    "    \n",
    "### Corresponding Parameter\n",
    "    f1, f2, f4, f5, no_GST, gdict, verbose, gt1, config, context_file\n",
    "        \n",
    "    0. QKG_file            f1=argv[1] #input QKG\n",
    "    1. cornerstone_file    f2=argv[2] #input Cornerstones \n",
    "    2. qtype               f4=argv[3] #answer match / qtype\n",
    "    3. answer_list_file    f5=argv[4] #answer type /answer_list_file \n",
    "    4. no_GST              no_GST=int(argv[5]) #number of GSTs\n",
    "    5. gdict               gdict\n",
    "    6. verbose             verbose=int(argv[6])\n",
    "    7. gt\n",
    "    8. config\n",
    "    9. con                 context file\n",
    "    \n",
    "### Corresponding Value\n",
    "    0. f1 = \"./files/QKG_ques-q1\"  \n",
    "        *** What: KG \n",
    "        *** From: Generated by Data2Graph\n",
    "        *** How to use it in GST:\n",
    "        \n",
    "    1. f2 = \"./files/QKG_cornerstones_ques-q1\" \n",
    "        *** What: KG Gpickle \n",
    "        *** From: Generated by Data2Graph, cornerstones?? and them selected by ????\n",
    "        *** How to use it in GST:\n",
    "        \n",
    "    2. f4 = \"question_type.txt\" \n",
    "        *** What: question type\n",
    "        *** From: get_answer_types_from_questions.py\n",
    "        *** How to use it in GST:used to check the answer type and select related answer\n",
    "        \n",
    "    3. f5 = \"./files/Answer_list_ques-q1\" \n",
    "        \n",
    "        *** What: answer_list_file='./files/Answer_list_'+str(qid) only represent an address\n",
    "        *** From: path parameter\n",
    "        *** How to use it in GST: used to named answer-related address\n",
    "    \n",
    "    4. no_GST = 50 #Number of GSTs to be considered\n",
    "        *** What: \n",
    "        *** From: config\n",
    "        *** How to use it in GST:set the limited node number  \n",
    "        \n",
    "    5. gdict = \n",
    "            # gdict={}\n",
    "            # model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)  \n",
    "            # word_vectors = model.wv\n",
    "            # gdict=word_vectors\n",
    "            \n",
    "        *** What: word2vector\n",
    "        *** From: gensim.models.KeyedVectors\n",
    "        *** How to use it in GST: for calculate the Predicate weight(no need to used in BT-QA)\n",
    "\n",
    "    6. verbose=int(argv[6])      \n",
    "        *** What: To print intermediate statements in verbose manner make it 1, other wise 0 \n",
    "        *** From: Config\n",
    "        *** How to use it in GST:\n",
    "    \n",
    "    7. gt = set(['unknown'])\n",
    "        *** What: a set of answer, the initial is 'unknown'\n",
    "        *** From: \n",
    "        original from reformat_dataset_single.py\n",
    "        in get_formatted_docs function,  \n",
    "        fp.write('Answer\\t' + 'Unknown\\n')\n",
    "        *** How to use it in GST:\n",
    "        \n",
    "    8. config stream = open(\"config.yml\", 'r')\n",
    "        for line in stream:\n",
    "        if not line.startswith('#') and len(line)>1:\n",
    "            line=line.split(':')\n",
    "            config[line[0]]=line[1].strip()\n",
    "       \n",
    "    9. con = \"./files/context_ques-q1\"  \n",
    "        *** What: context_file, not be used in GST, should be deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. GST Steps\n",
    "    - 0. load graph & corner\n",
    "    - 1. initialize_queue \n",
    "        (combine the 'corner' with graph and get edges' cost between 'corner node' and 'question node' in graph. see the result T & Q)\n",
    "    - 2. get GST set\n",
    "    - 3. get answer type \n",
    "    - 4. trees with potential answers by filtering answer type from GST set\n",
    "    - 5. answering merge (need to be changed because mention node provide more convience)\n",
    "    - 6. find unique sets of answers and get result list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. BT-QA main_GST Steps ( Plan )\n",
    "### preprepare (libraries part)\n",
    "- 0. For graph part: \n",
    "    - add node property (only for 'entity' & 'mention' nodes): weight & matched \n",
    "         - reference: \"def add_node_weights\" in \"generate_graphs_from_triples.py\"\n",
    "        \n",
    "    - add edges property wight & wlist \n",
    "         - reference: \"def distribute_node_weights\" in \"generate_graphs_from_triples.py\"\n",
    "        \n",
    "    - add type node of all 'mention' node\n",
    "         - reference: \"def add_type_edges\" in \"generate_graphs_from_triples.py\"\n",
    "        \n",
    "    - change the id from 'number' to 'vocabulary: Node Type(doc/sent/clause/entity/mention/type)'\n",
    "        \n",
    "    - Structure:\n",
    "   \n",
    "            *Nodes:\n",
    "            - ID:'vocabulary: Node Type(doc/sent/clause/entity/mention/type)'\n",
    "            - Attribute:\n",
    "                (u“id”, {\n",
    "                ‘type’:“”\n",
    "                ‘attr1’:“”\n",
    "                ‘attr2’:“”\n",
    "                ‘attr3’:“”\n",
    "                ‘matched’:“” ##for matched questions' entities\n",
    "                ‘weight’:0.0 ##for matched weight between node and questions' entities\n",
    "                })\n",
    "            - the weight are calculted by ‘Jaccard Coefficient’\n",
    "\n",
    "            *Edges:\n",
    "            - Node1, Node2\n",
    "            - Attribute:\n",
    "            (u'node1’,\n",
    "             u'node2',\n",
    "             {'weight': 0.0,\n",
    "              'wlist': [0.0，0.0]})\n",
    "\n",
    "    - generate corner and save it into pickle \n",
    "        reference: \"generate_graphs_from triples in generate graph from triples.py\"\n",
    "\n",
    "\n",
    "- 1. Generate answer type from question\n",
    "     - reference: get_answer_types_from_questions.py\n",
    "    \n",
    "### steps: ( 24 functions need to be modified, 14 of them contains graph )\n",
    "- 0. load graph & corner\n",
    "- 1. initialize_queue (2 def)\n",
    "    (combine the 'corner' with graph and get edges' cost between 'corner node' and 'question node' in graph. see the result T & Q)\n",
    "- 2. get GST set (6 def)\n",
    "- 3. get answer type \n",
    "- 4. trees with potential answers by filtering answer type from GST set (4 def)\n",
    "- 5. answering merge (need to be changed because Entity node provide more convience) (2 def)\n",
    "- 6. find unique sets of answers and get result list (10 def)\n",
    "    \n",
    "    future plan: \n",
    "    I'll try to extract predicate and generate predicate node from clause to see if the precision will be enhanced or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.3.5:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.addPyFile('/usr/local/Cellar/apache-spark/2.4.1/libexec/jars/graphframes-0.7.0-spark2.4-s_2.11.jar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. RDD -> DataFrame -> GraphFrame (code need to be change when add attr)\n",
    "#2. GraphX -> GraphFrame (code no need to change when add attr) encounter problem：https://github.com/graphframes/graphframes/issues/359"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Code part\n",
    "### 7.1 preprepare (libraries part)\n",
    "### 7.1.1 modify the id from \"number\" to \"nodeType:Attr1:id\" (1.edges, 2.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 get answer type from quetion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "import sys\n",
    "from graphframes import *\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "# library \n",
    "sys.path.append(\"project/library\")\n",
    "import get_answer_types_from_questions as gtQType\n",
    "import get_all_subjects_predicates_from_questions as gtQSub\n",
    "from stanfordcorenlp import StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP(r'/Users/jeanxu/PycharmProjects/QUEST_TerminalTest/Code/stanford-corenlp-full-2018-10-05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prune the predicate terms from the query if the query has more than 'prune' number of terms\n",
    "prune=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'when is national day of England '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting potential answer type from question\n",
    "f1='question_type.txt'\n",
    "gtQType.get_answer_type_main(question,f1,nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting query terms from question.\n",
    "s1='question_subject_predicate.txt'\n",
    "gtQSub.get_sub_pred_ques_main(question,s1,nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_list=set()\n",
    "for l in open('auxiliary_verb_list.txt'):\n",
    "    l=l.strip()\n",
    "    aux_list.add(l.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'am',\n",
       " 'are',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'can',\n",
       " 'could',\n",
       " 'dare',\n",
       " 'did',\n",
       " 'do',\n",
       " 'done',\n",
       " 'had',\n",
       " 'has',\n",
       " 'have',\n",
       " 'is',\n",
       " 'may',\n",
       " 'might',\n",
       " 'must',\n",
       " 'need',\n",
       " 'ought',\n",
       " 'shall',\n",
       " 'should',\n",
       " 'was',\n",
       " 'were',\n",
       " 'will',\n",
       " 'would'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read entities of question\n",
    "s11=open(s1, 'r')\n",
    "q_ent = set()\n",
    "type_qent = {}\n",
    "for line in s11:\n",
    "    line = line.strip()\n",
    "    line = line.split()\n",
    "    s = line[0]\n",
    "    for i in range(1, len(line) - 1):\n",
    "        s += ' ' + line[i]\n",
    "    q_ent.add(s.lower())\n",
    "    type_qent[s.lower()] = line[len(line) - 1]\n",
    "if verbose:\n",
    "    print \"Query terms ->\", len(q_ent), q_ent\n",
    "if len(q_ent) > prune:\n",
    "    if verbose:\n",
    "        print \"Pruning..\"\n",
    "    p = frozenset(q_ent)\n",
    "    for s in p:\n",
    "        if type_qent[s] == 'P':\n",
    "            q_ent.remove(s)\n",
    "\n",
    "if verbose:\n",
    "    print \"Without Predicate Query terms ->\", len(q_ent), q_ent\n",
    "\n",
    "p = frozenset(q_ent)\n",
    "for s in p:\n",
    "    if s in aux_list and type_qent[s] == 'P':\n",
    "        q_ent.remove(s)\n",
    "\n",
    "if verbose:\n",
    "    print \"Without Auxiliary Query terms ->\", len(q_ent), q_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'england national day': 'NE', 'is': 'P'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_qent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'england national day'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_ent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. File Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "File_verticesTextRDD = \"/Users/jeanxu/Documents/UniLU/0_MasterThesis/4_Spark/ReferenceFromPaul/Graph-Small/Vertices/part-*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "File_edgesTextRDD = \"/Users/jeanxu/Documents/UniLU/0_MasterThesis/4_Spark/ReferenceFromPaul/Graph-Small/Edges/part-*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "verticesText0 = spark.read.csv(File_verticesTextRDD, header='false', inferSchema='false', sep='\\t')\n",
    "#rdd=sc.textFile(File_verticesTextRDD).map(lambda line : line.split('\\t')).toDF()\n",
    "#rdd.createOrReplaceTempView(\"vertices\")\n",
    "#rdd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+---+--------------------+-------------------+------+\n",
      "|     _c0|_c1|_c2|                 _c3|                _c4|   _c5|\n",
      "+--------+---+---+--------------------+-------------------+------+\n",
      "|Sentence|  0|  1|Politics of Burun...|Politics of Burundi| $END$|\n",
      "|Sentence|  1|  2|Executive power i...|Politics of Burundi| $END$|\n",
      "|Sentence|  2|  3|Legislative power...|Politics of Burundi| $END$|\n",
      "|Sentence|  3|  4|The political lan...|Politics of Burundi| $END$|\n",
      "|Sentence|  4|  5|The current Presi...|Politics of Burundi| $END$|\n",
      "|Sentence|  5|  6|Nkurunziza was th...|Politics of Burundi| $END$|\n",
      "|Sentence|  6|  7|In November 1995,...|Politics of Burundi| $END$|\n",
      "|Sentence|  7|  8|In July 1996, for...|Politics of Burundi| $END$|\n",
      "|Sentence|  8|  9|He declared himse...|Politics of Burundi| $END$|\n",
      "|Sentence|  9| 10|Widespread condem...|Politics of Burundi| $END$|\n",
      "+--------+---+---+--------------------+-------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "verticesText0.show(10)\n",
    "# Document：(id, DocumentProperty(title, url, domain, tweets))\n",
    "# Sentence：(id, SentenceProperty(sentenceNumber, sentenceContent, root, links.toList(lenth!=0)))\n",
    "# Clause：  (id, ClauseProperty(clause,clauseType,subject,relation,argument,root,additional.toList))\n",
    "# Mention： (id, MentionProperty(mention, NERtype, entity))\n",
    "# Entity：  (id, EntityProperty(entity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##exmaple:\n",
    "# Document\t5691614\tOffice of the United Nations High Commissioner for Human Rights\t\t\tList() $END$\n",
    "# Document\t5691615\tGecko\t\t\tList() $END$\n",
    "# Document\t5691616\tMaeshowe\t\t\tList() $END$\n",
    "# Document\t5691617\tKiwi\t\t\tList() $END$\n",
    "# Document\t5691618\tIblis\t\t\tList() $END$\n",
    "# Document\t5691619\tNumber\t\t\tList() $END$\n",
    "\n",
    "# Sentence\t0\t1\tPolitics of Burundi takes place in a framework of a transitional presidential representative democratic republic, whereby the President of Burundi is both head of state and head of government, and of a multi-party system.\tPolitics of Burundi\t $END$\n",
    "# Sentence\t1\t2\tExecutive power is exercised by the government.\tPolitics of Burundi\t $END$\n",
    "\n",
    "# Clause\t24971\t(\"This method\", \"was used\", \"by an estimated 38 million couples worldwide\", \"in 1991\")\tSVA\tThis method\twas used\tby an estimated 38 million couples worldwide\tCoitus interruptus-3\tin 1991\t\t $END$\n",
    "# Clause\t24972\t(\"what\", \"was transpiring\", \"quickly\", \"spread and everybody\")\tUNKNOWN\twhat\twas transpiring\tquickly\tFirst Council of Constantinople-36\tspread and everybody\t\t $END$\n",
    "# Clause\t24973\t(\"The news of what was transpiring quickly spread and everybody\", \"rushed\", \"to the church\")\tSVA\tThe news of what was transpiring quickly spread and everybody\trushed\tto the church\tFirst Council of Constantinople-36\t\t $END$\n",
    "\n",
    "# Mention\t24975\tFreedom House\tMISC\tFreedom_House $END$\n",
    "# Mention\t24976\tNGO\tORGANIZATION\tNon-governmental_organization $END$\n",
    "# Mention\t24977\tObiang\tPERSON\tTeodoro_Obiang_Nguema_Mbasogo $END$\n",
    "\n",
    "# Entity\t8593089\tJosephine_of_Leuchtenberg $END$\n",
    "# Entity\t8593090\tPublic_Auditorium $END$\n",
    "# Entity\t8593091\tWest_Plains,_Missouri $END$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./GraphExample.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "verticesText1 = verticesText0.select(\"_c1\",\"_c0\",\"_c2\",\"_c3\",\"_c4\")\\\n",
    ".withColumnRenamed(\"_c0\", \"nodeType\").withColumnRenamed(\"_c1\", \"id\")\\\n",
    ".withColumnRenamed(\"_c2\", \"attr1\").withColumnRenamed(\"_c3\", \"attr2\")\\\n",
    ".withColumnRenamed(\"_c4\", \"attr3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+-------------------+\n",
      "| id|nodeType|attr1|               attr2|              attr3|\n",
      "+---+--------+-----+--------------------+-------------------+\n",
      "|  0|Sentence|    1|Politics of Burun...|Politics of Burundi|\n",
      "|  1|Sentence|    2|Executive power i...|Politics of Burundi|\n",
      "|  2|Sentence|    3|Legislative power...|Politics of Burundi|\n",
      "|  3|Sentence|    4|The political lan...|Politics of Burundi|\n",
      "|  4|Sentence|    5|The current Presi...|Politics of Burundi|\n",
      "|  5|Sentence|    6|Nkurunziza was th...|Politics of Burundi|\n",
      "|  6|Sentence|    7|In November 1995,...|Politics of Burundi|\n",
      "|  7|Sentence|    8|In July 1996, for...|Politics of Burundi|\n",
      "|  8|Sentence|    9|He declared himse...|Politics of Burundi|\n",
      "|  9|Sentence|   10|Widespread condem...|Politics of Burundi|\n",
      "+---+--------+-----+--------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "verticesText1.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 add node attributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verticesText2=verticesText1.withColumn(\"did\", \"\").withColumn(\"dtitle\", \"\").withColumn(\"sid\", \"\").withColumn(\"weight\", 0.0).withColumn(\"matched\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verticesText1=verticesText1.withColumn(\"did\", lit(0)).withColumn(\"dtitle\", lit(\"\")).withColumn(\"sid\", lit(0)).withColumn(\"weight\", lit(0)).withColumn(\"matched\", lit(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verticesText1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc_verticesText=verticesText1.filter(\"nodeType = 'Document'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------------------+-----+-----+\n",
      "|  id|nodeType|               attr1|attr2|attr3|\n",
      "+----+--------+--------------------+-----+-----+\n",
      "|4526|Document|     Africa Alphabet| null| null|\n",
      "|4527|Document|               Brain| null| null|\n",
      "|4528|Document|     Andreas Aagesen| null| null|\n",
      "|4529|Document|Australian Broadc...| null| null|\n",
      "|4530|Document|The Elephant 6 Re...| null| null|\n",
      "|4531|Document|Albert of Branden...| null| null|\n",
      "|4532|Document|Telecommunication...| null| null|\n",
      "|4533|Document|                 DMA| null| null|\n",
      "|4534|Document|         Alford plea| null| null|\n",
      "|4535|Document|        Claude Piron| null| null|\n",
      "|4536|Document|Full disclosure (...| null| null|\n",
      "|4537|Document|    Anthem of Europe| null| null|\n",
      "|4538|Document|             Cytosol| null| null|\n",
      "|4539|Document|            Barbagia| null| null|\n",
      "|4540|Document|             Calcium| null| null|\n",
      "|4541|Document|   Chomsky hierarchy| null| null|\n",
      "|4542|Document| Critical philosophy| null| null|\n",
      "|4543|Document|   Cultural movement| null| null|\n",
      "|4544|Document|          Braveheart| null| null|\n",
      "|4545|Document|                Bill| null| null|\n",
      "+----+--------+--------------------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_verticesText.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add attributes--documnets\n",
    "doc_verticesText=doc_verticesText.withColumn(\"did\", doc_verticesText.id).withColumn(\"dtitle\", doc_verticesText.attr1).drop(\"attr1\").drop(\"attr2\").drop(\"attr3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----+--------------------+\n",
      "|  id|nodeType| did|              dtitle|\n",
      "+----+--------+----+--------------------+\n",
      "|4526|Document|4526|     Africa Alphabet|\n",
      "|4527|Document|4527|               Brain|\n",
      "|4528|Document|4528|     Andreas Aagesen|\n",
      "|4529|Document|4529|Australian Broadc...|\n",
      "|4530|Document|4530|The Elephant 6 Re...|\n",
      "|4531|Document|4531|Albert of Branden...|\n",
      "|4532|Document|4532|Telecommunication...|\n",
      "|4533|Document|4533|                 DMA|\n",
      "|4534|Document|4534|         Alford plea|\n",
      "|4535|Document|4535|        Claude Piron|\n",
      "|4536|Document|4536|Full disclosure (...|\n",
      "|4537|Document|4537|    Anthem of Europe|\n",
      "|4538|Document|4538|             Cytosol|\n",
      "|4539|Document|4539|            Barbagia|\n",
      "|4540|Document|4540|             Calcium|\n",
      "|4541|Document|4541|   Chomsky hierarchy|\n",
      "|4542|Document|4542| Critical philosophy|\n",
      "|4543|Document|4543|   Cultural movement|\n",
      "|4544|Document|4544|          Braveheart|\n",
      "|4545|Document|4545|                Bill|\n",
      "+----+--------+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_verticesText.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sentence\n",
    "sen_verticesText=verticesText1.filter(\"nodeType = 'Sentence'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+-------------------+\n",
      "| id|nodeType|attr1|               attr2|              attr3|\n",
      "+---+--------+-----+--------------------+-------------------+\n",
      "|  0|Sentence|    1|Politics of Burun...|Politics of Burundi|\n",
      "|  1|Sentence|    2|Executive power i...|Politics of Burundi|\n",
      "|  2|Sentence|    3|Legislative power...|Politics of Burundi|\n",
      "|  3|Sentence|    4|The political lan...|Politics of Burundi|\n",
      "|  4|Sentence|    5|The current Presi...|Politics of Burundi|\n",
      "|  5|Sentence|    6|Nkurunziza was th...|Politics of Burundi|\n",
      "|  6|Sentence|    7|In November 1995,...|Politics of Burundi|\n",
      "|  7|Sentence|    8|In July 1996, for...|Politics of Burundi|\n",
      "|  8|Sentence|    9|He declared himse...|Politics of Burundi|\n",
      "|  9|Sentence|   10|Widespread condem...|Politics of Burundi|\n",
      "| 10|Sentence|   11|Buyoya agreed in ...|Politics of Burundi|\n",
      "| 11|Sentence|   12|Nonetheless, figh...|Politics of Burundi|\n",
      "| 12|Sentence|   13|In June 1998, Buy...|Politics of Burundi|\n",
      "| 13|Sentence|   14|After facilitator...|Politics of Burundi|\n",
      "| 14|Sentence|   15|Under Mandela the...|Politics of Burundi|\n",
      "| 15|Sentence|   16|In April 2015 the...|Politics of Burundi|\n",
      "| 16|Sentence|   17|Protests in the c...|Politics of Burundi|\n",
      "| 17|Sentence|   18|The president is ...|Politics of Burundi|\n",
      "| 18|Sentence|   19|He nominates two ...|Politics of Burundi|\n",
      "| 19|Sentence|   20|The National Asse...|Politics of Burundi|\n",
      "+---+--------+-----+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sen_verticesText.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1411580"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_verticesText.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_verticesTextJ=sen_verticesText.join(doc_verticesText.select(\"did\",\"dtitle\"),sen_verticesText.attr3==doc_verticesText.dtitle, \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----+--------------------+--------------------+-------+--------------------+\n",
      "|     id|nodeType|attr1|               attr2|               attr3|    did|              dtitle|\n",
      "+-------+--------+-----+--------------------+--------------------+-------+--------------------+\n",
      "|7282397|Sentence|    1|   A \"Hello, World!\"|&quot;Hello, Worl...|5691624|&quot;Hello, Worl...|\n",
      "|7282398|Sentence|    2|program generally...|&quot;Hello, Worl...|5691624|&quot;Hello, Worl...|\n",
      "|7282399|Sentence|    3|                   .|&quot;Hello, Worl...|5691624|&quot;Hello, Worl...|\n",
      "|7282400|Sentence|    4|Because it is ver...|&quot;Hello, Worl...|5691624|&quot;Hello, Worl...|\n",
      "|7282401|Sentence|    5|   A \"Hello, World!\"|&quot;Hello, Worl...|5691624|&quot;Hello, Worl...|\n",
      "|7282402|Sentence|    6|program is tradit...|&quot;Hello, Worl...|5691624|&quot;Hello, Worl...|\n",
      "|7282403|Sentence|    7|       Hello, world!|&quot;Hello, Worl...|5691624|&quot;Hello, Worl...|\n",
      "|7282404|Sentence|    8|is also tradition...|&quot;Hello, Worl...|5691624|&quot;Hello, Worl...|\n",
      "|7282405|Sentence|    9|While small test ...|&quot;Hello, Worl...|5691624|&quot;Hello, Worl...|\n",
      "|7282406|Sentence|   10|as a test message...|&quot;Hello, Worl...|5691624|&quot;Hello, Worl...|\n",
      "|7282407|Sentence|   11|The example progr...|&quot;Hello, Worl...|5691624|&quot;Hello, Worl...|\n",
      "|7282408|Sentence|   12|The phrase is div...|&quot;Hello, Worl...|5691624|&quot;Hello, Worl...|\n",
      "|7282409|Sentence|   13|The previous exam...|&quot;Hello, Worl...|5691624|&quot;Hello, Worl...|\n",
      "|7282410|Sentence|   14|The Jargon File c...|&quot;Hello, Worl...|5691624|&quot;Hello, Worl...|\n",
      "|7282411|Sentence|   15|This claim is sup...|&quot;Hello, Worl...|5691624|&quot;Hello, Worl...|\n",
      "|7282412|Sentence|   16|For modern langua...|&quot;Hello, Worl...|5691624|&quot;Hello, Worl...|\n",
      "|7282413|Sentence|   17|For example, the ...|&quot;Hello, Worl...|5691624|&quot;Hello, Worl...|\n",
      "|7282414|Sentence|   18|While some langua...|&quot;Hello, Worl...|5691624|&quot;Hello, Worl...|\n",
      "|7282415|Sentence|   19|Mark Guzdial and ...|&quot;Hello, Worl...|5691624|&quot;Hello, Worl...|\n",
      "|7282416|Sentence|   20|There are many va...|&quot;Hello, Worl...|5691624|&quot;Hello, Worl...|\n",
      "+-------+--------+-----+--------------------+--------------------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sen_verticesTextJ.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1410800"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_verticesTextJ.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_verticesText=sen_verticesTextJ.withColumn(\"sid\", sen_verticesTextJ.attr1).drop(\"attr1\").drop(\"attr2\").drop(\"attr3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+--------------------+---+\n",
      "|     id|nodeType|    did|              dtitle|sid|\n",
      "+-------+--------+-------+--------------------+---+\n",
      "|7282397|Sentence|5691624|&quot;Hello, Worl...|  1|\n",
      "|7282398|Sentence|5691624|&quot;Hello, Worl...|  2|\n",
      "|7282399|Sentence|5691624|&quot;Hello, Worl...|  3|\n",
      "|7282400|Sentence|5691624|&quot;Hello, Worl...|  4|\n",
      "|7282401|Sentence|5691624|&quot;Hello, Worl...|  5|\n",
      "|7282402|Sentence|5691624|&quot;Hello, Worl...|  6|\n",
      "|7282403|Sentence|5691624|&quot;Hello, Worl...|  7|\n",
      "|7282404|Sentence|5691624|&quot;Hello, Worl...|  8|\n",
      "|7282405|Sentence|5691624|&quot;Hello, Worl...|  9|\n",
      "|7282406|Sentence|5691624|&quot;Hello, Worl...| 10|\n",
      "|7282407|Sentence|5691624|&quot;Hello, Worl...| 11|\n",
      "|7282408|Sentence|5691624|&quot;Hello, Worl...| 12|\n",
      "|7282409|Sentence|5691624|&quot;Hello, Worl...| 13|\n",
      "|7282410|Sentence|5691624|&quot;Hello, Worl...| 14|\n",
      "|7282411|Sentence|5691624|&quot;Hello, Worl...| 15|\n",
      "|7282412|Sentence|5691624|&quot;Hello, Worl...| 16|\n",
      "|7282413|Sentence|5691624|&quot;Hello, Worl...| 17|\n",
      "|7282414|Sentence|5691624|&quot;Hello, Worl...| 18|\n",
      "|7282415|Sentence|5691624|&quot;Hello, Worl...| 19|\n",
      "|7282416|Sentence|5691624|&quot;Hello, Worl...| 20|\n",
      "+-------+--------+-------+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sen_verticesText.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "##clause \n",
    "clause_verticesText=verticesText1.filter(\"nodeType = 'Clause'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------------------+-----+--------------------+\n",
      "|  id|nodeType|               attr1|attr2|               attr3|\n",
      "+----+--------+--------------------+-----+--------------------+\n",
      "|4559|  Clause|(\"A significant c...|  SVA|A significant con...|\n",
      "|4560|  Clause|(\"by the French r...|  SVO|by the French res...|\n",
      "|4561|  Clause|(\"quinine and str...|  SVC|quinine and stryc...|\n",
      "|4562|  Clause|(\"strychnine\", \"i...|  SVC|          strychnine|\n",
      "|4563|  Clause|(\"Some writers\", ...|  SVO|        Some writers|\n",
      "|4564|  Clause|(\"those\", \"would ...|  SVO|               those|\n",
      "|4565|  Clause|(\"The English Cha...|  SVC|The English Chann...|\n",
      "|4566|  Clause|(\"Johnston\", \"res...|  SVO|            Johnston|\n",
      "|4567|  Clause|(\"Tupper\", \"becam...|  SVO|              Tupper|\n",
      "|4568|  Clause|(\"His father\", \"m...|  SVA|          His father|\n",
      "|4569|  Clause|(\"Many physicists...|  SVA|     Many physicists|\n",
      "|4570|  Clause|(\"of quantum mech...|  SVC|of quantum mechanics|\n",
      "|4571|  Clause|(\"The King\", \"app...|  SVO|            The King|\n",
      "|4572|  Clause|(\"the band\", \"spl...|  SVA|            the band|\n",
      "|4573|  Clause|(\"they\", \"had bui...|  SVO|                they|\n",
      "|4574|  Clause|(\"Channel 4\", \"ha...|  SVO|           Channel 4|\n",
      "|4575|  Clause|(\"the same logo\",...|  SVO|       the same logo|\n",
      "|4576|  Clause|(\"Others\", \"agree...| SVOC|              Others|\n",
      "|4577|  Clause|(\"some portion of...|  SVC|some portion of t...|\n",
      "|4578|  Clause|(\"the Kingdom of ...|  SVA|the Kingdom of Judah|\n",
      "+----+--------+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clause_verticesText.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------------------+-------+------------+-------+------------+\n",
      "|    src|    dst|              label| src_id|src_nodeType| dst_id|dst_nodeType|\n",
      "+-------+-------+-------------------+-------+------------+-------+------------+\n",
      "|1234113| 100010|contains the clause|1234113|    Sentence| 100010|      Clause|\n",
      "|3875588|1000240|contains the clause|3875588|    Sentence|1000240|      Clause|\n",
      "|3650624|1000280|contains the clause|3650624|    Sentence|1000280|      Clause|\n",
      "|2068926|1000665|contains the clause|2068926|    Sentence|1000665|      Clause|\n",
      "| 467648|1000795|contains the clause| 467648|    Sentence|1000795|      Clause|\n",
      "| 233944|1000839|contains the clause| 233944|    Sentence|1000839|      Clause|\n",
      "|4022932|1000888|contains the clause|4022932|    Sentence|1000888|      Clause|\n",
      "|1212133| 100140|contains the clause|1212133|    Sentence| 100140|      Clause|\n",
      "| 452611|1001866|contains the clause| 452611|    Sentence|1001866|      Clause|\n",
      "|1487892|1002011|contains the clause|1487892|    Sentence|1002011|      Clause|\n",
      "|1525764|1002185|contains the clause|1525764|    Sentence|1002185|      Clause|\n",
      "|1455756| 100227|contains the clause|1455756|    Sentence| 100227|      Clause|\n",
      "|2791683|1002442|contains the clause|2791683|    Sentence|1002442|      Clause|\n",
      "|2753656| 100263|contains the clause|2753656|    Sentence| 100263|      Clause|\n",
      "|3182725|1002783|contains the clause|3182725|    Sentence|1002783|      Clause|\n",
      "|1212312|1002883|contains the clause|1212312|    Sentence|1002883|      Clause|\n",
      "|1212752|1002887|contains the clause|1212752|    Sentence|1002887|      Clause|\n",
      "|3082848| 100320|contains the clause|3082848|    Sentence| 100320|      Clause|\n",
      "|3036946|1003202|contains the clause|3036946|    Sentence|1003202|      Clause|\n",
      "|3486666|1003366|contains the clause|3486666|    Sentence|1003366|      Clause|\n",
      "+-------+-------+-------------------+-------+------------+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edgesText3.filter(\"label = 'contains the clause'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "clause_verticesTextJ=clause_verticesText.join(edgesText3.select(\"src_id\",\"src_nodeType\",\"dst_id\",\"dst_nodeType\"), clause_verticesText.id==edgesText3.dst_id, \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "clause_verticesTextJ=clause_verticesTextJ.drop(\"src_nodeType\").drop(\"dst_id\").drop(\"dst_nodeType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------------+-----+--------------------+-------+\n",
      "|     id|nodeType|               attr1|attr2|               attr3| src_id|\n",
      "+-------+--------+--------------------+-----+--------------------+-------+\n",
      "| 100010|  Clause|(\"Kerensky\", \"ord...|  SVO|            Kerensky|1234113|\n",
      "|1000240|  Clause|(\"to the paternal...|  SVC|to the paternal h...|3875588|\n",
      "|1000280|  Clause|(\"roughly speakin...|  SVO|roughly speaking ...|3650624|\n",
      "|1000665|  Clause|(\"sympatric speci...|  SVC|sympatric speciation|2068926|\n",
      "|1000795|  Clause|(\"The growth of t...|  SVO|The growth of the...| 467648|\n",
      "|1000839|  Clause|(\"the priests\", \"...|  SVA|         the priests| 233944|\n",
      "|1000888|  Clause|(\"the absolute va...|  SVC|  the absolute value|4022932|\n",
      "| 100140|  Clause|(\"A memorial plaq...|  SVA|   A memorial plaque|1212133|\n",
      "|1001866|  Clause|(\"1QDan\", \"is\", \"...|  SVC|               1QDan| 452611|\n",
      "|1002011|  Clause|(\"the use of Afri...|  SVC|the use of Africa...|1487892|\n",
      "|1002185|  Clause|(\"he\", \"won\", \"th...|  SVO|                  he|1525764|\n",
      "| 100227|  Clause|(\"The following y...|  SVC|  The following year|1455756|\n",
      "|1002442|  Clause|(\"Beetles\", \"are\"...|  SVC|             Beetles|2791683|\n",
      "| 100263|  Clause|(\"it\", \"changes\",...|  SVO|                  it|2753656|\n",
      "|1002783|  Clause|(\"Disraeli\", \"hop...|  SVA|            Disraeli|3182725|\n",
      "|1002883|  Clause|(\"they\", \"reject\"...|  SVO|                they|1212312|\n",
      "|1002887|  Clause|(\"The result\", \"w...|  SVC|          The result|1212752|\n",
      "| 100320|  Clause|(\"chicks\", \"fledg...|  SVO|              chicks|3082848|\n",
      "|1003202|  Clause|(\"of stable indiv...|  SVC|of stable indivis...|3036946|\n",
      "|1003366|  Clause|(\"they\", \"emphasi...|  SVO|                they|3486666|\n",
      "+-------+--------+--------------------+-----+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clause_verticesTextJ.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+--------------------+---+\n",
      "|     id|nodeType|    did|              dtitle|sid|\n",
      "+-------+--------+-------+--------------------+---+\n",
      "|7282397|Sentence|5691624|&quot;Hello, Worl...|  1|\n",
      "|7282398|Sentence|5691624|&quot;Hello, Worl...|  2|\n",
      "|7282399|Sentence|5691624|&quot;Hello, Worl...|  3|\n",
      "|7282400|Sentence|5691624|&quot;Hello, Worl...|  4|\n",
      "|7282401|Sentence|5691624|&quot;Hello, Worl...|  5|\n",
      "|7282402|Sentence|5691624|&quot;Hello, Worl...|  6|\n",
      "|7282403|Sentence|5691624|&quot;Hello, Worl...|  7|\n",
      "|7282404|Sentence|5691624|&quot;Hello, Worl...|  8|\n",
      "|7282405|Sentence|5691624|&quot;Hello, Worl...|  9|\n",
      "|7282406|Sentence|5691624|&quot;Hello, Worl...| 10|\n",
      "|7282407|Sentence|5691624|&quot;Hello, Worl...| 11|\n",
      "|7282408|Sentence|5691624|&quot;Hello, Worl...| 12|\n",
      "|7282409|Sentence|5691624|&quot;Hello, Worl...| 13|\n",
      "|7282410|Sentence|5691624|&quot;Hello, Worl...| 14|\n",
      "|7282411|Sentence|5691624|&quot;Hello, Worl...| 15|\n",
      "|7282412|Sentence|5691624|&quot;Hello, Worl...| 16|\n",
      "|7282413|Sentence|5691624|&quot;Hello, Worl...| 17|\n",
      "|7282414|Sentence|5691624|&quot;Hello, Worl...| 18|\n",
      "|7282415|Sentence|5691624|&quot;Hello, Worl...| 19|\n",
      "|7282416|Sentence|5691624|&quot;Hello, Worl...| 20|\n",
      "+-------+--------+-------+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sen_verticesText.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+-----+-----+------+\n",
      "| id|nodeType|attr1|attr2|attr3|src_id|\n",
      "+---+--------+-----+-----+-----+------+\n",
      "+---+--------+-----+-----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clause_verticesTextJ.filter((clause_verticesTextJ[\"src_id\"] == \"\") | clause_verticesTextJ[\"src_id\"].isNull() | isnan(clause_verticesTextJ[\"src_id\"])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x115cbc990>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = SparkConf()\n",
    "conf.set(\"spark.sql.crossJoin.enabled\", \"true\")  # 避免Spark SQL在Linux执行成功，而放在自开发平台上失败的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.Builder at 0x1106ef690>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SparkSession.builder.config(\"spark.sql.crossJoin.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-245-2c2c1604aa0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrossJoin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'true' is not defined"
     ]
    }
   ],
   "source": [
    "pyspark.sql.crossJoin.enabled=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "clause_verticesText=clause_verticesTextJ.join(sen_verticesText.select(\"id\",\"did\",\"dtitle\",\"sid\"), sen_verticesText.id==clause_verticesTextJ.src_id, \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "u'Detected implicit cartesian product for INNER join between logical plans\\nProject [id#1842, nodeType#1836, attr1#1848, attr2#1854, attr3#1860, src_id#1288]\\n+- Join Inner, ((id#1842 = src_id#1288) && (id#1842 = dst_id#1429))\\n   :- Project [_c1#559 AS id#1842, _c0#558 AS nodeType#1836, _c2#560 AS attr1#1848, _c3#561 AS attr2#1854, _c4#562 AS attr3#1860]\\n   :  +- Filter ((isnotnull(_c0#558) && (_c0#558 = Clause)) && isnotnull(_c1#559))\\n   :     +- Relation[_c0#558,_c1#559,_c2#560,_c3#561,_c4#562,_c5#563] csv\\n   +- Project [src_id#1288, id#700 AS dst_id#1429]\\n      +- Join Inner, ((src_id#1288 = id#700) && (dst#892 = id#700))\\n         :- Project [dst#892, id#700 AS src_id#1288]\\n         :  +- Join Inner, (src#871 = id#700)\\n         :     :- Project [translate(_c0#852, Edge(, ) AS src#871, _c1#853 AS dst#892]\\n         :     :  +- Filter (isnotnull(translate(_c0#852, Edge(, )) && isnotnull(_c1#853))\\n         :     :     +- Relation[_c0#852,_c1#853,_c2#854] csv\\n         :     +- Project [_c1#559 AS id#700]\\n         :        +- Filter isnotnull(_c1#559)\\n         :           +- Relation[_c0#558,_c1#559,_c2#560,_c3#561,_c4#562,_c5#563] csv\\n         +- Project [_c1#559 AS id#700]\\n            +- Filter isnotnull(_c1#559)\\n               +- Relation[_c0#558,_c1#559,_c2#560,_c3#561,_c4#562,_c5#563] csv\\nand\\nProject [id#4232, did#2264, dtitle#2271, attr1#1848 AS sid#2443]\\n+- Join Inner, (attr3#1860 = dtitle#2271)\\n   :- Project [_c1#559 AS id#4232, _c2#560 AS attr1#1848, _c4#562 AS attr3#1860]\\n   :  +- Filter ((isnotnull(_c0#558) && (_c0#558 = Sentence)) && isnotnull(_c4#562))\\n   :     +- Relation[_c0#558,_c1#559,_c2#560,_c3#561,_c4#562,_c5#563] csv\\n   +- Project [_c1#559 AS did#2264, _c2#560 AS dtitle#2271]\\n      +- Filter ((isnotnull(_c0#558) && (_c0#558 = Document)) && isnotnull(_c2#560))\\n         +- Relation[_c0#558,_c1#559,_c2#560,_c3#561,_c4#562,_c5#563] csv\\nJoin condition is missing or trivial.\\nEither: use the CROSS JOIN syntax to allow cartesian products between these\\nrelations, or: enable implicit cartesian products by setting the configuration\\nvariable spark.sql.crossJoin.enabled=true;'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-243-6a1a389266f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclause_verticesText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/sql/dataframe.pyc\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \"\"\"\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.1/libexec/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.1/libexec/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: u'Detected implicit cartesian product for INNER join between logical plans\\nProject [id#1842, nodeType#1836, attr1#1848, attr2#1854, attr3#1860, src_id#1288]\\n+- Join Inner, ((id#1842 = src_id#1288) && (id#1842 = dst_id#1429))\\n   :- Project [_c1#559 AS id#1842, _c0#558 AS nodeType#1836, _c2#560 AS attr1#1848, _c3#561 AS attr2#1854, _c4#562 AS attr3#1860]\\n   :  +- Filter ((isnotnull(_c0#558) && (_c0#558 = Clause)) && isnotnull(_c1#559))\\n   :     +- Relation[_c0#558,_c1#559,_c2#560,_c3#561,_c4#562,_c5#563] csv\\n   +- Project [src_id#1288, id#700 AS dst_id#1429]\\n      +- Join Inner, ((src_id#1288 = id#700) && (dst#892 = id#700))\\n         :- Project [dst#892, id#700 AS src_id#1288]\\n         :  +- Join Inner, (src#871 = id#700)\\n         :     :- Project [translate(_c0#852, Edge(, ) AS src#871, _c1#853 AS dst#892]\\n         :     :  +- Filter (isnotnull(translate(_c0#852, Edge(, )) && isnotnull(_c1#853))\\n         :     :     +- Relation[_c0#852,_c1#853,_c2#854] csv\\n         :     +- Project [_c1#559 AS id#700]\\n         :        +- Filter isnotnull(_c1#559)\\n         :           +- Relation[_c0#558,_c1#559,_c2#560,_c3#561,_c4#562,_c5#563] csv\\n         +- Project [_c1#559 AS id#700]\\n            +- Filter isnotnull(_c1#559)\\n               +- Relation[_c0#558,_c1#559,_c2#560,_c3#561,_c4#562,_c5#563] csv\\nand\\nProject [id#4232, did#2264, dtitle#2271, attr1#1848 AS sid#2443]\\n+- Join Inner, (attr3#1860 = dtitle#2271)\\n   :- Project [_c1#559 AS id#4232, _c2#560 AS attr1#1848, _c4#562 AS attr3#1860]\\n   :  +- Filter ((isnotnull(_c0#558) && (_c0#558 = Sentence)) && isnotnull(_c4#562))\\n   :     +- Relation[_c0#558,_c1#559,_c2#560,_c3#561,_c4#562,_c5#563] csv\\n   +- Project [_c1#559 AS did#2264, _c2#560 AS dtitle#2271]\\n      +- Filter ((isnotnull(_c0#558) && (_c0#558 = Document)) && isnotnull(_c2#560))\\n         +- Relation[_c0#558,_c1#559,_c2#560,_c3#561,_c4#562,_c5#563] csv\\nJoin condition is missing or trivial.\\nEither: use the CROSS JOIN syntax to allow cartesian products between these\\nrelations, or: enable implicit cartesian products by setting the configuration\\nvariable spark.sql.crossJoin.enabled=true;'"
     ]
    }
   ],
   "source": [
    "clause_verticesText.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clause_verticesText=clause_verticesTextJ.join(sen_verticesText.select(\"*\"), clause_verticesTextJ.src_id==sen_verticesText.id, \"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "##did doc->sentence\n",
    "# edgesText2 = edgesText1.join(verticesText1.select(\"id\",\"nodeType\"), edgesText1.src == verticesText1.select(\"id\",\"nodeType\").id, \"inner\")\n",
    "did_verticesText1=verticesText1.join(edgesText3.filter(\"label = 'contains the sentence'\").select(\"dst_id\", \"dst_nodeType\"),verticesText1.id==edgesText3.dst_id, \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----+--------------------+--------------------+---+------+---+------+-------+------+------------+-------+------------+\n",
      "|     id|nodeType|attr1|               attr2|               attr3|did|dtitle|sid|weight|matched|src_id|src_nodeType| dst_id|dst_nodeType|\n",
      "+-------+--------+-----+--------------------+--------------------+---+------+---+------+-------+------+------------+-------+------------+\n",
      "|1014942|Sentence|  102|Both the process ...|              Genome|  0|      |  0|     0|       |626404|    Document|1014942|    Sentence|\n",
      "|1015263|Sentence|   99|In the gas phase,...|             Alcohol|  0|      |  0|     0|       |626407|    Document|1015263|    Sentence|\n",
      "|1015551|Sentence|    5|In the 19th centu...|             Cartoon|  0|      |  0|     0|       |626411|    Document|1015551|    Sentence|\n",
      "|1015552|Sentence|    6|In the early 20th...|             Cartoon|  0|      |  0|     0|       |626411|    Document|1015552|    Sentence|\n",
      "|1015610|Sentence|   64|Thomson capitaliz...|             Cartoon|  0|      |  0|     0|       |626411|    Document|1015610|    Sentence|\n",
      "|1015827|Sentence|  190|The ground-sharin...|Charlton Athletic...|  0|      |  0|     0|       |626413|    Document|1015827|    Sentence|\n",
      "|1015968|Sentence|  135|The Adriatic was ...|          Battleship|  0|      |  0|     0|       |626414|    Document|1015968|    Sentence|\n",
      "|1016299|Sentence|   93|Several rebellion...|          Bangladesh|  0|      |  0|     0|       |626417|    Document|1016299|    Sentence|\n",
      "|1016518|Sentence|  312|The Bangladesh En...|          Bangladesh|  0|      |  0|     0|       |626417|    Document|1016518|    Sentence|\n",
      "|1016816|Sentence|  610|Ivory and brass w...|          Bangladesh|  0|      |  0|     0|       |626417|    Document|1016816|    Sentence|\n",
      "+-------+--------+-----+--------------------+--------------------+---+------+---+------+-------+------+------------+-------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "did_verticesText1.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesText0 = spark.read.csv(File_edgesTextRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+--------------------+\n",
      "|         _c0|    _c1|                 _c2|\n",
      "+------------+-------+--------------------+\n",
      "|Edge(5691617|7284099|contains the sent...|\n",
      "|Edge(5691617|7284100|contains the sent...|\n",
      "|Edge(5691617|7284101|contains the sent...|\n",
      "|Edge(5691617|7284102|contains the sent...|\n",
      "|Edge(5691617|7284103|contains the sent...|\n",
      "|Edge(5691617|7284104|contains the sent...|\n",
      "|Edge(5691617|7284105|contains the sent...|\n",
      "|Edge(5691617|7284106|contains the sent...|\n",
      "|Edge(5691617|7284107|contains the sent...|\n",
      "|Edge(5691617|7284108|contains the sent...|\n",
      "+------------+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edgesText0.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesText0=edgesText0.select(f.translate(f.col(\"_c0\"), \"Edge(\", \"\").alias(\"src\"), \"_c1\", f.translate(f.col(\"_c2\"), \")\", \"\").alias(\"label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+\n",
      "|    src|    _c1|               label|\n",
      "+-------+-------+--------------------+\n",
      "|5691617|7284099|contains the sent...|\n",
      "|5691617|7284100|contains the sent...|\n",
      "|5691617|7284101|contains the sent...|\n",
      "|5691617|7284102|contains the sent...|\n",
      "|5691617|7284103|contains the sent...|\n",
      "|5691617|7284104|contains the sent...|\n",
      "|5691617|7284105|contains the sent...|\n",
      "|5691617|7284106|contains the sent...|\n",
      "|5691617|7284107|contains the sent...|\n",
      "|5691617|7284108|contains the sent...|\n",
      "|5691617|7284109|contains the sent...|\n",
      "|5691617|7284110|contains the sent...|\n",
      "|5691617|7284111|contains the sent...|\n",
      "|5691617|7284112|contains the sent...|\n",
      "|5691617|7284113|contains the sent...|\n",
      "|5691617|7284114|contains the sent...|\n",
      "|5691617|7284115|contains the sent...|\n",
      "|5691617|7284116|contains the sent...|\n",
      "|5691617|7284117|contains the sent...|\n",
      "|5691617|7284118|contains the sent...|\n",
      "+-------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edgesText0.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesText1 = edgesText0.select(\"*\").withColumnRenamed(\"_c1\", \"dst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+\n",
      "|    src|    dst|               label|\n",
      "+-------+-------+--------------------+\n",
      "|5691617|7284099|contains the sent...|\n",
      "|5691617|7284100|contains the sent...|\n",
      "|5691617|7284101|contains the sent...|\n",
      "|5691617|7284102|contains the sent...|\n",
      "|5691617|7284103|contains the sent...|\n",
      "|5691617|7284104|contains the sent...|\n",
      "|5691617|7284105|contains the sent...|\n",
      "|5691617|7284106|contains the sent...|\n",
      "|5691617|7284107|contains the sent...|\n",
      "|5691617|7284108|contains the sent...|\n",
      "|5691617|7284109|contains the sent...|\n",
      "|5691617|7284110|contains the sent...|\n",
      "|5691617|7284111|contains the sent...|\n",
      "|5691617|7284112|contains the sent...|\n",
      "|5691617|7284113|contains the sent...|\n",
      "|5691617|7284114|contains the sent...|\n",
      "|5691617|7284115|contains the sent...|\n",
      "|5691617|7284116|contains the sent...|\n",
      "|5691617|7284117|contains the sent...|\n",
      "|5691617|7284118|contains the sent...|\n",
      "+-------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edgesText1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verticesText1J=verticesText1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edgesText1.join(verticesText1.set_index('id'), on='src')\n",
    "# edgesText1.join(verticesText1, [\"src\"], \"outer\")\n",
    "# edgesText2 = edgesText1.join(verticesText1, edgesText1.src == verticesText1.id, \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesText2 = edgesText1.join(verticesText1.select(\"id\",\"nodeType\"), edgesText1.src == verticesText1.select(\"id\",\"nodeType\").id, \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesText2=edgesText2.withColumnRenamed(\"id\", \"src_id\").withColumnRenamed(\"nodeType\", \"src_nodeType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+-------+------------+\n",
      "|    src|    dst|               label| src_id|src_nodeType|\n",
      "+-------+-------+--------------------+-------+------------+\n",
      "| 100010|2216143|contains the mention| 100010|      Clause|\n",
      "| 100010|2216144|contains the mention| 100010|      Clause|\n",
      "| 100140|3579975|contains the mention| 100140|      Clause|\n",
      "| 100140|3579976|contains the mention| 100140|      Clause|\n",
      "|1002011|2086735|contains the mention|1002011|      Clause|\n",
      "|1002011|2086736|contains the mention|1002011|      Clause|\n",
      "|1002185|3571984|contains the mention|1002185|      Clause|\n",
      "|1002185|3571985|contains the mention|1002185|      Clause|\n",
      "| 100227|1679175|contains the mention| 100227|      Clause|\n",
      "| 100227|1679176|contains the mention| 100227|      Clause|\n",
      "+-------+-------+--------------------+-------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edgesText2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesText3 = edgesText2.join(verticesText1.select(\"id\",\"nodeType\"), edgesText2.dst == verticesText1.select(\"id\",\"nodeType\").id, \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesText3=edgesText3.withColumnRenamed(\"id\", \"dst_id\").withColumnRenamed(\"nodeType\", \"dst_nodeType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------------------+-------+------------+-------+------------+\n",
      "|    src|    dst|              label| src_id|src_nodeType| dst_id|dst_nodeType|\n",
      "+-------+-------+-------------------+-------+------------+-------+------------+\n",
      "|1234113| 100010|contains the clause|1234113|    Sentence| 100010|      Clause|\n",
      "|3875588|1000240|contains the clause|3875588|    Sentence|1000240|      Clause|\n",
      "|3650624|1000280|contains the clause|3650624|    Sentence|1000280|      Clause|\n",
      "|2068926|1000665|contains the clause|2068926|    Sentence|1000665|      Clause|\n",
      "| 467648|1000795|contains the clause| 467648|    Sentence|1000795|      Clause|\n",
      "| 233944|1000839|contains the clause| 233944|    Sentence|1000839|      Clause|\n",
      "|4022932|1000888|contains the clause|4022932|    Sentence|1000888|      Clause|\n",
      "|1212133| 100140|contains the clause|1212133|    Sentence| 100140|      Clause|\n",
      "| 452611|1001866|contains the clause| 452611|    Sentence|1001866|      Clause|\n",
      "|1487892|1002011|contains the clause|1487892|    Sentence|1002011|      Clause|\n",
      "+-------+-------+-------------------+-------+------------+-------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edgesText3.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------------------+------+------------+-------+------------+\n",
      "|   src|    dst|               label|src_id|src_nodeType| dst_id|dst_nodeType|\n",
      "+------+-------+--------------------+------+------------+-------+------------+\n",
      "|626404|1014942|contains the sent...|626404|    Document|1014942|    Sentence|\n",
      "|626407|1015263|contains the sent...|626407|    Document|1015263|    Sentence|\n",
      "|626411|1015551|contains the sent...|626411|    Document|1015551|    Sentence|\n",
      "|626411|1015552|contains the sent...|626411|    Document|1015552|    Sentence|\n",
      "|626411|1015610|contains the sent...|626411|    Document|1015610|    Sentence|\n",
      "|626413|1015827|contains the sent...|626413|    Document|1015827|    Sentence|\n",
      "|626414|1015968|contains the sent...|626414|    Document|1015968|    Sentence|\n",
      "|626417|1016299|contains the sent...|626417|    Document|1016299|    Sentence|\n",
      "|626417|1016518|contains the sent...|626417|    Document|1016518|    Sentence|\n",
      "|626417|1016816|contains the sent...|626417|    Document|1016816|    Sentence|\n",
      "|626418|1017045|contains the sent...|626418|    Document|1017045|    Sentence|\n",
      "|626418|1017074|contains the sent...|626418|    Document|1017074|    Sentence|\n",
      "|626419|1017462|contains the sent...|626419|    Document|1017462|    Sentence|\n",
      "|626421|1017551|contains the sent...|626421|    Document|1017551|    Sentence|\n",
      "|626422|1017716|contains the sent...|626422|    Document|1017716|    Sentence|\n",
      "|626422|1017805|contains the sent...|626422|    Document|1017805|    Sentence|\n",
      "|626422|1017849|contains the sent...|626422|    Document|1017849|    Sentence|\n",
      "|626422|1018090|contains the sent...|626422|    Document|1018090|    Sentence|\n",
      "|626422|1018100|contains the sent...|626422|    Document|1018100|    Sentence|\n",
      "|626392|1018247|contains the sent...|626392|    Document|1018247|    Sentence|\n",
      "+------+-------+--------------------+------+------------+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edgesText3.filter(\"label = 'contains the sentence'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------------------+-----+--------------------+\n",
      "|  id|nodeType|               attr1|attr2|               attr3|\n",
      "+----+--------+--------------------+-----+--------------------+\n",
      "|4559|  Clause|(\"A significant c...|  SVA|A significant con...|\n",
      "|4560|  Clause|(\"by the French r...|  SVO|by the French res...|\n",
      "|4561|  Clause|(\"quinine and str...|  SVC|quinine and stryc...|\n",
      "|4562|  Clause|(\"strychnine\", \"i...|  SVC|          strychnine|\n",
      "|4563|  Clause|(\"Some writers\", ...|  SVO|        Some writers|\n",
      "|4564|  Clause|(\"those\", \"would ...|  SVO|               those|\n",
      "|4565|  Clause|(\"The English Cha...|  SVC|The English Chann...|\n",
      "|4566|  Clause|(\"Johnston\", \"res...|  SVO|            Johnston|\n",
      "|4567|  Clause|(\"Tupper\", \"becam...|  SVO|              Tupper|\n",
      "|4568|  Clause|(\"His father\", \"m...|  SVA|          His father|\n",
      "|4569|  Clause|(\"Many physicists...|  SVA|     Many physicists|\n",
      "|4570|  Clause|(\"of quantum mech...|  SVC|of quantum mechanics|\n",
      "|4571|  Clause|(\"The King\", \"app...|  SVO|            The King|\n",
      "|4572|  Clause|(\"the band\", \"spl...|  SVA|            the band|\n",
      "|4573|  Clause|(\"they\", \"had bui...|  SVO|                they|\n",
      "|4574|  Clause|(\"Channel 4\", \"ha...|  SVO|           Channel 4|\n",
      "|4575|  Clause|(\"the same logo\",...|  SVO|       the same logo|\n",
      "|4576|  Clause|(\"Others\", \"agree...| SVOC|              Others|\n",
      "|4577|  Clause|(\"some portion of...|  SVC|some portion of t...|\n",
      "|4578|  Clause|(\"the Kingdom of ...|  SVA|the Kingdom of Judah|\n",
      "+----+--------+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "verticesText1.filter(\"nodeType = 'Clause'\").show()##remember here the  attr3 is not complete, however, this data will not be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Graph & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph = GraphFrame(verticesText1, edgesText1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+\n",
      "|    src|    dst|               label|\n",
      "+-------+-------+--------------------+\n",
      "|5691617|7284099|contains the sent...|\n",
      "|5691617|7284100|contains the sent...|\n",
      "|5691617|7284101|contains the sent...|\n",
      "|5691617|7284102|contains the sent...|\n",
      "|5691617|7284103|contains the sent...|\n",
      "|5691617|7284104|contains the sent...|\n",
      "|5691617|7284105|contains the sent...|\n",
      "|5691617|7284106|contains the sent...|\n",
      "|5691617|7284107|contains the sent...|\n",
      "|5691617|7284108|contains the sent...|\n",
      "+-------+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Graph.edges.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+-------------------+\n",
      "| id|nodeType|attr1|               attr2|              attr3|\n",
      "+---+--------+-----+--------------------+-------------------+\n",
      "|  0|Sentence|    1|Politics of Burun...|Politics of Burundi|\n",
      "|  1|Sentence|    2|Executive power i...|Politics of Burundi|\n",
      "|  2|Sentence|    3|Legislative power...|Politics of Burundi|\n",
      "|  3|Sentence|    4|The political lan...|Politics of Burundi|\n",
      "|  4|Sentence|    5|The current Presi...|Politics of Burundi|\n",
      "|  5|Sentence|    6|Nkurunziza was th...|Politics of Burundi|\n",
      "|  6|Sentence|    7|In November 1995,...|Politics of Burundi|\n",
      "|  7|Sentence|    8|In July 1996, for...|Politics of Burundi|\n",
      "|  8|Sentence|    9|He declared himse...|Politics of Burundi|\n",
      "|  9|Sentence|   10|Widespread condem...|Politics of Burundi|\n",
      "+---+--------+-----+--------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Graph.vertices.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8593092"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graph.vertices.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11607488"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graph.edges.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: bfs Algorithm\n",
    "filteredPaths = Graph.bfs(\n",
    "  fromExpr = \"id = '5691617'\",\n",
    "  toExpr = \"id = '7284108'\",\n",
    "  maxPathLength = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                from|                  e0|                  to|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|[5691617, Documen...|[5691617, 7284108...|[7284108, Sentenc...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display(filteredPaths)\n",
    "filteredPaths.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.13 64-bit ('QUEST': conda)",
   "language": "python",
   "name": "python271364bitquestconda39a3e5c16cfd48579e21bcb7b60777eb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
